# Model Configuration - DistilBERT
# Based on EDA key decisions

backbone: "distilbert-base-uncased"
tokenizer: "distilbert-base-uncased"

# EDA-based decisions
preprocessing:
  sequence_length: 40  # Covers 94.8% of sentences
  max_length: 128  # Safety margin
  tokenization: "subword"  # BPE/WordPiece for lexical sparsity
  replace_rare_with_unk: true
  unk_frequency_threshold: 2  # Replace tokens with freq ≤2
  keep_stopwords: true  # Essential for entity boundaries

decoding:
  use_crf: true  # Span-aware decoding for entity spans
  crf_learning_rate: 0.01

loss:
  use_class_weights: true
  class_weight_smoothing: 0.1  # Avoid naïve inverse-frequency
  ignore_index: -100

