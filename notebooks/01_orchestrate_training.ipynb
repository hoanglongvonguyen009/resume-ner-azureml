{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Training Orchestration\n",
    "\n",
    "This notebook orchestrates all training activities without performing local computation.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Step 1**: Load Centralized Configs\n",
    "- **Step 2**: Data Ingestion & Versioning (Asset Layer)\n",
    "- **Step 3**: Environment Definition\n",
    "- **Step 4**: The Dry Run\n",
    "- **Step 5**: The Sweep (HPO)\n",
    "- **Step 6**: Best Configuration Selection (Automated)\n",
    "- **Step 7**: Final Training (Post-HPO, Single Run)\n",
    "\n",
    "## Important\n",
    "\n",
    "- This notebook **only submits and monitors Azure ML jobs**\n",
    "- **No training logic** is executed locally\n",
    "- All computation happens remotely on Azure ML compute\n",
    "- The notebook must be **re-runnable end-to-end**\n",
    "\n",
    "## Platform Adapter Architecture\n",
    "\n",
    "The training and conversion scripts (`src/train.py` and `src/convert_to_onnx.py`) use a **platform adapter pattern** that automatically detects the execution environment (Azure ML vs local) and adapts accordingly:\n",
    "\n",
    "- **Output paths**: Automatically resolves Azure ML output directories via `AZURE_ML_OUTPUT_*` environment variables\n",
    "- **Logging**: Handles both MLflow and Azure ML native logging seamlessly\n",
    "- **MLflow context**: Manages MLflow runs appropriately for each platform\n",
    "- **Checkpoint resolution**: Handles Azure ML mounted inputs and local file paths\n",
    "\n",
    "This architecture allows the same code to run consistently on both Azure ML and local setups. When jobs run in Azure ML, the adapters automatically detect the Azure ML environment and use Azure-specific implementations. See `docs/PLATFORM_ADAPTER_ARCHITECTURE.md` for details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.1: Load Centralized Configs\n",
    "\n",
    "Load and validate all configuration files. Configs are immutable and will be logged with each job for reproducibility.\n",
    "\n",
    "**Note**: The training and conversion scripts executed by these jobs use platform adapters that automatically handle Azure ML-specific concerns (output paths, logging, MLflow context) without requiring explicit configuration in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml-mlflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Ensure we can import the orchestration package and shared utilities\n",
    "import sys\n",
    "ROOT_DIR = Path(\"..\").resolve()\n",
    "SRC_DIR = ROOT_DIR / \"src\"\n",
    "sys.path.append(str(ROOT_DIR))\n",
    "sys.path.append(str(SRC_DIR))\n",
    "\n",
    "from shared.yaml_utils import load_yaml\n",
    "from shared.json_cache import save_json, load_json\n",
    "from orchestration import (\n",
    "    STAGE_SMOKE,\n",
    "    STAGE_HPO,\n",
    "    STAGE_TRAINING,\n",
    "    EXPERIMENT_NAME,\n",
    "    MODEL_NAME,\n",
    "    PROD_STAGE,\n",
    "    build_aml_experiment_name,\n",
    ")\n",
    "from orchestration.config_loader import (\n",
    "    ExperimentConfig,\n",
    "    create_config_metadata,\n",
    "    load_all_configs,\n",
    "    load_experiment_config,\n",
    "    compute_config_hashes,\n",
    "    snapshot_configs,\n",
    "    validate_config_immutability,\n",
    ")\n",
    "\n",
    "\n",
    "env_path = Path(\"../config.env\")\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DIR = Path(\"../config\")\n",
    "\n",
    "# Experiment selection (switch to try different data/model/HPO/env combos)\n",
    "# The concrete experiment definition lives in config/experiment/<EXPERIMENT_NAME>.yaml\n",
    "\n",
    "# Resolve experiment-level config into concrete file paths\n",
    "experiment_config: ExperimentConfig = load_experiment_config(CONFIG_DIR, EXPERIMENT_NAME)\n",
    "configs = load_all_configs(experiment_config)\n",
    "config_hashes = compute_config_hashes(configs)\n",
    "\n",
    "# Immutable snapshots for runtime mutation checks\n",
    "original_configs = snapshot_configs(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse shared immutability validator from orchestration package\n",
    "validate_config_immutability(configs, original_configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace_name(configs: Dict[str, Any]) -> str:\n",
    "    \"\"\"Resolve the Azure ML workspace name from configuration files.\n",
    "\n",
    "    Order of precedence:\n",
    "    1. ``config/infrastructure.yaml`` (``workspace.name``)\n",
    "    2. ``config/env/azure.yaml`` (``workspace.name`` under ``env`` config)\n",
    "\n",
    "    This function is pure: it only reads configuration objects and files,\n",
    "    and does not perform any network or Azure ML operations.\n",
    "    \"\"\"\n",
    "    infrastructure_config_path = Path(\"../config/infrastructure.yaml\")\n",
    "    if infrastructure_config_path.exists():\n",
    "        infrastructure_config = load_yaml(infrastructure_config_path)\n",
    "        return infrastructure_config[\"workspace\"][\"name\"]\n",
    "\n",
    "    env_workspace = configs[\"env\"].get(\"workspace\", {}).get(\"name\")\n",
    "    if env_workspace:\n",
    "        return env_workspace\n",
    "\n",
    "    raise ValueError(\n",
    "        \"Workspace name must be configured in either \"\n",
    "        \"config/infrastructure.yaml (workspace.name) or config/env/azure.yaml (workspace.name).\"\n",
    "    )\n",
    "\n",
    "\n",
    "def create_ml_client(configs: Dict[str, Any]) -> MLClient:\n",
    "    \"\"\"Create an MLClient instance for the configured Azure ML workspace.\n",
    "\n",
    "    This function is responsible for reading required environment variables\n",
    "    and instantiating the Azure ML client. It assumes that configuration\n",
    "    loading has already completed.\n",
    "    \"\"\"\n",
    "    subscription_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "    resource_group = os.getenv(\"AZURE_RESOURCE_GROUP\")\n",
    "\n",
    "    if not subscription_id or not resource_group:\n",
    "        raise ValueError(\"AZURE_SUBSCRIPTION_ID and AZURE_RESOURCE_GROUP must be set\")\n",
    "\n",
    "    workspace_name = get_workspace_name(configs)\n",
    "    credential = DefaultAzureCredential()\n",
    "    return MLClient(\n",
    "        credential=credential,\n",
    "        subscription_id=subscription_id,\n",
    "        resource_group_name=resource_group,\n",
    "        workspace_name=workspace_name,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate MLClient for the configured workspace\n",
    "ml_client = create_ml_client(configs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All configs and their hashes will be attached to each Azure ML job for full reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build config metadata for job tagging using shared helper from\n",
    "# `orchestration.config_loader`.\n",
    "config_metadata = create_config_metadata(configs, config_hashes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.2: Data Ingestion & Versioning (Asset Layer)\n",
    "\n",
    "Upload dataset to Blob Storage and register as an Azure ML Data Asset for versioned, immutable data access.\n",
    "\n",
    "**Note**: The training script accepts data asset paths and can work with both Azure ML data assets (when running in Azure ML) and local file paths (when running locally), thanks to the platform adapter architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.data_assets import (\n",
    "    resolve_dataset_path,\n",
    "    register_data_asset,\n",
    "    ensure_data_asset_uploaded,\n",
    "    build_data_asset_reference,\n",
    ")\n",
    "\n",
    "# Resolve local dataset path from data config (configs[\"data\"][\"local_path\"])\n",
    "DATASET_LOCAL_PATH = resolve_dataset_path(configs[\"data\"])\n",
    "DATA_ASSET_NAME = configs[\"data\"][\"name\"]\n",
    "DATA_ASSET_VERSION = configs[\"data\"][\"version\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ASSET_OVERRIDE_PATH = None\n",
    "blob_uri = DATA_ASSET_OVERRIDE_PATH or str(DATASET_LOCAL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading dataset_tiny (0.02 MBs): 100%|##########| 16164/16164 [00:01<00:00, 15159.48it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_asset = register_data_asset(\n",
    "    ml_client=ml_client,\n",
    "    name=DATA_ASSET_NAME,\n",
    "    version=DATA_ASSET_VERSION,\n",
    "    uri=blob_uri,\n",
    "    description=configs[\"data\"][\"description\"],\n",
    ")\n",
    "\n",
    "# Best-effort upload of local content to the resolved data asset\n",
    "data_asset = ensure_data_asset_uploaded(\n",
    "    ml_client=ml_client,\n",
    "    data_asset=data_asset,\n",
    "    local_path=DATASET_LOCAL_PATH,\n",
    "    description=configs[\"data\"][\"description\"],\n",
    ")\n",
    "\n",
    "# Build shared references for downstream jobs\n",
    "asset_paths = build_data_asset_reference(ml_client, data_asset)\n",
    "asset_reference = asset_paths[\"asset_uri\"]\n",
    "datastore_path = asset_paths[\"datastore_path\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "\n",
    "If you encounter `ScriptExecution.StreamAccess.NotFound`, verify that:\n",
    "1. Compute cluster has managed identity assigned\n",
    "2. Managed identity has \"Storage Blob Data Reader\" role on storage account\n",
    "3. Storage account firewall allows Azure services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data asset: resume-ner-data-tiny-short v2.2 to data_asset_cache.json\n"
     ]
    }
   ],
   "source": [
    "# Save data asset info to a JSON file\n",
    "data_asset_cache_file = Path(\"data_asset_cache.json\")\n",
    "\n",
    "if \"data_asset\" in globals() and data_asset is not None:\n",
    "    data_asset_info = {\n",
    "        \"name\": data_asset.name,\n",
    "        \"version\": data_asset.version,\n",
    "        \"asset_paths\": asset_paths,\n",
    "    }\n",
    "\n",
    "    save_json(data_asset_cache_file, data_asset_info)\n",
    "    print(\n",
    "        f\"Saved data asset: {data_asset_info['name']} {data_asset_info['version']} \"\n",
    "        f\"to {data_asset_cache_file}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No data asset to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data asset: resume-ner-data-tiny-short vv2.2\n",
      "Asset URI: azureml:resume-ner-data-tiny-short:v2.2\n",
      "Skipping data asset registration - using cached asset\n"
     ]
    }
   ],
   "source": [
    "from orchestration.data_assets import build_data_asset_reference\n",
    "\n",
    "# Try to reload from cache\n",
    "data_asset_cache_file = Path(\"data_asset_cache.json\")\n",
    "\n",
    "data_asset_info = load_json(data_asset_cache_file, default=None)\n",
    "\n",
    "if data_asset_info is None:\n",
    "    print(\n",
    "        f\"Cache file {data_asset_cache_file} not found. \"\n",
    "        \"Will need to register data asset.\"\n",
    "    )\n",
    "    data_asset = None\n",
    "else:\n",
    "    try:\n",
    "        # Reload Data asset object from ML client\n",
    "        data_asset = ml_client.data.get(\n",
    "            name=data_asset_info[\"name\"],\n",
    "            version=data_asset_info[\"version\"],\n",
    "        )\n",
    "\n",
    "        # Rebuild asset_paths if they were saved, otherwise regenerate them\n",
    "        asset_paths = data_asset_info.get(\"asset_paths\") or build_data_asset_reference(\n",
    "            ml_client, data_asset\n",
    "        )\n",
    "\n",
    "        asset_reference = asset_paths[\"asset_uri\"]\n",
    "        datastore_path = asset_paths[\"datastore_path\"]\n",
    "\n",
    "        print(f\"Loaded data asset: {data_asset.name} v{data_asset.version}\")\n",
    "        print(f\"Asset URI: {asset_reference}\")\n",
    "        print(\"Skipping data asset registration - using cached asset\")\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            \"Warning: Could not load data asset \"\n",
    "            f\"{data_asset_info['name']} v{data_asset_info['version']}: {e}\"\n",
    "        )\n",
    "        print(\"Will need to register data asset again\")\n",
    "        data_asset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.3: Environment Definition\n",
    "\n",
    "Define a stable execution environment (Docker image + Conda dependencies) for consistent behavior across all training jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "\u001b[32mUploading src (0.19 MBs): 100%|##########| 192117/192117 [00:01<00:00, 122282.88it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: serene_machine_vc4bm1gjbp\n",
      "Web View: https://ml.azure.com/runs/serene_machine_vc4bm1gjbp?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "======Starting Image Build on Compute======\n",
      "The run ID for the image build on compute is imgbldrun_fc3f3cc\n",
      "Additional logs for the run: https://ml.azure.com/experiments/id/prepare_image/runs/imgbldrun_fc3f3cc?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f\n",
      "2025-12-18T22:01:09: Logging into Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-18T22:01:09: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "\n",
      "2025-12-18T22:01:09: Login Succeeded\n",
      "2025-12-18T22:01:09: WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "2025-12-18T22:01:09: Configure a credential helper to remove this warning. See\n",
      "2025-12-18T22:01:09: https://docs.docker.com/go/credential-store/\n",
      "\n",
      "\n",
      "\n",
      "2025-12-18T22:01:09: Running: ['docker', 'build', '-f', 'azureml-environment-setup/Dockerfile', '.', '-t', 'b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_f7da780250c27339c3dcc717184b56bf', '-t', 'b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_f7da780250c27339c3dcc717184b56bf:1']\n",
      "2025-12-18T22:01:09: #0 building with \"default\" instance using docker driver\n",
      "\n",
      "2025-12-18T22:01:09: #1 [internal] load .dockerignore\n",
      "2025-12-18T22:01:09: #1 transferring context: 2B done\n",
      "2025-12-18T22:01:09: #1 DONE 0.1s\n",
      "\n",
      "2025-12-18T22:01:09: #2 [internal] load build definition from Dockerfile\n",
      "2025-12-18T22:01:09: #2 transferring dockerfile: 1.68kB done\n",
      "2025-12-18T22:01:09: #2 DONE 0.1s\n",
      "\n",
      "2025-12-18T22:01:09: #3 [internal] load metadata for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33\n",
      "2025-12-18T22:01:10: #3 DONE 0.4s\n",
      "\n",
      "2025-12-18T22:01:10: #4 [internal] load build context\n",
      "2025-12-18T22:01:10: #4 transferring context: 1.79kB done\n",
      "2025-12-18T22:01:10: #4 DONE 0.1s\n",
      "\n",
      "2025-12-18T22:01:10: #5 [ 1/10] FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33\n",
      "2025-12-18T22:01:10: #5 resolve mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33 0.0s done\n",
      "2025-12-18T22:01:10: #5 sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33 2.43kB / 2.43kB done\n",
      "2025-12-18T22:01:10: #5 sha256:83631454f85b20f6f2f386c8f58cd8ec885a6b678fcbab1c9a21e1c9ceab4493 9.06kB / 9.06kB done\n",
      "2025-12-18T22:01:10: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 4.19MB / 28.58MB 0.2s\n",
      "2025-12-18T22:01:10: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 0B / 153.10MB 0.2s\n",
      "2025-12-18T22:01:10: #5 sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572 641.60kB / 641.60kB 0.1s done\n",
      "2025-12-18T22:01:10: #5 sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 0B / 3.61MB 0.2s\n",
      "2025-12-18T22:01:10: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 27.26MB / 28.58MB 0.3s\n",
      "2025-12-18T22:01:10: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 13.63MB / 153.10MB 0.3s\n",
      "2025-12-18T22:01:10: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 37.75MB / 153.10MB 0.4s\n",
      "2025-12-18T22:01:10: #5 sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 3.61MB / 3.61MB 0.4s\n",
      "2025-12-18T22:01:10: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 63.96MB / 153.10MB 0.5s\n",
      "2025-12-18T22:01:10: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 28.58MB / 28.58MB 0.5s done\n",
      "2025-12-18T22:01:10: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 87.03MB / 153.10MB 0.6s\n",
      "2025-12-18T22:01:10: #5 sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 3.61MB / 3.61MB 0.5s done\n",
      "2025-12-18T22:01:10: #5 extracting sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1\n",
      "2025-12-18T22:01:10: #5 sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 0B / 169B 0.6s\n",
      "2025-12-18T22:01:10: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 0B / 127.20MB 0.6s\n",
      "2025-12-18T22:01:10: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 105.91MB / 153.10MB 0.7s\n",
      "2025-12-18T22:01:10: #5 sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 169B / 169B 0.7s\n",
      "2025-12-18T22:01:10: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 121.63MB / 153.10MB 0.8s\n",
      "2025-12-18T22:01:10: #5 sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 169B / 169B 0.7s done\n",
      "2025-12-18T22:01:10: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 13.90MB / 127.20MB 0.8s\n",
      "2025-12-18T22:01:10: #5 sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 0B / 4.17MB 0.8s\n",
      "2025-12-18T22:01:11: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 135.94MB / 153.10MB 0.9s\n",
      "2025-12-18T22:01:11: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 29.36MB / 127.20MB 0.9s\n",
      "2025-12-18T22:01:11: #5 sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 4.17MB / 4.17MB 0.9s\n",
      "2025-12-18T22:01:11: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 152.04MB / 153.10MB 1.0s\n",
      "2025-12-18T22:01:11: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 46.14MB / 127.20MB 1.0s\n",
      "2025-12-18T22:01:11: #5 sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 4.17MB / 4.17MB 0.9s done\n",
      "2025-12-18T22:01:11: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 0B / 41.39MB 1.0s\n",
      "2025-12-18T22:01:11: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 63.96MB / 127.20MB 1.1s\n",
      "2025-12-18T22:01:11: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 6.29MB / 41.39MB 1.1s\n",
      "2025-12-18T22:01:11: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 79.69MB / 127.20MB 1.2s\n",
      "2025-12-18T22:01:11: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 23.07MB / 41.39MB 1.2s\n",
      "2025-12-18T22:01:11: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 95.42MB / 127.20MB 1.3s\n",
      "2025-12-18T22:01:11: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 37.75MB / 41.39MB 1.3s\n",
      "2025-12-18T22:01:11: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 117.44MB / 127.20MB 1.5s\n",
      "2025-12-18T22:01:11: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 41.39MB / 41.39MB 1.5s\n",
      "2025-12-18T22:01:12: #5 extracting sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 1.3s done\n",
      "2025-12-18T22:01:12: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 153.10MB / 153.10MB 2.2s done\n",
      "2025-12-18T22:01:12: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 127.20MB / 127.20MB 2.7s\n",
      "2025-12-18T22:01:12: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 41.39MB / 41.39MB 2.6s done\n",
      "2025-12-18T22:01:12: #5 sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 0B / 5.71MB 2.7s\n",
      "2025-12-18T22:01:12: #5 sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 5.71MB / 5.71MB 2.8s\n",
      "2025-12-18T22:01:13: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 127.20MB / 127.20MB 3.7s done\n",
      "2025-12-18T22:01:13: #5 sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 5.71MB / 5.71MB 3.8s done\n",
      "2025-12-18T22:01:14: #5 sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 0B / 197.03kB 3.9s\n",
      "2025-12-18T22:01:14: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 0.1s\n",
      "2025-12-18T22:01:15: #5 sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 197.03kB / 197.03kB 4.7s done\n",
      "2025-12-18T22:01:19: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 5.2s\n",
      "2025-12-18T22:01:19: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 5.4s done\n",
      "2025-12-18T22:01:23: #5 extracting sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572\n",
      "2025-12-18T22:01:23: #5 extracting sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572 0.0s done\n",
      "2025-12-18T22:01:23: #5 extracting sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94\n",
      "2025-12-18T22:01:24: #5 extracting sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 0.5s done\n",
      "2025-12-18T22:01:24: #5 extracting sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26\n",
      "2025-12-18T22:01:24: #5 extracting sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 done\n",
      "2025-12-18T22:01:24: #5 extracting sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 0.1s\n",
      "2025-12-18T22:01:27: #5 extracting sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 3.7s done\n",
      "2025-12-18T22:01:30: #5 extracting sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725\n",
      "2025-12-18T22:01:31: #5 extracting sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 0.2s done\n",
      "2025-12-18T22:01:31: #5 extracting sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310\n",
      "2025-12-18T22:01:31: #5 extracting sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 0.5s done\n",
      "2025-12-18T22:01:32: #5 extracting sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba\n",
      "2025-12-18T22:01:32: #5 extracting sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 0.0s done\n",
      "2025-12-18T22:01:32: #5 extracting sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3\n",
      "2025-12-18T22:01:32: #5 extracting sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 0.0s done\n",
      "2025-12-18T22:01:32: #5 DONE 22.7s\n",
      "\n",
      "2025-12-18T22:01:32: #6 [ 2/10] RUN mkdir -p $HOME/.cache\n",
      "2025-12-18T22:01:33: #6 DONE 0.3s\n",
      "\n",
      "2025-12-18T22:01:33: #7 [ 3/10] COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      "2025-12-18T22:01:33: #7 DONE 0.1s\n",
      "\n",
      "2025-12-18T22:01:33: #8 [ 4/10] RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      "2025-12-18T22:01:34: #8 DONE 1.7s\n",
      "\n",
      "2025-12-18T22:01:34: #9 [ 5/10] COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      "2025-12-18T22:01:34: #9 DONE 0.1s\n",
      "\n",
      "2025-12-18T22:01:35: #10 [ 6/10] RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_d814665c2345be6bee20d6b8bc278ede -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      "2025-12-18T22:01:36: #10 0.596 Retrieving notices: done\n",
      "2025-12-18T22:01:36: #10 1.505 Channels:\n",
      "2025-12-18T22:01:36: #10 1.505  - pytorch\n",
      "2025-12-18T22:01:36: #10 1.505  - conda-forge\n",
      "2025-12-18T22:01:36: #10 1.505  - defaults\n",
      "2025-12-18T22:01:36: #10 1.505 Platform: linux-64\n",
      "2025-12-18T22:01:50: #10 1.505 Collecting package metadata (repodata.json): ...working... done\n",
      "2025-12-18T22:01:56: #10 15.77 Solving environment: ...working... done\n",
      "2025-12-18T22:01:56: #10 21.45 \n",
      "2025-12-18T22:01:56: #10 21.45 \n",
      "2025-12-18T22:01:56: #10 21.45 ==> WARNING: A newer version of conda exists. <==\n",
      "2025-12-18T22:01:56: #10 21.45     current version: 25.1.1\n",
      "2025-12-18T22:01:56: #10 21.45     latest version: 25.11.1\n",
      "2025-12-18T22:01:56: #10 21.45 \n",
      "2025-12-18T22:01:56: #10 21.45 Please update conda by running\n",
      "2025-12-18T22:01:56: #10 21.45 \n",
      "2025-12-18T22:01:56: #10 21.45     $ conda update -n base -c conda-forge conda\n",
      "2025-12-18T22:01:56: #10 21.45 \n",
      "2025-12-18T22:01:56: #10 21.45 \n",
      "2025-12-18T22:01:56: #10 21.55 \n",
      "2025-12-18T22:01:56: mkl-2025.3.0         | 119.4 MB  |            |   0% \n",
      "2025-12-18T22:01:56: libtorch-2.9.1       | 57.9 MB   |            |   0% \u001b[A\n",
      "2025-12-18T22:01:56: #10 21.55 \n",
      "2025-12-18T22:01:56: python-3.10.19       | 24.1 MB   |            |   0% \u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.55 \n",
      "2025-12-18T22:01:56: #10 21.55 \n",
      "2025-12-18T22:01:56: pytorch-2.9.1        | 20.4 MB   |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.55 \n",
      "2025-12-18T22:01:56: #10 21.55 \n",
      "2025-12-18T22:01:56: #10 21.55 \n",
      "2025-12-18T22:01:56: numpy-2.2.6          | 7.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: llvm-openmp-21.1.8   | 5.8 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: libstdcxx-15.2.0     | 5.6 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: libprotobuf-6.31.1   | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: sympy-1.14.0         | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: tk-8.6.13            | 3.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: openssl-3.6.0        | 3.0 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: libhwloc-2.12.1      | 2.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: sleef-3.9.0          | 1.9 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: libabseil-20250512.1 | 1.2 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: networkx-3.4.2       | 1.2 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: pip-25.3             | 1.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: libgcc-15.2.0        | 1018 KB   |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: libsqlite-3.51.1     | 917 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: #10 21.56 \n",
      "2025-12-18T22:01:56: libuv-1.51.0         | 874 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: #10 21.57 \n",
      "2025-12-18T22:01:56: mkl-2025.3.0         | 119.4 MB  | 1          |   2% \n",
      "2025-12-18T22:01:56: libtorch-2.9.1       | 57.9 MB   |            |   1% \u001b[A\n",
      "2025-12-18T22:01:56: #10 21.65 \n",
      "2025-12-18T22:01:56: python-3.10.19       | 24.1 MB   | 7          |   7% \u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.65 \n",
      "2025-12-18T22:01:56: #10 21.65 \n",
      "2025-12-18T22:01:56: pytorch-2.9.1        | 20.4 MB   | 1          |   1% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.66 \n",
      "2025-12-18T22:01:56: #10 21.66 \n",
      "2025-12-18T22:01:56: #10 21.66 \n",
      "2025-12-18T22:01:56: mkl-2025.3.0         | 119.4 MB  | 4          |   4% \n",
      "2025-12-18T22:01:56: libtorch-2.9.1       | 57.9 MB   | 5          |   6% \u001b[A\n",
      "2025-12-18T22:01:56: #10 21.75 \n",
      "2025-12-18T22:01:56: python-3.10.19       | 24.1 MB   | ##         |  21% \u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.75 \n",
      "2025-12-18T22:01:56: #10 21.75 \n",
      "2025-12-18T22:01:56: pytorch-2.9.1        | 20.4 MB   | #6         |  17% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.76 \n",
      "2025-12-18T22:01:56: #10 21.76 \n",
      "2025-12-18T22:01:56: #10 21.76 \n",
      "2025-12-18T22:01:56: mkl-2025.3.0         | 119.4 MB  | 7          |   7% \n",
      "2025-12-18T22:01:56: #10 21.85 \n",
      "2025-12-18T22:01:56: python-3.10.19       | 24.1 MB   | ###5       |  35% \u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.85 \n",
      "2025-12-18T22:01:56: #10 21.85 \n",
      "2025-12-18T22:01:56: pytorch-2.9.1        | 20.4 MB   | ###4       |  34% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:56: #10 21.86 \n",
      "2025-12-18T22:01:56: #10 21.86 \n",
      "2025-12-18T22:01:56: #10 21.86 \n",
      "2025-12-18T22:01:56: numpy-2.2.6          | 7.5 MB    | ########8  |  89% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: mkl-2025.3.0         | 119.4 MB  | #          |  10% \n",
      "2025-12-18T22:01:57: #10 21.95 \n",
      "2025-12-18T22:01:57: python-3.10.19       | 24.1 MB   | ####9      |  49% \u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: #10 21.95 \n",
      "2025-12-18T22:01:57: #10 21.95 \n",
      "2025-12-18T22:01:57: pytorch-2.9.1        | 20.4 MB   | #####      |  50% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: mkl-2025.3.0         | 119.4 MB  | #3         |  14% \n",
      "2025-12-18T22:01:57: #10 22.05 \n",
      "2025-12-18T22:01:57: python-3.10.19       | 24.1 MB   | ######3    |  63% \u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: #10 22.05 \n",
      "2025-12-18T22:01:57: #10 22.05 \n",
      "2025-12-18T22:01:57: pytorch-2.9.1        | 20.4 MB   | ######8    |  69% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: #10 22.08 \n",
      "2025-12-18T22:01:57: #10 22.08 \n",
      "2025-12-18T22:01:57: #10 22.08 \n",
      "2025-12-18T22:01:57: numpy-2.2.6          | 7.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: libtorch-2.9.1       | 57.9 MB   | ##1        |  21% \u001b[A\n",
      "2025-12-18T22:01:57: #10 22.13 \n",
      "2025-12-18T22:01:57: #10 22.13 \n",
      "2025-12-18T22:01:57: #10 22.13 \n",
      "2025-12-18T22:01:57: #10 22.13 \n",
      "2025-12-18T22:01:57: llvm-openmp-21.1.8   | 5.8 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: #10 22.16 \n",
      "2025-12-18T22:01:57: #10 22.16 \n",
      "2025-12-18T22:01:57: pytorch-2.9.1        | 20.4 MB   | ########4  |  85% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: #10 22.16 \n",
      "2025-12-18T22:01:57: mkl-2025.3.0         | 119.4 MB  | #6         |  17% \n",
      "2025-12-18T22:01:57: libtorch-2.9.1       | 57.9 MB   | ##6        |  26% \u001b[A\n",
      "2025-12-18T22:01:57: #10 22.23 \n",
      "2025-12-18T22:01:57: #10 22.23 \n",
      "2025-12-18T22:01:57: #10 22.23 \n",
      "2025-12-18T22:01:57: #10 22.23 \n",
      "2025-12-18T22:01:57: mkl-2025.3.0         | 119.4 MB  | #9         |  19% \n",
      "2025-12-18T22:01:57: #10 22.28 \n",
      "2025-12-18T22:01:57: python-3.10.19       | 24.1 MB   | #########  |  90% \u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: libtorch-2.9.1       | 57.9 MB   | ###1       |  31% \u001b[A\n",
      "2025-12-18T22:01:57: #10 22.33 \n",
      "2025-12-18T22:01:57: #10 22.33 \n",
      "2025-12-18T22:01:57: #10 22.33 \n",
      "2025-12-18T22:01:57: #10 22.33 \n",
      "2025-12-18T22:01:57: mkl-2025.3.0         | 119.4 MB  | ##2        |  22% \n",
      "2025-12-18T22:01:57: mkl-2025.3.0         | 119.4 MB  | ##5        |  25% \n",
      "2025-12-18T22:01:57: libtorch-2.9.1       | 57.9 MB   | ####3      |  44% \u001b[A\n",
      "2025-12-18T22:01:57: #10 22.49 \n",
      "2025-12-18T22:01:57: #10 22.49 \n",
      "2025-12-18T22:01:57: #10 22.49 \n",
      "2025-12-18T22:01:57: #10 22.49 \n",
      "2025-12-18T22:01:57: llvm-openmp-21.1.8   | 5.8 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: #10 22.52 \n",
      "2025-12-18T22:01:57: #10 22.52 \n",
      "2025-12-18T22:01:57: #10 22.52 \n",
      "2025-12-18T22:01:57: #10 22.52 \n",
      "2025-12-18T22:01:57: #10 22.52 \n",
      "2025-12-18T22:01:57: libstdcxx-15.2.0     | 5.6 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: mkl-2025.3.0         | 119.4 MB  | ##8        |  28% \n",
      "2025-12-18T22:01:57: #10 22.62 \n",
      "2025-12-18T22:01:57: #10 22.62 \n",
      "2025-12-18T22:01:57: #10 22.62 \n",
      "2025-12-18T22:01:57: #10 22.62 \n",
      "2025-12-18T22:01:57: #10 22.62 \n",
      "2025-12-18T22:01:57: libstdcxx-15.2.0     | 5.6 MB    | ####9      |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: mkl-2025.3.0         | 119.4 MB  | ###1       |  31% \n",
      "2025-12-18T22:01:57: mkl-2025.3.0         | 119.4 MB  | ###3       |  34% \n",
      "2025-12-18T22:01:57: #10 22.88 \n",
      "2025-12-18T22:01:57: #10 22.88 \n",
      "2025-12-18T22:01:57: #10 22.88 \n",
      "2025-12-18T22:01:57: #10 22.88 \n",
      "2025-12-18T22:01:57: #10 22.88 \n",
      "2025-12-18T22:01:57: libstdcxx-15.2.0     | 5.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: #10 22.88 \n",
      "2025-12-18T22:01:57: #10 22.88 \n",
      "2025-12-18T22:01:57: #10 22.88 \n",
      "2025-12-18T22:01:57: #10 22.88 \n",
      "2025-12-18T22:01:57: #10 22.88 \n",
      "2025-12-18T22:01:57: libstdcxx-15.2.0     | 5.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: libtorch-2.9.1       | 57.9 MB   | ######6    |  67% \u001b[A\n",
      "2025-12-18T22:01:57: #10 22.90 \n",
      "2025-12-18T22:01:57: #10 22.90 \n",
      "2025-12-18T22:01:57: mkl-2025.3.0         | 119.4 MB  | ###6       |  37% \n",
      "2025-12-18T22:01:57: #10 22.92 \n",
      "2025-12-18T22:01:57: #10 22.92 \n",
      "2025-12-18T22:01:57: #10 22.92 \n",
      "2025-12-18T22:01:57: #10 22.92 \n",
      "2025-12-18T22:01:57: #10 22.92 \n",
      "2025-12-18T22:01:57: #10 22.92 \n",
      "2025-12-18T22:01:57: libprotobuf-6.31.1   | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:57: #10 22.93 \n",
      "2025-12-18T22:01:57: #10 22.93 \n",
      "2025-12-18T22:01:57: #10 22.93 \n",
      "2025-12-18T22:01:57: #10 22.93 \n",
      "2025-12-18T22:01:57: #10 22.93 \n",
      "2025-12-18T22:01:57: #10 22.93 \n",
      "2025-12-18T22:01:57: #10 22.93 \n",
      "2025-12-18T22:01:57: sympy-1.14.0         | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: libtorch-2.9.1       | 57.9 MB   | #######2   |  72% \u001b[A\n",
      "2025-12-18T22:01:58: #10 23.02 \n",
      "2025-12-18T22:01:58: #10 23.02 \n",
      "2025-12-18T22:01:58: #10 23.02 \n",
      "2025-12-18T22:01:58: #10 23.02 \n",
      "2025-12-18T22:01:58: #10 23.02 \n",
      "2025-12-18T22:01:58: #10 23.02 \n",
      "2025-12-18T22:01:58: mkl-2025.3.0         | 119.4 MB  | ###9       |  39% \n",
      "2025-12-18T22:01:58: #10 23.03 \n",
      "2025-12-18T22:01:58: #10 23.03 \n",
      "2025-12-18T22:01:58: #10 23.03 \n",
      "2025-12-18T22:01:58: #10 23.03 \n",
      "2025-12-18T22:01:58: #10 23.03 \n",
      "2025-12-18T22:01:58: #10 23.03 \n",
      "2025-12-18T22:01:58: #10 23.03 \n",
      "2025-12-18T22:01:58: sympy-1.14.0         | 4.4 MB    | #####8     |  58% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.12 \n",
      "2025-12-18T22:01:58: mkl-2025.3.0         | 119.4 MB  | ####2      |  42% \n",
      "2025-12-18T22:01:58: libtorch-2.9.1       | 57.9 MB   | #######7   |  78% \u001b[A\n",
      "2025-12-18T22:01:58: #10 23.16 \n",
      "2025-12-18T22:01:58: #10 23.16 \n",
      "2025-12-18T22:01:58: #10 23.16 \n",
      "2025-12-18T22:01:58: #10 23.16 \n",
      "2025-12-18T22:01:58: #10 23.16 \n",
      "2025-12-18T22:01:58: #10 23.16 \n",
      "2025-12-18T22:01:58: #10 23.16 \n",
      "2025-12-18T22:01:58: #10 23.16 \n",
      "2025-12-18T22:01:58: mkl-2025.3.0         | 119.4 MB  | ####4      |  45% \n",
      "2025-12-18T22:01:58: libtorch-2.9.1       | 57.9 MB   | ########2  |  83% \u001b[A\n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: libprotobuf-6.31.1   | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: libprotobuf-6.31.1   | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: #10 23.26 \n",
      "2025-12-18T22:01:58: tk-8.6.13            | 3.1 MB    | ########5  |  86% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: llvm-openmp-21.1.8   | 5.8 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: #10 23.27 \n",
      "2025-12-18T22:01:58: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.29 \n",
      "2025-12-18T22:01:58: #10 23.29 \n",
      "2025-12-18T22:01:58: #10 23.29 \n",
      "2025-12-18T22:01:58: #10 23.29 \n",
      "2025-12-18T22:01:58: #10 23.29 \n",
      "2025-12-18T22:01:58: #10 23.29 \n",
      "2025-12-18T22:01:58: #10 23.29 \n",
      "2025-12-18T22:01:58: #10 23.29 \n",
      "2025-12-18T22:01:58: #10 23.29 \n",
      "2025-12-18T22:01:58: openssl-3.6.0        | 3.0 MB    |            |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.31 \n",
      "2025-12-18T22:01:58: #10 23.31 \n",
      "2025-12-18T22:01:58: #10 23.31 \n",
      "2025-12-18T22:01:58: #10 23.31 \n",
      "2025-12-18T22:01:58: #10 23.31 \n",
      "2025-12-18T22:01:58: #10 23.31 \n",
      "2025-12-18T22:01:58: #10 23.31 \n",
      "2025-12-18T22:01:58: #10 23.31 \n",
      "2025-12-18T22:01:58: #10 23.31 \n",
      "2025-12-18T22:01:58: #10 23.31 \n",
      "2025-12-18T22:01:58: mkl-2025.3.0         | 119.4 MB  | ####6      |  47% \n",
      "2025-12-18T22:01:58: libtorch-2.9.1       | 57.9 MB   | ########7  |  88% \u001b[A\n",
      "2025-12-18T22:01:58: #10 23.39 \n",
      "2025-12-18T22:01:58: #10 23.39 \n",
      "2025-12-18T22:01:58: #10 23.39 \n",
      "2025-12-18T22:01:58: #10 23.39 \n",
      "2025-12-18T22:01:58: #10 23.39 \n",
      "2025-12-18T22:01:58: #10 23.39 \n",
      "2025-12-18T22:01:58: #10 23.39 \n",
      "2025-12-18T22:01:58: #10 23.39 \n",
      "2025-12-18T22:01:58: #10 23.39 \n",
      "2025-12-18T22:01:58: openssl-3.6.0        | 3.0 MB    | ########1  |  82% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.40 \n",
      "2025-12-18T22:01:58: #10 23.40 \n",
      "2025-12-18T22:01:58: #10 23.40 \n",
      "2025-12-18T22:01:58: #10 23.40 \n",
      "2025-12-18T22:01:58: #10 23.40 \n",
      "2025-12-18T22:01:58: #10 23.40 \n",
      "2025-12-18T22:01:58: #10 23.40 \n",
      "2025-12-18T22:01:58: #10 23.40 \n",
      "2025-12-18T22:01:58: tk-8.6.13            | 3.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.44 \n",
      "2025-12-18T22:01:58: #10 23.44 \n",
      "2025-12-18T22:01:58: #10 23.44 \n",
      "2025-12-18T22:01:58: #10 23.44 \n",
      "2025-12-18T22:01:58: #10 23.44 \n",
      "2025-12-18T22:01:58: #10 23.44 \n",
      "2025-12-18T22:01:58: #10 23.44 \n",
      "2025-12-18T22:01:58: #10 23.44 \n",
      "2025-12-18T22:01:58: #10 23.44 \n",
      "2025-12-18T22:01:58: #10 23.44 \n",
      "2025-12-18T22:01:58: #10 23.44 \n",
      "2025-12-18T22:01:58: mkl-2025.3.0         | 119.4 MB  | ####9      |  49% \n",
      "2025-12-18T22:01:58: libtorch-2.9.1       | 57.9 MB   | #########2 |  92% \u001b[A\n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: #10 23.50 \n",
      "2025-12-18T22:01:58: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.54 \n",
      "2025-12-18T22:01:58: #10 23.54 \n",
      "2025-12-18T22:01:58: #10 23.54 \n",
      "2025-12-18T22:01:58: #10 23.54 \n",
      "2025-12-18T22:01:58: #10 23.54 \n",
      "2025-12-18T22:01:58: #10 23.54 \n",
      "2025-12-18T22:01:58: #10 23.54 \n",
      "2025-12-18T22:01:58: #10 23.54 \n",
      "2025-12-18T22:01:58: #10 23.54 \n",
      "2025-12-18T22:01:58: openssl-3.6.0        | 3.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: #10 23.55 \n",
      "2025-12-18T22:01:58: mkl-2025.3.0         | 119.4 MB  | #####1     |  52% \n",
      "2025-12-18T22:01:58: libtorch-2.9.1       | 57.9 MB   | #########7 |  97% \u001b[A\n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: networkx-3.4.2       | 1.2 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: #10 23.59 \n",
      "2025-12-18T22:01:58: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: pip-25.3             | 1.1 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: #10 23.63 \n",
      "2025-12-18T22:01:58: libabseil-20250512.1 | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: #10 23.67 \n",
      "2025-12-18T22:01:58: mkl-2025.3.0         | 119.4 MB  | #####4     |  54% \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: #10 23.68 \n",
      "2025-12-18T22:01:58: networkx-3.4.2       | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: #10 23.71 \n",
      "2025-12-18T22:01:58: libsqlite-3.51.1     | 917 KB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: #10 23.74 \n",
      "2025-12-18T22:01:58: libgcc-15.2.0        | 1018 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: #10 23.75 \n",
      "2025-12-18T22:01:58: mkl-2025.3.0         | 119.4 MB  | #####6     |  57% \n",
      "2025-12-18T22:01:58: #10 23.77 \n",
      "2025-12-18T22:01:58: #10 23.77 \n",
      "2025-12-18T22:01:58: #10 23.77 \n",
      "2025-12-18T22:01:58: #10 23.77 \n",
      "2025-12-18T22:01:58: #10 23.77 \n",
      "2025-12-18T22:01:58: libstdcxx-15.2.0     | 5.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: libsqlite-3.51.1     | 917 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58: #10 23.78 \n",
      "2025-12-18T22:01:58:  ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: #10 23.82 \n",
      "2025-12-18T22:01:58: libuv-1.51.0         | 874 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:01:58: #10 23.84 \n",
      "2025-12-18T22:02:00: mkl-2025.3.0         | 119.4 MB  | #########8 |  98% \n",
      "2025-12-18T22:02:01: libtorch-2.9.1       | 57.9 MB   | ########## | 100% \u001b[A\n",
      "2025-12-18T22:02:01: #10 26.19 \n",
      "2025-12-18T22:02:01: #10 26.19 \n",
      "2025-12-18T22:02:01: #10 26.19 \n",
      "2025-12-18T22:02:01: numpy-2.2.6          | 7.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:01: #10 26.93 \n",
      "2025-12-18T22:02:01: #10 26.93 \n",
      "2025-12-18T22:02:01: #10 26.93 \n",
      "2025-12-18T22:02:01: #10 26.93 \n",
      "2025-12-18T22:02:01: #10 26.93 \n",
      "2025-12-18T22:02:01: #10 26.93 \n",
      "2025-12-18T22:02:02: mkl-2025.3.0         | 119.4 MB  | ########## | 100% \n",
      "2025-12-18T22:02:02: #10 27.99 \n",
      "2025-12-18T22:02:03: python-3.10.19       | 24.1 MB   | ########## | 100% \u001b[A\u001b[A\n",
      "2025-12-18T22:02:03: #10 28.68 \n",
      "2025-12-18T22:02:03: #10 28.68 \n",
      "2025-12-18T22:02:03: #10 28.68 \n",
      "2025-12-18T22:02:03: #10 28.68 \n",
      "2025-12-18T22:02:03: #10 28.68 \n",
      "2025-12-18T22:02:03: #10 28.68 \n",
      "2025-12-18T22:02:03: #10 28.68 \n",
      "2025-12-18T22:02:03: #10 28.68 \n",
      "2025-12-18T22:02:03: tk-8.6.13            | 3.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:03: #10 28.70 \n",
      "2025-12-18T22:02:03: #10 28.70 \n",
      "2025-12-18T22:02:03: #10 28.70 \n",
      "2025-12-18T22:02:03: #10 28.70 \n",
      "2025-12-18T22:02:03: #10 28.70 \n",
      "2025-12-18T22:02:03: #10 28.70 \n",
      "2025-12-18T22:02:03: #10 28.70 \n",
      "2025-12-18T22:02:04: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:04: #10 29.05 \n",
      "2025-12-18T22:02:04: #10 29.05 \n",
      "2025-12-18T22:02:04: #10 29.05 \n",
      "2025-12-18T22:02:04: #10 29.05 \n",
      "2025-12-18T22:02:04: #10 29.05 \n",
      "2025-12-18T22:02:04: #10 29.05 \n",
      "2025-12-18T22:02:04: #10 29.05 \n",
      "2025-12-18T22:02:04: #10 29.05 \n",
      "2025-12-18T22:02:04: #10 29.05 \n",
      "2025-12-18T22:02:04: openssl-3.6.0        | 3.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:04: #10 29.17 \n",
      "2025-12-18T22:02:04: #10 29.17 \n",
      "2025-12-18T22:02:04: #10 29.17 \n",
      "2025-12-18T22:02:04: #10 29.17 \n",
      "2025-12-18T22:02:04: #10 29.17 \n",
      "2025-12-18T22:02:04: #10 29.17 \n",
      "2025-12-18T22:02:04: #10 29.17 \n",
      "2025-12-18T22:02:04: #10 29.17 \n",
      "2025-12-18T22:02:04: #10 29.17 \n",
      "2025-12-18T22:02:04: #10 29.17 \n",
      "2025-12-18T22:02:04: #10 29.17 \n",
      "2025-12-18T22:02:04: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:04: #10 29.23 \n",
      "2025-12-18T22:02:04: #10 29.23 \n",
      "2025-12-18T22:02:04: #10 29.23 \n",
      "2025-12-18T22:02:04: #10 29.23 \n",
      "2025-12-18T22:02:04: #10 29.23 \n",
      "2025-12-18T22:02:04: #10 29.23 \n",
      "2025-12-18T22:02:04: #10 29.23 \n",
      "2025-12-18T22:02:04: #10 29.23 \n",
      "2025-12-18T22:02:04: #10 29.23 \n",
      "2025-12-18T22:02:04: #10 29.23 \n",
      "2025-12-18T22:02:04: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:04: #10 29.88 \n",
      "2025-12-18T22:02:05: networkx-3.4.2       | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: #10 29.88 \n",
      "2025-12-18T22:02:05: networkx-3.4.2       | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: libabseil-20250512.1 | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: #10 29.94 \n",
      "2025-12-18T22:02:05: libabseil-20250512.1 | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: libgcc-15.2.0        | 1018 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: #10 30.06 \n",
      "2025-12-18T22:02:05: libgcc-15.2.0        | 1018 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: libsqlite-3.51.1     | 917 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: #10 30.13 \n",
      "2025-12-18T22:02:05: libsqlite-3.51.1     | 917 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: libuv-1.51.0         | 874 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: #10 30.19 \n",
      "2025-12-18T22:02:05: libuv-1.51.0         | 874 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:05: #10 30.44 \n",
      "2025-12-18T22:02:06: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:06: #10 31.24 \n",
      "2025-12-18T22:02:06: #10 31.24 \n",
      "2025-12-18T22:02:07: pytorch-2.9.1        | 20.4 MB   | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07:  ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:07: #10 32.77 \n",
      "2025-12-18T22:02:13: mkl-2025.3.0         | 119.4 MB  | ########## | 100% \n",
      "2025-12-18T22:02:13: libtorch-2.9.1       | 57.9 MB   | ########## | 100% \u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: \u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: #10 38.18 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: \u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: \u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: #10 38.19 \n",
      "2025-12-18T22:02:13: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A done\n",
      "2025-12-18T22:02:13: #10 38.19 Preparing transaction: done\n",
      "2025-12-18T22:02:16: #10 38.95 Verifying transaction: done\n",
      "2025-12-18T22:02:26: #10 41.70 Executing transaction: done\n",
      "2025-12-18T22:04:34: #10 51.24 Installing pip dependencies: \\ Ran pip subprocess with arguments:\n",
      "2025-12-18T22:04:34: #10 179.1 ['/azureml-envs/azureml_d814665c2345be6bee20d6b8bc278ede/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt', '--exists-action=b']\n",
      "2025-12-18T22:04:34: #10 179.1 Pip subprocess output:\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azureml-defaults (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azureml_defaults-1.61.0-py3-none-any.whl.metadata (914 bytes)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting transformers<5.0.0,>=4.35.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting safetensors>=0.4.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 3))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting datasets>=2.12.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting numpy<2.0,>=1.24.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 5))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pandas>=2.0.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 6))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting scikit-learn>=1.3.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 7))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-ai-ml>=1.0.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_ai_ml-1.30.0-py3-none-any.whl.metadata (40 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-identity>=1.12.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 9))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_identity-1.25.1-py3-none-any.whl.metadata (88 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-storage-blob>=12.17.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 10))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_blob-12.27.1-py3-none-any.whl.metadata (26 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pyyaml>=6.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 11))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting tqdm>=4.65.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 12))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting seqeval>=1.2.2 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 13))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Installing build dependencies: started\n",
      "2025-12-18T22:04:34: #10 179.1   Installing build dependencies: finished with status 'done'\n",
      "2025-12-18T22:04:34: #10 179.1   Getting requirements to build wheel: started\n",
      "2025-12-18T22:04:34: #10 179.1   Getting requirements to build wheel: finished with status 'done'\n",
      "2025-12-18T22:04:34: #10 179.1   Installing backend dependencies: started\n",
      "2025-12-18T22:04:34: #10 179.1   Installing backend dependencies: finished with status 'done'\n",
      "2025-12-18T22:04:34: #10 179.1   Preparing metadata (pyproject.toml): started\n",
      "2025-12-18T22:04:34: #10 179.1   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting sentencepiece>=0.1.99 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 14))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting mlflow (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading mlflow-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azureml-mlflow (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 16))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azureml_mlflow-1.61.0.post1-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting onnxruntime (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 17))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading onnxruntime-1.23.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting onnx>=1.16.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 18))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading onnx-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting onnxscript>=0.1.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 19))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Requirement already satisfied: filelock in /azureml-envs/azureml_d814665c2345be6bee20d6b8bc278ede/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2)) (3.20.1)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting huggingface-hub<1.0,>=0.34.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting packaging>=20.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2))\n",
      "2025-12-18T22:04:34: #10 179.1   Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting requests (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Requirement already satisfied: fsspec>=2023.5.0 in /azureml-envs/azureml_d814665c2345be6bee20d6b8bc278ede/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2)) (2025.12.0)\n",
      "2025-12-18T22:04:34: #10 179.1 Requirement already satisfied: typing-extensions>=3.7.4.3 in /azureml-envs/azureml_d814665c2345be6bee20d6b8bc278ede/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2)) (4.15.0)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azureml-inference-server-http~=1.4 (from azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azureml_inference_server_http-1.5.1-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azureml-core~=1.61.0 (from azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azureml_core-1.61.0.post1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azureml-dataset-runtime~=1.61.0 (from azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azureml_dataset_runtime-1.61.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pytz (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting backports.tempfile (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading backports.tempfile-1.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pathspec<1.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting msal<2.0.0,>=1.15.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting msal-extensions<=2.0.0,>=0.3.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting knack<0.13.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading knack-0.12.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-core<2.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_core-1.37.0-py3-none-any.whl.metadata (47 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pkginfo (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pkginfo-1.12.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting argcomplete<4 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading argcomplete-3.6.3-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting humanfriendly<11.0,>=4.7 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting paramiko<4.0.0,>=2.0.8 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-mgmt-resource<=24.0.0,>=15.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_mgmt_resource-24.0.0-py3-none-any.whl.metadata (43 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-mgmt-containerregistry<15,>=8.2.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_mgmt_containerregistry-14.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-mgmt-storage<=24.0.0,>=16.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_mgmt_storage-24.0.0-py3-none-any.whl.metadata (36 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-mgmt-keyvault<12.0.0,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_mgmt_keyvault-11.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-mgmt-authorization<5,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-mgmt-network<=30.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_mgmt_network-30.0.0-py3-none-any.whl.metadata (94 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-graphrbac<1.0.0,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_graphrbac-0.61.2-py2.py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-common<2.0.0,>=1.1.12 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting msrest<=0.7.1,>=0.5.1 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting msrestazure<=0.7,>=0.4.33 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting urllib3<3.0.0,>1.26.17 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting python-dateutil<3.0.0,>=2.7.3 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting ndg-httpsclient<=0.5.1 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading ndg_httpsclient-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting SecretStorage<4.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading secretstorage-3.5.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting jsonpickle<5.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading jsonpickle-4.1.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting contextlib2<22.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting docker<8.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting PyJWT<3.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting adal<=1.2.7,>=1.2.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading adal-1.2.7-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pyopenssl<26.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting jmespath<2.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting cryptography>=1.1.0 (from adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting isodate<1.0.0,>=0.6.1 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-mgmt-core<2.0.0,>=1.3.2 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_mgmt_core-1.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azureml-dataprep<5.5.0a,>=5.1.0a (from azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azureml_dataprep-5.4.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pyarrow<21.0.0,>=0.17.0 (from azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azureml-dataprep-native<43.0.0,>=42.0.0 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azureml_dataprep_native-42.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azureml-dataprep-rslex~=2.25.1 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azureml_dataprep_rslex-2.25.2-cp310-cp310-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting cloudpickle<3.0.0,>=1.1.0 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-identity>=1.12.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 9))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_identity-1.17.0-py3-none-any.whl.metadata (79 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting jsonschema (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Requirement already satisfied: pip>=25.3 in /azureml-envs/azureml_d814665c2345be6bee20d6b8bc278ede/lib/python3.10/site-packages (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1)) (25.3)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting fusepy<4.0.0,>=3.0.1 (from azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Installing build dependencies: started\n",
      "2025-12-18T22:04:34: #10 179.1   Installing build dependencies: finished with status 'done'\n",
      "2025-12-18T22:04:34: #10 179.1   Getting requirements to build wheel: started\n",
      "2025-12-18T22:04:34: #10 179.1   Getting requirements to build wheel: finished with status 'done'\n",
      "2025-12-18T22:04:34: #10 179.1   Preparing metadata (pyproject.toml): started\n",
      "2025-12-18T22:04:34: #10 179.1   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting flask~=3.1.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting flask-cors~=6.0.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting gunicorn>=23.0.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting inference-schema~=1.8.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading inference_schema-1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-sdk==1.33.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-api==1.33.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_api-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-semantic-conventions (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry_exporter-1.0.0b46-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pydantic~=2.12.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pydantic-settings (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting werkzeug>=3.0.3 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting certifi>=2024.7.4 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting deprecated>=1.2.6 (from opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-semantic-conventions (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting blinker>=1.9.0 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting click>=8.1.3 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting itsdangerous>=2.2.0 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Requirement already satisfied: jinja2>=3.1.2 in /azureml-envs/azureml_d814665c2345be6bee20d6b8bc278ede/lib/python3.10/site-packages (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1)) (3.1.6)\n",
      "2025-12-18T22:04:34: #10 179.1 Requirement already satisfied: markupsafe>=2.1.1 in /azureml-envs/azureml_d814665c2345be6bee20d6b8bc278ede/lib/python3.10/site-packages (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1)) (3.0.3)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting wrapt<=1.16.0,>=1.14.0 (from inference-schema~=1.8.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pygments (from knack<0.13.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting tabulate (from knack<0.13.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting cffi>=2.0.0 (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting requests-oauthlib>=0.5.0 (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting six (from msrestazure<=0.7,>=0.4.33->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pyasn1>=0.1.1 (from ndg-httpsclient<=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting bcrypt>=3.2 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pynacl>=1.5 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pynacl-1.6.1-cp38-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting annotated-types>=0.6.0 (from pydantic~=2.12.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pydantic-core==2.41.5 (from pydantic~=2.12.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting typing-inspection>=0.4.2 (from pydantic~=2.12.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting charset_normalizer<4,>=2 (from requests->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting idna<4,>=2.5 (from requests->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting jeepney>=0.6 (from SecretStorage<4.0.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading jeepney-0.9.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting datasets>=2.12.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading datasets-4.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading datasets-4.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting xxhash (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting multiprocess<0.70.17 (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 2))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting tzdata>=2022.7 (from pandas>=2.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 6))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting scipy>=1.8.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 7))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting joblib>=1.2.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 7))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 7))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting marshmallow<4.0.0,>=3.5 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting strictyaml<2.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting colorama<1.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-storage-file-share (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_file_share-12.23.1-py3-none-any.whl.metadata (52 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_file_datalake-12.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pydash<9.0.0,>=6.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pydash-8.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.8.3-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting attrs>=22.2.0 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting referencing>=0.28.4 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting rpds-py>=0.7.1 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting mlflow-skinny==3.7.0 (from mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading mlflow_skinny-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting mlflow-tracing==3.7.0 (from mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading mlflow_tracing-3.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting alembic!=1.10.0,<2 (from mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting graphene<4 (from mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting huey<3,>=2.5.0 (from mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading huey-2.5.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting matplotlib<4 (from mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting sqlalchemy<3,>=1.4.0 (from mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading sqlalchemy-2.0.45-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading cachetools-6.2.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading databricks_sdk-0.76.0-py3-none-any.whl.metadata (40 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting fastapi<1 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading fastapi-0.125.0-py3-none-any.whl.metadata (30 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading sqlparse-0.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting uvicorn<1 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting Mako (from alembic!=1.10.0,<2->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting tomli (from alembic!=1.10.0,<2->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Using cached tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading google_auth-2.45.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting starlette<0.51.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting cycler>=0.10 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting fonttools>=4.22.0 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting kiwisolver>=1.3.1 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pillow>=8 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pyparsing>=3 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading greenlet-3.3.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting anyio<5,>=3.6.2 (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 15))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of azureml-mlflow to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azureml-mlflow (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 16))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azureml_mlflow-1.61.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azureml_mlflow-1.60.0.post1-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azureml_mlflow-1.60.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-storage-blob>=12.17.0 (from -r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 10))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting coloredlogs (from onnxruntime->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 17))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting flatbuffers (from onnxruntime->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 17))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "2025-12-18T22:04:34: #10 179.1 Requirement already satisfied: sympy in /azureml-envs/azureml_d814665c2345be6bee20d6b8bc278ede/lib/python3.10/site-packages (from onnxruntime->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 17)) (1.14.0)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting ml_dtypes>=0.5.0 (from onnx>=1.16.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 18))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading ml_dtypes-0.5.4-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting onnx_ir<2,>=0.1.12 (from onnxscript>=0.1.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 19))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading onnx_ir-0.1.13-py3-none-any.whl.metadata (3.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 4))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of azure-storage-file-datalake to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_file_datalake-12.21.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_file_datalake-12.19.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_file_datalake-12.18.1-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_file_datalake-12.18.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_file_datalake-12.17.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_file_datalake-12.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is still looking at multiple versions of azure-storage-file-datalake to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_file_datalake-12.15.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_storage_file_datalake-12.14.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting pycparser (from cffi>=2.0.0->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-core-tracing-opentelemetry~=1.0.0b11 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of azure-monitor-opentelemetry to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.8.2-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.8.1-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.8.0-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-django~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_django-0.60b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-fastapi~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_fastapi-0.60b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-flask~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_flask-0.60b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-psycopg2~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_psycopg2-0.60b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-requests~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_requests-0.60b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-urllib~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib-0.60b1-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-urllib3~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib3-0.60b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-resource-detector-azure~=0.1.5 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl.metadata (5.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.6.13-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.6.12-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-django<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_django-0.52b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-flask<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_flask-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-psycopg2<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_psycopg2-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-requests<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_requests-0.52b1-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-urllib<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib-0.52b1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-urllib3<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib3-0.52b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.6.11-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is still looking at multiple versions of azure-monitor-opentelemetry to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.6.10-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.6.9-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.6.8-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry-1.6.7-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of azure-monitor-opentelemetry-exporter to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry_exporter-1.0.0b45-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry_exporter-1.0.0b44-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry_exporter-1.0.0b43-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry_exporter-1.0.0b42-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry_exporter-1.0.0b41-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading azure_monitor_opentelemetry_exporter-1.0.0b40-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting psutil<8,>=5.9 (from azure-monitor-opentelemetry-exporter->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-wsgi==0.60b1 (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_wsgi-0.60b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation==0.60b1 (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation-0.60b1-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-django to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_django-0.60b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-wsgi==0.60b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_wsgi-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation==0.60b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation-0.60b0-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_django-0.59b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-wsgi==0.59b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_wsgi-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_django-0.58b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-wsgi==0.58b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_wsgi-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation==0.58b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_django-0.57b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-wsgi==0.57b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_wsgi-0.57b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation==0.57b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_django-0.56b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-wsgi==0.56b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_wsgi-0.56b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation==0.56b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation-0.56b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_django-0.55b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-wsgi==0.55b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_wsgi-0.55b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_django-0.55b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-wsgi==0.55b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_wsgi-0.55b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation==0.55b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation-0.55b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-django to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_django-0.54b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-wsgi==0.54b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_wsgi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_django-0.54b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-wsgi==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_wsgi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-util-http==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-asgi==0.60b1 (from opentelemetry-instrumentation-fastapi~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_asgi-0.60b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_fastapi-0.60b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-asgi==0.60b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_asgi-0.60b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_fastapi-0.59b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-asgi==0.59b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_asgi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_fastapi-0.58b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-asgi==0.58b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_asgi-0.58b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_fastapi-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-asgi==0.57b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_asgi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_fastapi-0.56b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-asgi==0.56b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_asgi-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_fastapi-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-asgi==0.55b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_asgi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-asgi==0.54b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b0->opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading asgiref-3.11.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-flask to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-flask~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_flask-0.60b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_flask-0.59b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_flask-0.58b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_flask-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_flask-0.56b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_flask-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_flask-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-flask to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_flask-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_flask-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-dbapi==0.60b1 (from opentelemetry-instrumentation-psycopg2~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_dbapi-0.60b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-psycopg2 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_psycopg2-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-dbapi==0.60b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_dbapi-0.60b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_psycopg2-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-dbapi==0.59b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_dbapi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_psycopg2-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-dbapi==0.58b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_dbapi-0.58b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_psycopg2-0.57b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-dbapi==0.57b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_dbapi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_psycopg2-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-dbapi==0.56b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_dbapi-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_psycopg2-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-dbapi==0.55b1 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_dbapi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_psycopg2-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-dbapi==0.55b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_dbapi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-psycopg2 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_psycopg2-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-dbapi==0.54b1 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_dbapi-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_psycopg2-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-dbapi==0.54b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_dbapi-0.54b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-requests to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-requests~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_requests-0.60b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_requests-0.59b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_requests-0.58b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_requests-0.57b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_requests-0.56b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_requests-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_requests-0.55b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-requests to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_requests-0.54b1-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_requests-0.54b0-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-urllib to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-urllib~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib-0.60b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib-0.59b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib-0.58b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib-0.57b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib-0.56b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib-0.55b1-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib-0.55b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-urllib to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib-0.54b1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib-0.54b0-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting opentelemetry-instrumentation-urllib3~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 8))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib3-0.60b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib3-0.59b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib3-0.58b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib3-0.57b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib3-0.56b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib3-0.55b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib3-0.55b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib3-0.54b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading opentelemetry_instrumentation_urllib3-0.54b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Collecting backports.weakref (from backports.tempfile->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 1))\n",
      "2025-12-18T22:04:34: #10 179.1   Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Requirement already satisfied: mpmath<1.4,>=1.1.0 in /azureml-envs/azureml_d814665c2345be6bee20d6b8bc278ede/lib/python3.10/site-packages (from sympy->onnxruntime->-r /azureml-environment-setup/condaenv.h6v5k1n4.requirements.txt (line 17)) (1.3.0)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     12.0/12.0 MB 127.9 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     18.2/18.2 MB 78.7 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "2025-12-18T22:04:34: #10 179.1     566.1/566.1 kB 21.0 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     3.3/3.3 MB 65.7 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     3.3/3.3 MB 92.2 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azureml_defaults-1.61.0-py3-none-any.whl (2.1 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azureml_core-1.61.0.post1-py3-none-any.whl (3.3 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     3.3/3.3 MB 93.6 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading argcomplete-3.6.3-py3-none-any.whl (43 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_core-1.37.0-py3-none-any.whl (214 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_graphrbac-0.61.2-py2.py3-none-any.whl (142 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl (1.1 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     1.1/1.1 MB 37.9 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_mgmt_containerregistry-14.0.0-py3-none-any.whl (1.7 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     1.7/1.7 MB 64.5 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_mgmt_core-1.6.0-py3-none-any.whl (29 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_mgmt_keyvault-11.0.0-py3-none-any.whl (308 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_mgmt_network-30.0.0-py3-none-any.whl (614 kB)\n",
      "2025-12-18T22:04:34: #10 179.1     614.0/614.0 kB 21.6 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_mgmt_resource-24.0.0-py3-none-any.whl (3.6 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     3.6/3.6 MB 74.1 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_mgmt_storage-24.0.0-py3-none-any.whl (290 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azureml_dataset_runtime-1.61.0-py3-none-any.whl (2.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azureml_dataprep-5.4.2-py3-none-any.whl (253 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_identity-1.17.0-py3-none-any.whl (173 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "2025-12-18T22:04:34: #10 179.1     770.3/770.3 kB 29.9 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azureml_dataprep_native-42.1.0-cp310-cp310-manylinux1_x86_64.whl (187 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azureml_dataprep_rslex-2.25.2-cp310-cp310-manylinux1_x86_64.whl (26.1 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     26.1/26.1 MB 80.1 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azureml_inference_server_http-1.5.1-py3-none-any.whl (42 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_api-1.33.0-py3-none-any.whl (65 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl (118 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl (194 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading inference_schema-1.8-py3-none-any.whl (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading jsonpickle-4.1.1-py3-none-any.whl (47 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading knack-0.12.0-py3-none-any.whl (60 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading msal-1.34.0-py3-none-any.whl (116 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     4.5/4.5 MB 84.1 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl (40 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading paramiko-3.5.1-py3-none-any.whl (227 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     42.3/42.3 MB 63.0 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     2.1/2.1 MB 79.9 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pyopenssl-25.3.0-py3-none-any.whl (57 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading secretstorage-3.5.0-py3-none-any.whl (15 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     12.8/12.8 MB 103.7 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     9.7/9.7 MB 106.3 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_ai_ml-1.30.0-py3-none-any.whl (13.3 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     13.3/13.3 MB 89.1 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     1.4/1.4 MB 42.9 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading mlflow-3.7.0-py3-none-any.whl (8.9 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     8.9/8.9 MB 95.1 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading mlflow_skinny-3.7.0-py3-none-any.whl (2.4 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     2.4/2.4 MB 74.0 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading mlflow_tracing-3.7.0-py3-none-any.whl (1.3 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     1.3/1.3 MB 48.7 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading alembic-1.17.2-py3-none-any.whl (248 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading cachetools-6.2.4-py3-none-any.whl (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading databricks_sdk-0.76.0-py3-none-any.whl (774 kB)\n",
      "2025-12-18T22:04:34: #10 179.1     774.7/774.7 kB 35.3 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading fastapi-0.125.0-py3-none-any.whl (112 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading google_auth-2.45.0-py2.py3-none-any.whl (233 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading huey-2.5.5-py3-none-any.whl (76 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     8.7/8.7 MB 124.9 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     37.7/37.7 MB 66.7 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading sqlalchemy-2.0.45-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     3.2/3.2 MB 106.7 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading sqlparse-0.5.4-py3-none-any.whl (45 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azureml_mlflow-1.60.0-py3-none-any.whl (1.0 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     1.0/1.0 MB 44.3 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading onnxruntime-1.23.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     17.4/17.4 MB 103.8 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading onnx-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     18.1/18.1 MB 89.9 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n",
      "2025-12-18T22:04:34: #10 179.1     693.4/693.4 kB 31.6 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading onnx_ir-0.1.13-py3-none-any.whl (133 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     1.7/1.7 MB 65.0 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_storage_file_datalake-12.14.0-py3-none-any.whl (251 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     4.9/4.9 MB 122.9 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading greenlet-3.3.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (586 kB)\n",
      "2025-12-18T22:04:34: #10 179.1     586.9/586.9 kB 25.5 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading jeepney-0.9.0-py3-none-any.whl (49 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     1.6/1.6 MB 45.4 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading ml_dtypes-0.5.4-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     5.0/5.0 MB 105.7 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     7.0/7.0 MB 129.4 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pynacl-1.6.1-cp38-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     1.4/1.4 MB 57.9 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "2025-12-18T22:04:34: #10 179.1     791.7/791.7 kB 35.8 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_monitor_opentelemetry-1.6.7-py3-none-any.whl (23 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl (11 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_monitor_opentelemetry_exporter-1.0.0b40-py2.py3-none-any.whl (159 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_instrumentation_django-0.54b0-py3-none-any.whl (19 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl (31 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_instrumentation_wsgi-0.54b0-py3-none-any.whl (14 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl (7.3 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl (16 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading asgiref-3.11.0-py3-none-any.whl (24 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_instrumentation_flask-0.54b0-py3-none-any.whl (14 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_instrumentation_psycopg2-0.54b0-py3-none-any.whl (10 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_instrumentation_dbapi-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_instrumentation_requests-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_instrumentation_urllib-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_instrumentation_urllib3-0.54b0-py3-none-any.whl (13 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl (14 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading azure_storage_file_share-12.23.1-py3-none-any.whl (307 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pkginfo-1.12.1.2-py3-none-any.whl (32 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "2025-12-18T22:04:34: #10 179.1     1.2/1.2 MB 56.0 MB/s  0:00:00\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Using cached tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "2025-12-18T22:04:34: #10 179.1 Building wheels for collected packages: fusepy, seqeval\n",
      "2025-12-18T22:04:34: #10 179.1   Building wheel for fusepy (pyproject.toml): started\n",
      "2025-12-18T22:04:34: #10 179.1   Building wheel for fusepy (pyproject.toml): finished with status 'done'\n",
      "2025-12-18T22:04:34: #10 179.1   Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10537 sha256=8fe92e9e0c260a4a43a0071171473f5b4c93341554f4091fecd836a0162cfbd2\n",
      "2025-12-18T22:04:34: #10 179.1   Stored in directory: /root/.cache/pip/wheels/c0/18/f6/f0d6be9d0435e2677ce5cc758e91da50053dce456a346f08c5\n",
      "2025-12-18T22:04:34: #10 179.1   Building wheel for seqeval (pyproject.toml): started\n",
      "2025-12-18T22:04:34: #10 179.1   Building wheel for seqeval (pyproject.toml): finished with status 'done'\n",
      "2025-12-18T22:04:34: #10 179.1   Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16250 sha256=e10fd548d70cc7118321505c772ecbd1ed466f405c57af3d7210838b7dc32686\n",
      "2025-12-18T22:04:34: #10 179.1   Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "2025-12-18T22:04:34: #10 179.1 Successfully built fusepy seqeval\n",
      "2025-12-18T22:04:34: #10 179.1 Installing collected packages: pytz, huey, fusepy, flatbuffers, fixedint, backports.weakref, azureml-dataprep-rslex, azure-common, zipp, xxhash, wrapt, werkzeug, urllib3, tzdata, typing-inspection, tqdm, tomli, threadpoolctl, tabulate, sqlparse, smmap, six, sentencepiece, safetensors, rpds-py, regex, pyyaml, python-dotenv, PySocks, pyparsing, PyJWT, pygments, pydash, pydantic-core, pycparser, pyasn1, pyarrow, psutil, protobuf, propcache, pkginfo, pillow, pathspec, packaging, opentelemetry-util-http, oauthlib, numpy, multidict, Mako, kiwisolver, jsonpickle, joblib, jmespath, jeepney, itsdangerous, isodate, idna, humanfriendly, hf-xet, h11, greenlet, graphql-core, fsspec, frozenlist, fonttools, exceptiongroup, dill, cycler, contextlib2, colorama, cloudpickle, click, charset_normalizer, certifi, cachetools, blinker, bcrypt, backports.tempfile, azureml-dataprep-native, attrs, async-timeout, asgiref, argcomplete, annotated-types, annotated-doc, aiohappyeyeballs, yarl, uvicorn, sqlalchemy, scipy, rsa, requests, referencing, python-dateutil, pydantic, pyasn1-modules, opentelemetry-proto, multiprocess, ml_dtypes, marshmallow, knack, importlib-metadata, gunicorn, graphql-relay, gitdb, flask, deprecated, contourpy, coloredlogs, cffi, anyio, aiosignal, strictyaml, starlette, scikit-learn, requests-oauthlib, pynacl, pydantic-settings, pandas, opentelemetry-api, onnxruntime, onnx, matplotlib, jsonschema-specifications, inference-schema, huggingface-hub, graphene, google-auth, gitpython, flask-cors, docker, cryptography, azure-core, alembic, aiohttp, tokenizers, seqeval, SecretStorage, pyopenssl, paramiko, opentelemetry-semantic-conventions, onnx_ir, msrest, jsonschema, fastapi, databricks-sdk, azure-storage-file-share, azure-storage-blob, azure-mgmt-core, azure-core-tracing-opentelemetry, adal, transformers, opentelemetry-sdk, opentelemetry-instrumentation, onnxscript, ndg-httpsclient, msrestazure, msal, datasets, azure-storage-file-datalake, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-network, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, opentelemetry-resource-detector-azure, opentelemetry-instrumentation-wsgi, opentelemetry-instrumentation-urllib3, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-dbapi, opentelemetry-instrumentation-asgi, msal-extensions, mlflow-tracing, mlflow-skinny, azure-graphrbac, opentelemetry-instrumentation-psycopg2, opentelemetry-instrumentation-flask, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-django, mlflow, azureml-core, azure-identity, azureml-mlflow, azureml-dataprep, azure-monitor-opentelemetry-exporter, azureml-inference-server-http, azureml-dataset-runtime, azure-monitor-opentelemetry, azure-ai-ml, azureml-defaults\n",
      "2025-12-18T22:04:34: #10 179.1   Attempting uninstall: numpy\n",
      "2025-12-18T22:04:34: #10 179.1     Found existing installation: numpy 2.2.6\n",
      "2025-12-18T22:04:34: #10 179.1     Uninstalling numpy-2.2.6:\n",
      "2025-12-18T22:04:34: #10 179.1       Successfully uninstalled numpy-2.2.6\n",
      "2025-12-18T22:04:34: #10 179.1   Attempting uninstall: fsspec\n",
      "2025-12-18T22:04:34: #10 179.1     Found existing installation: fsspec 2025.12.0\n",
      "2025-12-18T22:04:34: #10 179.1     Uninstalling fsspec-2025.12.0:\n",
      "2025-12-18T22:04:34: #10 179.1       Successfully uninstalled fsspec-2025.12.0\n",
      "2025-12-18T22:04:34: #10 179.1 \n",
      "2025-12-18T22:04:34: #10 179.1 Successfully installed Mako-1.3.10 PyJWT-2.10.1 PySocks-1.7.1 SecretStorage-3.5.0 adal-1.2.7 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 alembic-1.17.2 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.12.0 argcomplete-3.6.3 asgiref-3.11.0 async-timeout-5.0.1 attrs-25.4.0 azure-ai-ml-1.30.0 azure-common-1.1.28 azure-core-1.37.0 azure-core-tracing-opentelemetry-1.0.0b12 azure-graphrbac-0.61.2 azure-identity-1.17.0 azure-mgmt-authorization-4.0.0 azure-mgmt-containerregistry-14.0.0 azure-mgmt-core-1.6.0 azure-mgmt-keyvault-11.0.0 azure-mgmt-network-30.0.0 azure-mgmt-resource-24.0.0 azure-mgmt-storage-24.0.0 azure-monitor-opentelemetry-1.6.7 azure-monitor-opentelemetry-exporter-1.0.0b40 azure-storage-blob-12.19.0 azure-storage-file-datalake-12.14.0 azure-storage-file-share-12.23.1 azureml-core-1.61.0.post1 azureml-dataprep-5.4.2 azureml-dataprep-native-42.1.0 azureml-dataprep-rslex-2.25.2 azureml-dataset-runtime-1.61.0 azureml-defaults-1.61.0 azureml-inference-server-http-1.5.1 azureml-mlflow-1.60.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-5.0.0 blinker-1.9.0 cachetools-6.2.4 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 cloudpickle-2.2.1 colorama-0.4.6 coloredlogs-15.0.1 contextlib2-21.6.0 contourpy-1.3.2 cryptography-46.0.3 cycler-0.12.1 databricks-sdk-0.76.0 datasets-4.0.0 deprecated-1.3.1 dill-0.3.8 docker-7.1.0 exceptiongroup-1.3.1 fastapi-0.125.0 fixedint-0.1.6 flask-3.1.2 flask-cors-6.0.2 flatbuffers-25.9.23 fonttools-4.61.1 frozenlist-1.8.0 fsspec-2025.3.0 fusepy-3.0.1 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.45.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 greenlet-3.3.0 gunicorn-23.0.0 h11-0.16.0 hf-xet-1.2.0 huey-2.5.5 huggingface-hub-0.36.0 humanfriendly-10.0 idna-3.11 importlib-metadata-8.6.1 inference-schema-1.8 isodate-0.7.2 itsdangerous-2.2.0 jeepney-0.9.0 jmespath-1.0.1 joblib-1.5.3 jsonpickle-4.1.1 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kiwisolver-1.4.9 knack-0.12.0 marshmallow-3.26.1 matplotlib-3.10.8 ml_dtypes-0.5.4 mlflow-3.7.0 mlflow-skinny-3.7.0 mlflow-tracing-3.7.0 msal-1.34.0 msal-extensions-1.3.1 msrest-0.7.1 msrestazure-0.6.4.post1 multidict-6.7.0 multiprocess-0.70.16 ndg-httpsclient-0.5.1 numpy-1.26.4 oauthlib-3.3.1 onnx-1.20.0 onnx_ir-0.1.13 onnxruntime-1.23.2 onnxscript-0.5.7 opentelemetry-api-1.33.0 opentelemetry-instrumentation-0.54b0 opentelemetry-instrumentation-asgi-0.54b0 opentelemetry-instrumentation-dbapi-0.54b0 opentelemetry-instrumentation-django-0.54b0 opentelemetry-instrumentation-fastapi-0.54b0 opentelemetry-instrumentation-flask-0.54b0 opentelemetry-instrumentation-psycopg2-0.54b0 opentelemetry-instrumentation-requests-0.54b0 opentelemetry-instrumentation-urllib-0.54b0 opentelemetry-instrumentation-urllib3-0.54b0 opentelemetry-instrumentation-wsgi-0.54b0 opentelemetry-proto-1.39.1 opentelemetry-resource-detector-azure-0.1.5 opentelemetry-sdk-1.33.0 opentelemetry-semantic-conventions-0.54b0 opentelemetry-util-http-0.54b0 packaging-25.0 pandas-2.3.3 paramiko-3.5.1 pathspec-0.12.1 pillow-12.0.0 pkginfo-1.12.1.2 propcache-0.4.1 protobuf-6.33.2 psutil-7.1.3 pyarrow-20.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.23 pydantic-2.12.5 pydantic-core-2.41.5 pydantic-settings-2.12.0 pydash-8.0.5 pygments-2.19.2 pynacl-1.6.1 pyopenssl-25.3.0 pyparsing-3.2.5 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 pytz-2025.2 pyyaml-6.0.3 referencing-0.37.0 regex-2025.11.3 requests-2.32.5 requests-oauthlib-2.0.0 rpds-py-0.30.0 rsa-4.9.1 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 sentencepiece-0.2.1 seqeval-1.2.2 six-1.17.0 smmap-5.0.2 sqlalchemy-2.0.45 sqlparse-0.5.4 starlette-0.50.0 strictyaml-1.7.3 tabulate-0.9.0 threadpoolctl-3.6.0 tokenizers-0.22.1 tomli-2.3.0 tqdm-4.67.1 transformers-4.57.3 typing-inspection-0.4.2 tzdata-2025.3 urllib3-2.6.2 uvicorn-0.38.0 werkzeug-3.1.4 wrapt-1.16.0 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0\n",
      "2025-12-18T22:04:34: #10 179.1 \n",
      "2025-12-18T22:04:34: #10 179.done\n",
      "2025-12-18T22:04:34: #10 179.1 #\n",
      "2025-12-18T22:04:34: #10 179.1 # To activate this environment, use\n",
      "2025-12-18T22:04:34: #10 179.1 #\n",
      "2025-12-18T22:04:34: #10 179.1 #     $ conda activate /azureml-envs/azureml_d814665c2345be6bee20d6b8bc278ede\n",
      "2025-12-18T22:04:34: #10 179.1 #\n",
      "2025-12-18T22:04:34: #10 179.1 # To deactivate an active environment, use\n",
      "2025-12-18T22:04:34: #10 179.1 #\n",
      "2025-12-18T22:04:34: #10 179.1 #     $ conda deactivate\n",
      "2025-12-18T22:04:34: #10 179.1 \n",
      "2025-12-18T22:04:39: #10 DONE 184.1s\n",
      "\n",
      "2025-12-18T22:04:39: #11 [ 7/10] COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      "2025-12-18T22:04:39: #11 DONE 0.2s\n",
      "\n",
      "2025-12-18T22:04:39: #12 [ 8/10] RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      "2025-12-18T22:04:39: #12 DONE 0.3s\n",
      "\n",
      "2025-12-18T22:04:39: #13 [ 9/10] RUN rm -rf azureml-environment-setup\n",
      "2025-12-18T22:04:39: #13 DONE 0.3s\n",
      "\n",
      "2025-12-18T22:04:40: #14 exporting to image\n",
      "2025-12-18T22:04:40: #14 exporting layers\n",
      "2025-12-18T22:05:03: #14 exporting layers 23.4s done\n",
      "2025-12-18T22:05:03: #14 writing image sha256:c77bef2d0f69209110be941b3a1e2436a2336fb75122db2996f1755aa406fab5 done\n",
      "2025-12-18T22:05:03: #14 naming to b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_f7da780250c27339c3dcc717184b56bf done\n",
      "2025-12-18T22:05:03: #14 naming to b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_f7da780250c27339c3dcc717184b56bf:1 done\n",
      "2025-12-18T22:05:03: #14 DONE 23.5s\n",
      "\n",
      "\n",
      "2025-12-18T22:05:03: Logging into Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-18T22:05:03: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "2025-12-18T22:05:03: Login Succeeded\n",
      "\n",
      "\n",
      "2025-12-18T22:05:03: Using default tag: latest\n",
      "2025-12-18T22:05:03: The push refers to repository [b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_f7da780250c27339c3dcc717184b56bf]\n",
      "2025-12-18T22:05:03: 5eab06764372: Preparing\n",
      "2025-12-18T22:05:03: 5f70bf18a086: Preparing\n",
      "2025-12-18T22:05:03: b836e3b95fd0: Preparing\n",
      "2025-12-18T22:05:03: c2ff616f70c8: Preparing\n",
      "2025-12-18T22:05:03: dc7e2d9f0702: Preparing\n",
      "2025-12-18T22:05:03: 1d980516c1dc: Preparing\n",
      "2025-12-18T22:05:03: 097774b9466f: Preparing\n",
      "2025-12-18T22:05:03: 5f70bf18a086: Preparing\n",
      "2025-12-18T22:05:03: 6b0c1cfc8f15: Preparing\n",
      "2025-12-18T22:05:03: d0b10cfca986: Preparing\n",
      "2025-12-18T22:05:03: 2baf6d5fcdda: Preparing\n",
      "2025-12-18T22:05:03: 947277ce5638: Preparing\n",
      "2025-12-18T22:05:03: 2ea0beed9e18: Preparing\n",
      "2025-12-18T22:05:03: 1d980516c1dc: Waiting\n",
      "2025-12-18T22:05:03: 7d3ba5b124ef: Preparing\n",
      "2025-12-18T22:05:03: 097774b9466f: Waiting\n",
      "2025-12-18T22:05:03: cd1cc5cf0a38: Preparing\n",
      "2025-12-18T22:05:03: fa26ceb8799b: Preparing\n",
      "2025-12-18T22:05:03: 44bfba9b2552: Preparing\n",
      "2025-12-18T22:05:03: fffe76c64ef2: Preparing\n",
      "2025-12-18T22:05:03: 6b0c1cfc8f15: Waiting\n",
      "2025-12-18T22:05:03: d0b10cfca986: Waiting\n",
      "2025-12-18T22:05:03: 2baf6d5fcdda: Waiting\n",
      "2025-12-18T22:05:03: 947277ce5638: Waiting\n",
      "2025-12-18T22:05:03: 2ea0beed9e18: Waiting\n",
      "2025-12-18T22:05:03: 7d3ba5b124ef: Waiting\n",
      "2025-12-18T22:05:03: cd1cc5cf0a38: Waiting\n",
      "2025-12-18T22:05:03: fa26ceb8799b: Waiting\n",
      "2025-12-18T22:05:03: 44bfba9b2552: Waiting\n",
      "2025-12-18T22:05:03: fffe76c64ef2: Waiting\n",
      "2025-12-18T22:05:03: b836e3b95fd0: Pushed\n",
      "2025-12-18T22:05:03: dc7e2d9f0702: Pushed\n",
      "2025-12-18T22:05:03: 5f70bf18a086: Pushed\n",
      "2025-12-18T22:05:03: 5eab06764372: Pushed\n",
      "2025-12-18T22:05:04: 6b0c1cfc8f15: Pushed\n",
      "2025-12-18T22:05:04: 097774b9466f: Pushed\n",
      "2025-12-18T22:05:04: 1d980516c1dc: Pushed\n",
      "2025-12-18T22:05:04: d0b10cfca986: Pushed\n",
      "2025-12-18T22:05:05: 7d3ba5b124ef: Pushed\n",
      "2025-12-18T22:05:05: 947277ce5638: Pushed\n",
      "2025-12-18T22:05:06: cd1cc5cf0a38: Pushed\n",
      "2025-12-18T22:05:06: fa26ceb8799b: Pushed\n",
      "2025-12-18T22:05:08: 2baf6d5fcdda: Pushed\n",
      "2025-12-18T22:05:11: fffe76c64ef2: Pushed\n",
      "2025-12-18T22:05:21: 2ea0beed9e18: Pushed\n",
      "2025-12-18T22:05:29: 44bfba9b2552: Pushed\n",
      "2025-12-18T22:06:54: c2ff616f70c8: Pushed\n",
      "2025-12-18T22:06:54: latest: digest: sha256:ec2c8bc54d32446790e7edd99db54e89697e727823e63f8be51d72c5600dd29b size: 4092\n",
      "\n",
      "\n",
      "2025-12-18T22:06:55: The push refers to repository [b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_f7da780250c27339c3dcc717184b56bf]\n",
      "2025-12-18T22:06:55: 5eab06764372: Preparing\n",
      "2025-12-18T22:06:55: 5f70bf18a086: Preparing\n",
      "2025-12-18T22:06:55: b836e3b95fd0: Preparing\n",
      "2025-12-18T22:06:55: c2ff616f70c8: Preparing\n",
      "2025-12-18T22:06:55: dc7e2d9f0702: Preparing\n",
      "2025-12-18T22:06:55: 1d980516c1dc: Preparing\n",
      "2025-12-18T22:06:55: 097774b9466f: Preparing\n",
      "2025-12-18T22:06:55: 5f70bf18a086: Preparing\n",
      "2025-12-18T22:06:55: 6b0c1cfc8f15: Preparing\n",
      "2025-12-18T22:06:55: d0b10cfca986: Preparing\n",
      "2025-12-18T22:06:55: 2baf6d5fcdda: Preparing\n",
      "2025-12-18T22:06:55: 947277ce5638: Preparing\n",
      "2025-12-18T22:06:55: 2ea0beed9e18: Preparing\n",
      "2025-12-18T22:06:55: 7d3ba5b124ef: Preparing\n",
      "2025-12-18T22:06:55: cd1cc5cf0a38: Preparing\n",
      "2025-12-18T22:06:55: fa26ceb8799b: Preparing\n",
      "2025-12-18T22:06:55: 44bfba9b2552: Preparing\n",
      "2025-12-18T22:06:55: fffe76c64ef2: Preparing\n",
      "2025-12-18T22:06:55: 2baf6d5fcdda: Waiting\n",
      "2025-12-18T22:06:55: 947277ce5638: Waiting\n",
      "2025-12-18T22:06:55: 2ea0beed9e18: Waiting\n",
      "2025-12-18T22:06:55: 7d3ba5b124ef: Waiting\n",
      "2025-12-18T22:06:55: cd1cc5cf0a38: Waiting\n",
      "2025-12-18T22:06:55: fa26ceb8799b: Waiting\n",
      "2025-12-18T22:06:55: 44bfba9b2552: Waiting\n",
      "2025-12-18T22:06:55: fffe76c64ef2: Waiting\n",
      "2025-12-18T22:06:55: 1d980516c1dc: Waiting\n",
      "2025-12-18T22:06:55: 097774b9466f: Waiting\n",
      "2025-12-18T22:06:55: 6b0c1cfc8f15: Waiting\n",
      "2025-12-18T22:06:55: d0b10cfca986: Waiting\n",
      "2025-12-18T22:06:55: b836e3b95fd0: Layer already exists\n",
      "2025-12-18T22:06:55: c2ff616f70c8: Layer already exists\n",
      "2025-12-18T22:06:55: 5f70bf18a086: Layer already exists\n",
      "2025-12-18T22:06:55: dc7e2d9f0702: Layer already exists\n",
      "2025-12-18T22:06:55: 5eab06764372: Layer already exists\n",
      "2025-12-18T22:06:55: 1d980516c1dc: Layer already exists\n",
      "2025-12-18T22:06:55: 097774b9466f: Layer already exists\n",
      "2025-12-18T22:06:55: d0b10cfca986: Layer already exists\n",
      "2025-12-18T22:06:55: 6b0c1cfc8f15: Layer already exists\n",
      "2025-12-18T22:06:55: 2baf6d5fcdda: Layer already exists\n",
      "2025-12-18T22:06:55: 2ea0beed9e18: Layer already exists\n",
      "2025-12-18T22:06:55: 947277ce5638: Layer already exists\n",
      "2025-12-18T22:06:55: cd1cc5cf0a38: Layer already exists\n",
      "2025-12-18T22:06:55: 7d3ba5b124ef: Layer already exists\n",
      "2025-12-18T22:06:55: fa26ceb8799b: Layer already exists\n",
      "2025-12-18T22:06:55: fffe76c64ef2: Layer already exists\n",
      "2025-12-18T22:06:55: 44bfba9b2552: Layer already exists\n",
      "2025-12-18T22:06:55: 1: digest: sha256:ec2c8bc54d32446790e7edd99db54e89697e727823e63f8be51d72c5600dd29b size: 4092\n",
      "\n",
      "\n",
      "2025-12-18T22:06:55: #### Image for post-processing commands: b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_f7da780250c27339c3dcc717184b56bf:latest\n",
      "2025-12-18T22:06:55: #### Image digest: sha256:ec2c8bc54d32446790e7edd99db54e89697e727823e63f8be51d72c5600dd29b\n",
      "2025-12-18T22:06:55: \n",
      "\n",
      "#### Found send_dependencies.py at: /tmp/tmp0zyr0iby/azureml-environment-setup/send_dependencies.py\n",
      "2025-12-18T22:06:56: #### Attempting to run dependencies script\n",
      "\n",
      "\n",
      "2025-12-18T22:07:01: Report materialized dependencies for the environment\n",
      "2025-12-18T22:07:01: Reading environment context\n",
      "2025-12-18T22:07:01: Exporting conda environment\n",
      "2025-12-18T22:07:01: Sending request with materialized conda environment details\n",
      "2025-12-18T22:07:01: Successfully sent materialized environment dependencies\n",
      "\n",
      "\n",
      "2025-12-18T22:07:01: 43a1dbe9937d7f2f6aa7716c7a033d2ebdfdd0e6fa77be8c025808ab842e3005\n",
      "\n",
      "\n",
      "2025-12-18T22:07:01: #### Cleaning up local image cache\n",
      "2025-12-18T22:07:01: Deleting b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_f7da780250c27339c3dcc717184b56bf from local machine\n",
      "2025-12-18T22:07:01: Error response from daemon: page not found\n",
      "\n",
      "\n",
      "2025-12-18T22:07:01: Logging out of Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-18T22:07:01: Removing login credentials for https://index.docker.io/v1/\n",
      "\n",
      "\n",
      "2025-12-18T22:07:01: Logging out of Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-18T22:07:01: Removing login credentials for https://index.docker.io/v1/\n",
      "\n",
      "\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: serene_machine_vc4bm1gjbp\n",
      "Web View: https://ml.azure.com/runs/serene_machine_vc4bm1gjbp?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from orchestration.environment import (\n",
    "    build_environment_config,\n",
    "    create_training_environment,\n",
    "    prepare_environment_image,\n",
    ")\n",
    "\n",
    "# Build environment configuration from env.yaml (with sensible defaults)\n",
    "env_config = build_environment_config(CONFIG_DIR, configs[\"env\"])\n",
    "\n",
    "# Materialize or fetch the Azure ML Environment\n",
    "training_environment = create_training_environment(ml_client, env_config)\n",
    "\n",
    "# Trigger a small warm-up job so the image is built/cached before real work\n",
    "prepare_environment_image(\n",
    "    ml_client=ml_client,\n",
    "    environment=training_environment,\n",
    "    compute_cluster=configs[\"env\"][\"compute\"][\"training_cluster\"],\n",
    "    env_config=env_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training environment: resume-ner-training vv2f3546327b1fc9ec to training_environment_cache.json\n"
     ]
    }
   ],
   "source": [
    "# Save environment info to a JSON file\n",
    "env_cache_file = Path(\"training_environment_cache.json\")\n",
    "\n",
    "if 'training_environment' in globals() and training_environment is not None:\n",
    "    env_data = {\n",
    "        \"name\": training_environment.name,\n",
    "        \"version\": training_environment.version,\n",
    "    }\n",
    "\n",
    "    save_json(env_cache_file, env_data)\n",
    "    print(f\"Saved training environment: {env_data['name']} v{env_data['version']} to {env_cache_file}\")\n",
    "else:\n",
    "    print(\"No training environment to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training environment: resume-ner-training vv2f3546327b1fc9ec\n",
      "Skipping environment setup - using cached environment\n"
     ]
    }
   ],
   "source": [
    "# Try to reload from cache\n",
    "env_cache_file = Path(\"training_environment_cache.json\")\n",
    "\n",
    "env_data = load_json(env_cache_file, default=None)\n",
    "\n",
    "if env_data is None:\n",
    "    print(f\"Cache file {env_cache_file} not found. Will need to create environment.\")\n",
    "    training_environment = None\n",
    "else:\n",
    "    try:\n",
    "        # Reload Environment object from ML client\n",
    "        training_environment = ml_client.environments.get(\n",
    "            name=env_data[\"name\"],\n",
    "            version=env_data[\"version\"]\n",
    "        )\n",
    "        print(f\"Loaded training environment: {training_environment.name} v{training_environment.version}\")\n",
    "        print(\"Skipping environment setup - using cached environment\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load environment {env_data['name']} v{env_data['version']}: {e}\")\n",
    "        print(\"Will need to create environment again\")\n",
    "        training_environment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.4: The Dry Run\n",
    "\n",
    "Submit a minimal sweep job using `smoke.yaml` to validate the sweep mechanism and pipeline integrity before launching the production HPO sweep.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs import (\n",
    "    create_dry_run_sweep_job_for_backbone,\n",
    "    submit_and_wait_for_job,\n",
    "    validate_sweep_job,\n",
    ")\n",
    "\n",
    "TRAINING_SCRIPT_PATH = Path(\"../src/train.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cluster_name = configs[\"env\"][\"compute\"][\"training_cluster\"]\n",
    "\n",
    "try:\n",
    "    compute_cluster = ml_client.compute.get(compute_cluster_name)\n",
    "    if compute_cluster.provisioning_state != \"Succeeded\":\n",
    "        raise ValueError(f\"Compute cluster not ready: {compute_cluster.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Compute cluster '{compute_cluster_name}' not accessible: {e}\")\n",
    "\n",
    "stage_name = STAGE_SMOKE\n",
    "smoke_hpo_config = configs[\"hpo\"]\n",
    "\n",
    "# Backbones are controlled by the HPO config file (single source of truth)\n",
    "backbone_values = smoke_hpo_config[\"search_space\"][\"backbone\"][\"values\"]\n",
    "\n",
    "dry_run_sweep_jobs = {}\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    aml_experiment_name = build_aml_experiment_name(\n",
    "        experiment_name=experiment_config.name,\n",
    "        stage=stage_name,\n",
    "        backbone=backbone,\n",
    "    )\n",
    "    dry_run_sweep_jobs[backbone] = create_dry_run_sweep_job_for_backbone(\n",
    "        script_path=TRAINING_SCRIPT_PATH,\n",
    "        data_asset=data_asset,\n",
    "        environment=training_environment,\n",
    "        compute_cluster=compute_cluster_name,\n",
    "        backbone=backbone,\n",
    "        smoke_hpo_config=smoke_hpo_config,\n",
    "        configs=configs,\n",
    "        config_metadata=config_metadata,\n",
    "        aml_experiment_name=aml_experiment_name,\n",
    "        stage=stage_name,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for backbone, sweep_job in dry_run_sweep_jobs.items():\n",
    "    completed_job = submit_and_wait_for_job(ml_client, sweep_job)\n",
    "    validate_sweep_job(\n",
    "        job=completed_job,\n",
    "        backbone=backbone,\n",
    "        job_type=\"Dry run sweep\",\n",
    "        ml_client=ml_client,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.5: The Sweep (HPO)\n",
    "\n",
    "Submit a hyperparameter optimization sweep to systematically search for the best model configuration.\n",
    "\n",
    "**Note**: Currently using `smoke.yaml` for demonstration purposes (CPU-only setup). For production with GPU, switch to `prod.yaml` in the configuration.\n",
    "\n",
    "**Platform Adapter Note**: Each training trial in the sweep automatically uses the platform adapter to handle Azure ML-specific concerns. The adapter ensures consistent behavior across all trials regardless of the execution environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs import (\n",
    "    create_hpo_sweep_job_for_backbone,\n",
    "    submit_and_wait_for_job,\n",
    "    validate_sweep_job,\n",
    ")\n",
    "\n",
    "TRAINING_SCRIPT_PATH = Path(\"../src/train.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cluster_name = configs[\"env\"][\"compute\"][\"training_cluster\"]\n",
    "\n",
    "try:\n",
    "    compute_cluster = ml_client.compute.get(compute_cluster_name)\n",
    "    if compute_cluster.provisioning_state != \"Succeeded\":\n",
    "        raise ValueError(f\"Compute cluster not ready: {compute_cluster.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Compute cluster '{compute_cluster_name}' not accessible: {e}\")\n",
    "\n",
    "stage_name = STAGE_HPO\n",
    "hpo_config = configs[\"hpo\"]\n",
    "backbone_values = hpo_config[\"search_space\"][\"backbone\"][\"values\"]\n",
    "hpo_sweep_jobs = {}\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    aml_experiment_name = build_aml_experiment_name(\n",
    "        experiment_name=experiment_config.name,\n",
    "        stage=stage_name,\n",
    "        backbone=backbone,\n",
    "    )\n",
    "    hpo_sweep_jobs[backbone] = create_hpo_sweep_job_for_backbone(\n",
    "        script_path=TRAINING_SCRIPT_PATH,\n",
    "        data_asset=data_asset,\n",
    "        environment=training_environment,\n",
    "        compute_cluster=compute_cluster_name,\n",
    "        hpo_config=hpo_config,\n",
    "        backbone=backbone,\n",
    "        aml_experiment_name=aml_experiment_name,\n",
    "        stage=stage_name,\n",
    "        configs=configs,\n",
    "        config_metadata=config_metadata,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading resume-ner-azureml (0.24 MBs): 100%|##########| 236343/236343 [00:01<00:00, 144636.43it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: willing_kale_dm5y8fsvgg\n",
      "Web View: https://ml.azure.com/runs/willing_kale_dm5y8fsvgg?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "[2025-12-18T22:16:16.3356234Z][GENERATOR][DEBUG]Sampled 2 jobs from search space \n",
      "[2025-12-18T22:16:16.7702030Z][SCHEDULER][INFO]Scheduling job, id='willing_kale_dm5y8fsvgg_0' \n",
      "[2025-12-18T22:16:16.8069831Z][SCHEDULER][INFO]Scheduling job, id='willing_kale_dm5y8fsvgg_1' \n",
      "[2025-12-18T22:16:17.2579734Z][SCHEDULER][INFO]Successfully scheduled a job. Id='willing_kale_dm5y8fsvgg_1' \n",
      "[2025-12-18T22:16:17.4069221Z][SCHEDULER][INFO]Successfully scheduled a job. Id='willing_kale_dm5y8fsvgg_0' \n",
      "[2025-12-18T22:16:46.9511492Z][GENERATOR][DEBUG]Setting all jobs generated as True, reason : Max number of jobs reached \n",
      "[2025-12-18T22:23:49.6296353Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: willing_kale_dm5y8fsvgg\n",
      "Web View: https://ml.azure.com/runs/willing_kale_dm5y8fsvgg?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hpo_completed_jobs = {}\n",
    "\n",
    "for backbone, sweep_job in hpo_sweep_jobs.items():\n",
    "    completed_job = submit_and_wait_for_job(ml_client, sweep_job)\n",
    "    validate_sweep_job(\n",
    "        job=completed_job,\n",
    "        backbone=backbone,\n",
    "        job_type=\"HPO sweep\",\n",
    "        min_expected_trials=2,\n",
    "        ml_client=ml_client,\n",
    "    )\n",
    "    hpo_completed_jobs[backbone] = completed_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 HPO job references to hpo_completed_jobs_cache.json\n"
     ]
    }
   ],
   "source": [
    "# Save HPO job references to a JSON file\n",
    "hpo_jobs_cache_file = Path(\"hpo_completed_jobs_cache.json\")\n",
    "\n",
    "if hpo_completed_jobs:\n",
    "    hpo_jobs_data = {\n",
    "        backbone: {\n",
    "            \"job_name\": job.name,\n",
    "            \"job_id\": job.id,\n",
    "        }\n",
    "        for backbone, job in hpo_completed_jobs.items()\n",
    "    }\n",
    "\n",
    "    save_json(hpo_jobs_cache_file, hpo_jobs_data)\n",
    "    print(f\"Saved {len(hpo_jobs_data)} HPO job references to {hpo_jobs_cache_file}\")\n",
    "else:\n",
    "    print(\"No HPO completed jobs to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HPO job for deberta: willing_kale_dm5y8fsvgg (status: Completed)\n",
      "\n",
      "Successfully reloaded 1 HPO completed jobs from cache\n"
     ]
    }
   ],
   "source": [
    "# Try to reload HPO jobs from cache\n",
    "hpo_jobs_cache_file = Path(\"hpo_completed_jobs_cache.json\")\n",
    "\n",
    "hpo_jobs_data = load_json(hpo_jobs_cache_file, default=None)\n",
    "\n",
    "if hpo_jobs_data is None:\n",
    "    print(f\"Cache file {hpo_jobs_cache_file} not found. Will need to run HPO.\")\n",
    "    hpo_completed_jobs = {}\n",
    "else:\n",
    "    hpo_completed_jobs = {}\n",
    "    for backbone, job_info in hpo_jobs_data.items():\n",
    "        try:\n",
    "            job = ml_client.jobs.get(job_info[\"job_name\"])\n",
    "            hpo_completed_jobs[backbone] = job\n",
    "            print(f\"Loaded HPO job for {backbone}: {job.name} (status: {job.status})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load job {job_info['job_name']} for {backbone}: {e}\")\n",
    "\n",
    "    if hpo_completed_jobs:\n",
    "        print(f\"\\nSuccessfully reloaded {len(hpo_completed_jobs)} HPO completed jobs from cache\")\n",
    "    else:\n",
    "        print(\"No valid jobs found in cache, will need to run HPO again\")\n",
    "        hpo_completed_jobs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.6: Best Configuration Selection (Automated)\n",
    "\n",
    "Programmatically select the best configuration from all HPO sweep runs across all backbone models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs import select_best_configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best configuration from all HPO sweep runs\n",
    "best_configuration = select_best_configuration(\n",
    "    ml_client=ml_client,\n",
    "    hpo_completed_jobs=hpo_completed_jobs,\n",
    "    hpo_config=configs[\"hpo\"],\n",
    "    dataset_version=configs[\"data\"][\"version\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best configuration to best_configuration_cache.json\n",
      "  Backbone: deberta\n",
      "  Best metric value: 0.021546261089987324\n"
     ]
    }
   ],
   "source": [
    "# Save best configuration to a JSON file\n",
    "best_config_cache_file = Path(\"best_configuration_cache.json\")\n",
    "\n",
    "if \"best_configuration\" in globals() and best_configuration is not None:\n",
    "    # best_configuration contains trial_name, trial_id, backbone, hyperparameters, metrics, etc.\n",
    "    # All of these are JSON-serializable\n",
    "    save_json(best_config_cache_file, best_configuration)\n",
    "    print(f\"Saved best configuration to {best_config_cache_file}\")\n",
    "    print(f\"  Backbone: {best_configuration.get('backbone')}\")\n",
    "    print(f\"  Best metric value: {best_configuration.get('selection_criteria', {}).get('best_value')}\")\n",
    "else:\n",
    "    print(\"No best configuration to save\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best configuration from cache:\n",
      "  Backbone: deberta\n",
      "  Trial: willing_kale_dm5y8fsvgg_0\n",
      "  Best metric value: 0.021546261089987324\n",
      "  Dataset version: v2.1\n",
      "\n",
      "Skipping best configuration selection - using cached result\n"
     ]
    }
   ],
   "source": [
    "# Try to reload from cache\n",
    "best_config_cache_file = Path(\"best_configuration_cache.json\")\n",
    "\n",
    "best_configuration = load_json(best_config_cache_file, default=None)\n",
    "\n",
    "if best_configuration is None:\n",
    "    print(f\"Cache file {best_config_cache_file} not found. Will need to run Step P1-3.6.\")\n",
    "else:\n",
    "    print(f\"Loaded best configuration from cache:\")\n",
    "    print(f\"  Backbone: {best_configuration.get('backbone')}\")\n",
    "    print(f\"  Trial: {best_configuration.get('trial_name')}\")\n",
    "    print(f\"  Best metric value: {best_configuration.get('selection_criteria', {}).get('best_value')}\")\n",
    "    print(f\"  Dataset version: {best_configuration.get('dataset_version')}\")\n",
    "    print(f\"\\nSkipping best configuration selection - using cached result\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.7: Final Training (Post-HPO, Single Run)\n",
    "\n",
    "Train the final production model using the best configuration from HPO with stable, controlled conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs import (\n",
    "    build_final_training_config,\n",
    "    create_final_training_job,\n",
    "    validate_final_training_job,\n",
    "    submit_and_wait_for_job\n",
    ")\n",
    "\n",
    "TRAINING_SCRIPT_PATH = Path(\"../src/train.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final training config from best HPO result + train.yaml defaults\n",
    "final_training_config = build_final_training_config(best_configuration, configs[\"train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone': 'deberta',\n",
       " 'learning_rate': '1.0000356121684548',\n",
       " 'dropout': '0.2895659423108745',\n",
       " 'weight_decay': '1.0568946134321513',\n",
       " 'batch_size': 4,\n",
       " 'epochs': 2,\n",
       " 'random_seed': 42,\n",
       " 'early_stopping_enabled': False,\n",
       " 'use_combined_data': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cluster_name = configs[\"env\"][\"compute\"][\"training_cluster\"]\n",
    "\n",
    "try:\n",
    "    compute_cluster = ml_client.compute.get(compute_cluster_name)\n",
    "    if compute_cluster.provisioning_state != \"Succeeded\":\n",
    "        raise ValueError(f\"Compute cluster not ready: {compute_cluster.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Compute cluster '{compute_cluster_name}' not accessible: {e}\")\n",
    "    \n",
    "# Create and submit final training job\n",
    "stage_name = STAGE_TRAINING\n",
    "aml_experiment_name = build_aml_experiment_name(\n",
    "    experiment_name=experiment_config.name,\n",
    "    stage=stage_name,\n",
    "    backbone=final_training_config[\"backbone\"],\n",
    ")\n",
    "\n",
    "final_training_tags = {\n",
    "    **config_metadata,\n",
    "    \"job_type\": \"final_training\",\n",
    "    \"backbone\": final_training_config[\"backbone\"],\n",
    "    \"best_trial\": best_configuration[\"trial_name\"],\n",
    "    \"best_metric_value\": str(best_configuration[\"selection_criteria\"][\"best_value\"]),\n",
    "    \"stage\": stage_name,\n",
    "}\n",
    "\n",
    "final_training_job = create_final_training_job(\n",
    "    script_path=TRAINING_SCRIPT_PATH,\n",
    "    data_asset=data_asset,\n",
    "    environment=training_environment,\n",
    "    compute_cluster=compute_cluster_name,\n",
    "    final_config=final_training_config,\n",
    "    aml_experiment_name=aml_experiment_name,\n",
    "    tags=final_training_tags,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "\u001b[32mUploading resume-ner-azureml (0.24 MBs): 100%|##########| 236755/236755 [00:01<00:00, 142490.40it/s]\n",
      "\u001b[39m\n",
      "\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: jovial_plane_p1804d73rk\n",
      "Web View: https://ml.azure.com/runs/jovial_plane_p1804d73rk?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: jovial_plane_p1804d73rk\n",
      "Web View: https://ml.azure.com/runs/jovial_plane_p1804d73rk?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Submit and validate final training job\n",
    "final_training_completed_job = submit_and_wait_for_job(ml_client, final_training_job)\n",
    "validate_final_training_job(final_training_completed_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final training job reference to final_training_job_cache.json\n"
     ]
    }
   ],
   "source": [
    "final_training_cache_file = Path(\"final_training_job_cache.json\")\n",
    "\n",
    "if \"final_training_completed_job\" in globals() and final_training_completed_job is not None:\n",
    "    data = {\n",
    "        \"job_name\": final_training_completed_job.name,\n",
    "        \"job_id\": final_training_completed_job.id,\n",
    "    }\n",
    "    save_json(final_training_cache_file, data)\n",
    "    print(f\"Saved final training job reference to {final_training_cache_file}\")\n",
    "else:\n",
    "    print(\"No final training job to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded final training job: jovial_plane_p1804d73rk (status: Completed)\n",
      " Training job has checkpoint output\n"
     ]
    }
   ],
   "source": [
    "final_training_cache_file = Path(\"final_training_job_cache.json\")\n",
    "\n",
    "data = load_json(final_training_cache_file, default=None)\n",
    "\n",
    "if data is None:\n",
    "    print(f\"Cache file {final_training_cache_file} not found. Will need to run Step P1-3.7: Final Training.\")\n",
    "    final_training_completed_job = None\n",
    "else:\n",
    "    try:\n",
    "        final_training_completed_job = ml_client.jobs.get(data[\"job_name\"])\n",
    "        print(f\"Loaded final training job: {final_training_completed_job.name} (status: {final_training_completed_job.status})\")\n",
    "        \n",
    "        # Validate that the job has a checkpoint output\n",
    "        if not hasattr(final_training_completed_job, \"outputs\") or \"checkpoint\" not in final_training_completed_job.outputs:\n",
    "            print(f\"\\n  WARNING: Training job {final_training_completed_job.name} does not have a 'checkpoint' output.\")\n",
    "            print(\"   This job cannot be used for model conversion.\")\n",
    "            print(\"   Please re-run Step P1-3.7: Final Training to generate a new job with checkpoint output.\")\n",
    "            final_training_completed_job = None\n",
    "        else:\n",
    "            print(\" Training job has checkpoint output\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not reload final training job {data['job_name']}: {e}\")\n",
    "        final_training_completed_job = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-4: Model Conversion & Optimization\n",
    "\n",
    "Convert the final training checkpoint to an optimized ONNX model (int8 quantized) for production inference.\n",
    "\n",
    "**Platform Adapter Note**: The conversion script (`src/convert_to_onnx.py`) uses the platform adapter to:\n",
    "- Resolve checkpoint paths from Azure ML mounted inputs\n",
    "- Handle output paths for the ONNX model (via `AZURE_ML_OUTPUT_onnx_model`)\n",
    "- Manage logging and MLflow context appropriately\n",
    "\n",
    "The adapter automatically detects the Azure ML environment and uses the appropriate implementations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>resume_ner_baseline-training-deberta</td><td>great_giraffe_wjbqltyd3v</td><td>command</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/great_giraffe_wjbqltyd3v?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&amp;tid=e7572e92-7aee-4713-a3c4-ba64888ad45f\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {'learning_rate': '1.0000356121684548', 'batch_size': '4', 'dropout': '0.2895659423108745', 'weight_decay': '1.0568946134321513', 'epochs': '2', 'backbone': 'microsoft/deberta-v3-base'}, 'init': False, 'name': 'great_giraffe_wjbqltyd3v', 'type': 'command', 'status': 'Completed', 'log_files': None, 'description': 'Final production training with best HPO configuration', 'tags': {'data_config_hash': '99115e7d01de0510', 'model_config_hash': '5f90a66353401b44', 'train_config_hash': 'f0c2caf728759868', 'hpo_config_hash': 'b28114c649d43a67', 'env_config_hash': '3e54b931c7640cf2', 'data_version': 'v2.2', 'model_backbone': 'distilbert-base-uncased', 'job_type': 'final_training', 'backbone': 'deberta', 'best_trial': 'willing_kale_dm5y8fsvgg_0', 'best_metric_value': '0.021546261089987324', 'stage': 'training', '_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":0,\"CurrentNodeCount\":2}'}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/longdang193/resume-ner-azureml', 'mlflow.source.git.branch': 'feature/google-colab-compute', 'mlflow.source.git.commit': 'abf08446ea6da3ede1cae3af46194bd646d25e9e', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'cpu-cluster', 'ContentSnapshotId': '23fbb297-6bae-4072-9ef6-f1e80a20da77', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'StartTimeUtc': '2025-12-18 22:27:25', 'EndTimeUtc': '2025-12-18 22:28:54'}, 'print_as_yaml': False, 'id': '/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/jobs/great_giraffe_wjbqltyd3v', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\HOANG PHI LONG DANG\\\\repos\\\\resume-ner-azureml\\\\notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x000002F57530F460>, 'serialize': <msrest.serialization.Serializer object at 0x000002F57530E9B0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'final-training', 'experiment_name': 'resume_ner_baseline-training-deberta', 'compute': 'cpu-cluster', 'services': {'Tracking': {'endpoint': 'azureml://japanwest.api.azureml.ms/mlflow/v1.0/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/great_giraffe_wjbqltyd3v?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/5e79991c1c42a8888c43689351b73e21e7ca7bd77d75cf11e094a28e2b53caa1/dataset_tiny', 'mode': 'ro_mount'}}, 'job_outputs': {'checkpoint': {'type': 'uri_folder', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.great_giraffe_wjbqltyd3v', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x000002F57530CF40>}, 'outputs': {'checkpoint': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x000002F57530E860>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x000002F57530EB30>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'great_giraffe_wjbqltyd3v', 'description': 'Final production training with best HPO configuration', 'tags': {'data_config_hash': '99115e7d01de0510', 'model_config_hash': '5f90a66353401b44', 'train_config_hash': 'f0c2caf728759868', 'hpo_config_hash': 'b28114c649d43a67', 'env_config_hash': '3e54b931c7640cf2', 'data_version': 'v2.2', 'model_backbone': 'distilbert-base-uncased', 'job_type': 'final_training', 'backbone': 'deberta', 'best_trial': 'willing_kale_dm5y8fsvgg_0', 'best_metric_value': '0.021546261089987324', 'stage': 'training', '_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":0,\"CurrentNodeCount\":2}'}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\HOANG PHI LONG DANG\\\\repos\\\\resume-ner-azureml\\\\notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x000002F57530F460>, 'serialize': <msrest.serialization.Serializer object at 0x000002F57530EE60>, 'command': 'python src/train.py --data-asset ${{inputs.data}} --config-dir config --backbone deberta --learning-rate 1.0000356121684548 --batch-size 4 --dropout 0.2895659423108745 --weight-decay 1.0568946134321513 --epochs 2 --random-seed 42 --early-stopping-enabled false --use-combined-data true', 'code': '/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/codes/b0ad6f0c-1f94-455a-9b9c-8ee6a8007a81/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/environments/resume-ner-training/versions/v2f3546327b1fc9ec', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'final-training', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/5e79991c1c42a8888c43689351b73e21e7ca7bd77d75cf11e094a28e2b53caa1/dataset_tiny', 'mode': 'ro_mount'}}, 'outputs': {'checkpoint': {'type': 'uri_folder', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.great_giraffe_wjbqltyd3v', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Completed', 'parameters': {'learning_rate': '1.0000356121684548', 'batch_size': '4', 'dropout': '0.2895659423108745', 'weight_decay': '1.0568946134321513', 'epochs': '2', 'backbone': 'microsoft/deberta-v3-base'}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://japanwest.api.azureml.ms/mlflow/v1.0/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/great_giraffe_wjbqltyd3v?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f', 'type': 'Studio'}}, 'status': 'Completed', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x000002F57530F460>}, 'instance_id': '9abacae0-313d-42d6-8250-aa517ea0e3b7', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'resume-ner-training:v2f3546327b1fc9ec', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': {'job_tier': 'null'}, 'parent_job_name': None, 'swept': False})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_training_completed_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs import (\n",
    "    get_checkpoint_output_from_training_job,\n",
    "    create_conversion_job,\n",
    "    validate_conversion_job,\n",
    "    submit_and_wait_for_job,\n",
    ")\n",
    "\n",
    "CONVERSION_SCRIPT_PATH = Path(\"../src/convert_to_onnx.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrieved checkpoint output: azureml:azureml_great_giraffe_wjbqltyd3v_output_data_checkpoint:1\n"
     ]
    }
   ],
   "source": [
    "# Guard: ensure final_training_completed_job is set and has checkpoint output\n",
    "if \"final_training_completed_job\" not in globals() or final_training_completed_job is None:\n",
    "    raise ValueError(\n",
    "        \"final_training_completed_job is not set. \"\n",
    "        \"Please run Step P1-3.7: Final Training first, or ensure the cached job has a checkpoint output.\"\n",
    "    )\n",
    "\n",
    "# Guard: ensure ml_client is defined (required for fetching checkpoint data asset)\n",
    "if \"ml_client\" not in globals() or ml_client is None:\n",
    "    raise ValueError(\n",
    "        \"ml_client is not defined. \"\n",
    "        \"Please run the cells that set up ml_client (Step P1-3.1) before running this cell.\"\n",
    "    )\n",
    "\n",
    "checkpoint_output = get_checkpoint_output_from_training_job(final_training_completed_job, ml_client=ml_client)\n",
    "print(f\" Retrieved checkpoint output: {checkpoint_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_cluster_name = configs[\"env\"][\"compute\"][\"conversion_cluster\"]\n",
    "conversion_experiment_name = configs[\"env\"][\"logging\"][\"experiment_name\"]\n",
    "\n",
    "conversion_tags = {\n",
    "    **config_metadata,\n",
    "    \"job_type\": \"model_conversion\",\n",
    "    \"backbone\": best_configuration[\"backbone\"],\n",
    "    \"source_training_job\": final_training_completed_job.name,\n",
    "    \"quantization\": \"int8\",\n",
    "}\n",
    "\n",
    "conversion_job = create_conversion_job(\n",
    "    script_path=CONVERSION_SCRIPT_PATH,\n",
    "    checkpoint_uri=str(checkpoint_output),\n",
    "    environment=training_environment,\n",
    "    compute_cluster=conversion_cluster_name,\n",
    "    backbone=best_configuration[\"backbone\"],\n",
    "    experiment_name=conversion_experiment_name,\n",
    "    tags=conversion_tags,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: joyful_gold_m7d3ch3ll8\n",
      "Web View: https://ml.azure.com/runs/joyful_gold_m7d3ch3ll8?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: joyful_gold_m7d3ch3ll8\n",
      "Web View: https://ml.azure.com/runs/joyful_gold_m7d3ch3ll8?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversion_completed_job = submit_and_wait_for_job(ml_client, conversion_job)\n",
    "validate_conversion_job(conversion_completed_job, ml_client=ml_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved conversion job reference to conversion_job_cache.json\n"
     ]
    }
   ],
   "source": [
    "conversion_cache_file = Path(\"conversion_job_cache.json\")\n",
    "\n",
    "if \"conversion_completed_job\" in globals() and conversion_completed_job is not None:\n",
    "    data = {\n",
    "        \"job_name\": conversion_completed_job.name,\n",
    "        \"job_id\": conversion_completed_job.id,\n",
    "    }\n",
    "    save_json(conversion_cache_file, data)\n",
    "    print(f\"Saved conversion job reference to {conversion_cache_file}\")\n",
    "else:\n",
    "    print(\"No conversion job to save\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded conversion job: joyful_gold_m7d3ch3ll8 (status: Completed)\n",
      " Conversion job has ONNX model output\n"
     ]
    }
   ],
   "source": [
    "conversion_cache_file = Path(\"conversion_job_cache.json\")\n",
    "\n",
    "data = load_json(conversion_cache_file, default=None)\n",
    "\n",
    "if data is None:\n",
    "    print(f\"Cache file {conversion_cache_file} not found. Will need to run Step P1-4: Model Conversion.\")\n",
    "    conversion_completed_job = None\n",
    "else:\n",
    "    try:\n",
    "        conversion_completed_job = ml_client.jobs.get(data[\"job_name\"])\n",
    "        print(f\"Loaded conversion job: {conversion_completed_job.name} (status: {conversion_completed_job.status})\")\n",
    "        \n",
    "        # Validate that the job has an onnx_model output\n",
    "        if not hasattr(conversion_completed_job, \"outputs\") or \"onnx_model\" not in conversion_completed_job.outputs:\n",
    "            print(f\"\\n  WARNING: Conversion job {conversion_completed_job.name} does not have an 'onnx_model' output.\")\n",
    "            print(\"   This job cannot be used for model registration.\")\n",
    "            print(\"   Please re-run Step P1-4: Model Conversion to generate a new job with ONNX model output.\")\n",
    "            conversion_completed_job = None\n",
    "        else:\n",
    "            print(\" Conversion job has ONNX model output\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not reload conversion job {data['job_name']}: {e}\")\n",
    "        conversion_completed_job = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-5: Model Registration (The Handover)\n",
    "\n",
    "Register the optimized ONNX model in Azure ML Model Registry with full metadata for production deployment.\n",
    "\n",
    "**Platform Adapter Note**: The conversion job's ONNX model output is automatically handled by the platform adapter. The model path is resolved from the Azure ML job output and registered in the model registry with full traceability back to the training and conversion jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.core.exceptions import ResourceNotFoundError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onnx_model_path(conversion_job: Job) -> str:\n",
    "    \"\"\"\n",
    "    Get ONNX model path from completed conversion job.\n",
    "    \n",
    "    Args:\n",
    "        conversion_job: Completed conversion job\n",
    "        \n",
    "    Returns:\n",
    "        str: ONNX model path (Azure ML datastore URI)\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If ONNX model not found in job outputs\n",
    "    \"\"\"\n",
    "    if not hasattr(conversion_job, \"outputs\") or not conversion_job.outputs:\n",
    "        raise ValueError(\"Conversion job produced no outputs\")\n",
    "    \n",
    "    if \"onnx_model\" not in conversion_job.outputs:\n",
    "        raise ValueError(\"Conversion job missing 'onnx_model' output\")\n",
    "    \n",
    "    onnx_output = conversion_job.outputs[\"onnx_model\"]\n",
    "    \n",
    "    if hasattr(onnx_output, \"path\"):\n",
    "        return onnx_output.path\n",
    "    elif isinstance(onnx_output, str):\n",
    "        return onnx_output\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected ONNX output type: {type(onnx_output)}\")\n",
    "\n",
    "\n",
    "onnx_model_path = get_onnx_model_path(conversion_completed_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_version(best_config: Dict[str, Any], config_hashes: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Compute deterministic model version from configuration hashes.\n",
    "    \n",
    "    Args:\n",
    "        best_config: Best configuration from HPO selection\n",
    "        config_hashes: Configuration hashes dictionary\n",
    "        \n",
    "    Returns:\n",
    "        str: Model version string\n",
    "    \"\"\"\n",
    "    version_components = [\n",
    "        config_hashes[\"data\"],\n",
    "        config_hashes[\"model\"],\n",
    "        config_hashes[\"train\"],\n",
    "        best_config[\"backbone\"],\n",
    "    ]\n",
    "    version_str = \"_\".join(version_components)\n",
    "    version_hash = hashlib.sha256(version_str.encode()).hexdigest()[:CONFIG_HASH_LENGTH]\n",
    "    return f\"v{version_hash}\"\n",
    "\n",
    "\n",
    "model_version = compute_model_version(best_configuration, config_hashes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_production_model(\n",
    "    ml_client: MLClient,\n",
    "    model_name: str,\n",
    "    model_version: str,\n",
    "    model_path: str,\n",
    "    best_config: Dict[str, Any],\n",
    "    configs: Dict[str, Any],\n",
    "    config_metadata: Dict[str, str],\n",
    ") -> Model:\n",
    "    \"\"\"\n",
    "    Register optimized ONNX model in Azure ML Model Registry.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        model_name: Model name in registry\n",
    "        model_version: Model version\n",
    "        model_path: Path to ONNX model (Azure ML datastore URI)\n",
    "        best_config: Best configuration from HPO selection\n",
    "        configs: Configuration dictionaries\n",
    "        config_metadata: Configuration metadata for tagging\n",
    "        \n",
    "    Returns:\n",
    "        Model: Registered model instance\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If model path is invalid\n",
    "    \"\"\"\n",
    "    if not model_path or not model_path.endswith(\".onnx\"):\n",
    "        raise ValueError(f\"Invalid ONNX model path: {model_path}\")\n",
    "    \n",
    "    selection_criteria = best_config[\"selection_criteria\"]\n",
    "    \n",
    "    model_description = (\n",
    "        f\"Production ONNX model for Resume NER. \"\n",
    "        f\"Backbone: {selection_criteria['backbone']}, \"\n",
    "        f\"Metric: {selection_criteria['metric']}={selection_criteria['best_value']:.4f}\"\n",
    "    )\n",
    "    \n",
    "    model_tags = {\n",
    "        **config_metadata,\n",
    "        \"stage\": PROD_STAGE,\n",
    "        \"backbone\": selection_criteria[\"backbone\"],\n",
    "        \"metric\": selection_criteria[\"metric\"],\n",
    "        \"metric_value\": str(selection_criteria[\"best_value\"]),\n",
    "        \"dataset_version\": best_config[\"dataset_version\"],\n",
    "        \"model_format\": \"onnx\",\n",
    "        \"quantization\": \"int8\",\n",
    "        \"source_training_job\": final_training_completed_job.name,\n",
    "        \"source_conversion_job\": conversion_completed_job.name,\n",
    "    }\n",
    "    \n",
    "    model = Model(\n",
    "        name=model_name,\n",
    "        version=model_version,\n",
    "        description=model_description,\n",
    "        path=model_path,\n",
    "        tags=model_tags,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        existing_model = ml_client.models.get(name=model_name, version=model_version)\n",
    "        return existing_model\n",
    "    except ResourceNotFoundError:\n",
    "        return ml_client.models.create_or_update(model)\n",
    "\n",
    "\n",
    "registered_model = register_production_model(\n",
    "    ml_client=ml_client,\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=model_version,\n",
    "    model_path=onnx_model_path,\n",
    "    best_config=best_configuration,\n",
    "    configs=configs,\n",
    "    config_metadata=config_metadata,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_registered_model(model: Model) -> None:\n",
    "    \"\"\"\n",
    "    Validate registered model has required metadata and tags.\n",
    "    \n",
    "    Args:\n",
    "        model: Registered model instance\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If validation fails\n",
    "    \"\"\"\n",
    "    required_tags = [\"stage\", \"backbone\", \"metric\", \"dataset_version\"]\n",
    "    for tag in required_tags:\n",
    "        if tag not in model.tags:\n",
    "            raise ValueError(f\"Registered model missing required tag: {tag}\")\n",
    "    \n",
    "    if model.tags.get(\"stage\") != PROD_STAGE:\n",
    "        raise ValueError(f\"Model stage must be '{PROD_STAGE}', got: {model.tags.get('stage')}\")\n",
    "    \n",
    "    if not model.path or not model.path.endswith(\".onnx\"):\n",
    "        raise ValueError(f\"Invalid model path: {model.path}\")\n",
    "\n",
    "\n",
    "validate_registered_model(registered_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
