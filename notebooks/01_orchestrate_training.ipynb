{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Training Orchestration\n",
    "\n",
    "This notebook orchestrates all training activities without performing local computation.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Step 1**: Load Centralized Configs\n",
    "- **Step 2**: Data Ingestion & Versioning (Asset Layer)\n",
    "- **Step 3**: Environment Definition\n",
    "- **Step 4**: The Dry Run\n",
    "- **Step 5**: The Sweep (HPO)\n",
    "- **Step 6**: Best Configuration Selection (Automated)\n",
    "- **Step 7**: Final Training (Post-HPO, Single Run)\n",
    "\n",
    "## Important\n",
    "\n",
    "- This notebook **only submits and monitors Azure ML jobs**\n",
    "- **No training logic** is executed locally\n",
    "- All computation happens remotely on Azure ML compute\n",
    "- The notebook must be **re-runnable end-to-end**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.1: Load Centralized Configs\n",
    "\n",
    "Load and validate all configuration files. Configs are immutable and will be logged with each job for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import hashlib\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "CONFIG_HASH_LENGTH = 16\n",
    "DEFAULT_WORKSPACE_NAME = \"resume-ner-ws\"\n",
    "\n",
    "env_path = Path(\"../config.env\")\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DIR = Path(\"../config\")\n",
    "\n",
    "# Toggle: use tiny smoke dataset config instead of full dataset\n",
    "# - False: use ../config/data/resume_v1.yaml (full data)\n",
    "# - True:  use ../config/data/resume_tiny.yaml (tiny data generated by 00_make_tiny_dataset.ipynb)\n",
    "USE_TINY_DATA = True\n",
    "\n",
    "DATA_CONFIG_FILENAME = \"resume_tiny.yaml\" if USE_TINY_DATA else \"resume_v1.yaml\"\n",
    "\n",
    "CONFIG_PATHS = {\n",
    "    \"data\": CONFIG_DIR / \"data\" / DATA_CONFIG_FILENAME,\n",
    "    \"model\": CONFIG_DIR / \"model\" / \"distilbert.yaml\",\n",
    "    \"train\": CONFIG_DIR / \"train.yaml\",\n",
    "    \"hpo\": CONFIG_DIR / \"hpo\" / \"smoke.yaml\",\n",
    "    \"env\": CONFIG_DIR / \"env\" / \"azure.yaml\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_config_file(path: Path) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load a YAML config file.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the YAML config file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parsed configuration dictionary\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If config file does not exist\n",
    "    \"\"\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Config file not found: {path}\")\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "def compute_config_hash(config: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Compute SHA256 hash of config for reproducibility.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        str: Hexadecimal hash string (truncated to CONFIG_HASH_LENGTH)\n",
    "    \"\"\"\n",
    "    config_str = json.dumps(config, sort_keys=True)\n",
    "    full_hash = hashlib.sha256(config_str.encode()).hexdigest()\n",
    "    return full_hash[:CONFIG_HASH_LENGTH]\n",
    "\n",
    "\n",
    "configs = {}\n",
    "config_hashes = {}\n",
    "\n",
    "for name, path in CONFIG_PATHS.items():\n",
    "    configs[name] = load_config_file(path)\n",
    "    config_hashes[name] = compute_config_hash(configs[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_configs = {k: json.dumps(v, sort_keys=True) for k, v in configs.items()}\n",
    "\n",
    "\n",
    "def validate_config_immutability():\n",
    "    \"\"\"\n",
    "    Ensure configs haven't been mutated at runtime.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If any config was mutated\n",
    "    \"\"\"\n",
    "    for name in configs:\n",
    "        current = json.dumps(configs[name], sort_keys=True)\n",
    "        if current != original_configs[name]:\n",
    "            raise ValueError(f\"Config '{name}' was mutated at runtime!\")\n",
    "\n",
    "\n",
    "validate_config_immutability()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current LoggerProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "def get_workspace_name() -> str:\n",
    "    \"\"\"\n",
    "    Get workspace name from infrastructure config or use default.\n",
    "    \n",
    "    Returns:\n",
    "        str: Workspace name\n",
    "    \"\"\"\n",
    "    infrastructure_config_path = Path(\"../config/infrastructure.yaml\")\n",
    "    if infrastructure_config_path.exists():\n",
    "        with open(infrastructure_config_path, \"r\") as f:\n",
    "            infrastructure_config = yaml.safe_load(f)\n",
    "        return infrastructure_config[\"workspace\"][\"name\"]\n",
    "    return DEFAULT_WORKSPACE_NAME\n",
    "\n",
    "\n",
    "subscription_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"AZURE_RESOURCE_GROUP\")\n",
    "\n",
    "if not subscription_id or not resource_group:\n",
    "    raise ValueError(\"AZURE_SUBSCRIPTION_ID and AZURE_RESOURCE_GROUP must be set\")\n",
    "\n",
    "workspace_name = get_workspace_name()\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All configs and their hashes will be attached to each Azure ML job for full reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_config_metadata(configs: Dict[str, Any], config_hashes: Dict[str, str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Create metadata dictionary for job tagging.\n",
    "    \n",
    "    Args:\n",
    "        configs: Dictionary of loaded configs\n",
    "        config_hashes: Dictionary of config hashes\n",
    "        \n",
    "    Returns:\n",
    "        dict: Metadata dictionary for Azure ML job tags\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"data_config_hash\": config_hashes[\"data\"],\n",
    "        \"model_config_hash\": config_hashes[\"model\"],\n",
    "        \"train_config_hash\": config_hashes[\"train\"],\n",
    "        \"hpo_config_hash\": config_hashes[\"hpo\"],\n",
    "        \"env_config_hash\": config_hashes[\"env\"],\n",
    "        \"data_version\": configs[\"data\"][\"version\"],\n",
    "        \"model_backbone\": configs[\"model\"][\"backbone\"],\n",
    "    }\n",
    "\n",
    "\n",
    "config_metadata = create_config_metadata(configs, config_hashes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.2: Data Ingestion & Versioning (Asset Layer)\n",
    "\n",
    "Upload dataset to Blob Storage and register as an Azure ML Data Asset for versioned, immutable data access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "import json\n",
    "# Use tiny dataset folder when USE_TINY_DATA is enabled\n",
    "DATASET_LOCAL_PATH = Path(\"../dataset_tiny\" if USE_TINY_DATA else \"../dataset\")\n",
    "DATA_ASSET_NAME = configs[\"data\"][\"name\"]\n",
    "DATA_ASSET_VERSION = configs[\"data\"][\"version\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    \n",
    "DATA_ASSET_OVERRIDE_PATH = None\n",
    "blob_uri = DATA_ASSET_OVERRIDE_PATH or str(DATASET_LOCAL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: re-upload via SDK upload failed: (UserError) A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's data uri cannot be changed. Only tags, description, and isArchived can be updated.\n",
      "Code: UserError\n",
      "Message: A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's data uri cannot be changed. Only tags, description, and isArchived can be updated.\n",
      "Additional Information:Type: ComponentName\n",
      "Info: {\n",
      "    \"value\": \"managementfrontend\"\n",
      "}Type: Correlation\n",
      "Info: {\n",
      "    \"value\": {\n",
      "        \"operation\": \"afdf5679f00efca34d01d40cc0bf32c3\",\n",
      "        \"request\": \"7fca363ca15a2779\"\n",
      "    }\n",
      "}Type: Environment\n",
      "Info: {\n",
      "    \"value\": \"japanwest\"\n",
      "}Type: Location\n",
      "Info: {\n",
      "    \"value\": \"japanwest\"\n",
      "}Type: Time\n",
      "Info: {\n",
      "    \"value\": \"2025-12-15T22:45:02.7724535+00:00\"\n",
      "}Type: InnerError\n",
      "Info: {\n",
      "    \"value\": {\n",
      "        \"code\": \"Immutable\",\n",
      "        \"innerError\": {\n",
      "            \"code\": \"DataVersionPropertyImmutable\",\n",
      "            \"innerError\": null\n",
      "        }\n",
      "    }\n",
      "}Type: MessageFormat\n",
      "Info: {\n",
      "    \"value\": \"A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's {property} cannot be changed. Only tags, description, and isArchived can be updated.\"\n",
      "}Type: MessageParameters\n",
      "Info: {\n",
      "    \"value\": {\n",
      "        \"property\": \"data uri\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def register_data_asset(name: str, version: str, uri: str, description: str) -> Data:\n",
    "    \"\"\"\n",
    "    Register or resolve Azure ML Data Asset (uri_folder type).\n",
    "    \n",
    "    Args:\n",
    "        name: Data asset name\n",
    "        version: Data asset version\n",
    "        uri: Azure ML datastore path\n",
    "        description: Asset description\n",
    "        \n",
    "    Returns:\n",
    "        Data: Registered data asset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        existing_asset = ml_client.data.get(name=name, version=version)\n",
    "        return existing_asset\n",
    "    except Exception:\n",
    "        data_asset = Data(\n",
    "            name=name,\n",
    "            version=version,\n",
    "            description=description,\n",
    "            path=uri,\n",
    "            type=AssetTypes.URI_FOLDER,\n",
    "        )\n",
    "        return ml_client.data.create_or_update(data_asset)\n",
    "\n",
    "\n",
    "data_asset = register_data_asset(\n",
    "    name=DATA_ASSET_NAME,\n",
    "    version=DATA_ASSET_VERSION,\n",
    "    uri=blob_uri,\n",
    "    description=configs[\"data\"][\"description\"],\n",
    ")\n",
    "\n",
    "# Store both asset reference and datastore path for fallback\n",
    "default_datastore = ml_client.datastores.get_default()\n",
    "if \"/paths/\" in data_asset.path:\n",
    "    relative_path = data_asset.path.split(\"/paths/\", 1)[1].rstrip('/')\n",
    "    datastore_path = f\"azureml://datastores/{default_datastore.name}/paths/{relative_path}\"\n",
    "else:\n",
    "    datastore_path = data_asset.path.rstrip('/')\n",
    "\n",
    "asset_reference = f\"azureml:{data_asset.name}:{data_asset.version}\"\n",
    "\n",
    "# Force re-upload/re-register via SDK upload if asset content might be missing\n",
    "FORCE_REUPLOAD_DATA_ASSET = True\n",
    "if FORCE_REUPLOAD_DATA_ASSET:\n",
    "    try:\n",
    "        # Prefer override path if provided; else upload local dataset\n",
    "        path_arg = DATA_ASSET_OVERRIDE_PATH or str(DATASET_LOCAL_PATH)\n",
    "        data_asset = ml_client.data.create_or_update(\n",
    "            Data(\n",
    "                name=DATA_ASSET_NAME,\n",
    "                version=DATA_ASSET_VERSION,\n",
    "                description=configs[\"data\"][\"description\"],\n",
    "                path=path_arg,\n",
    "                type=AssetTypes.URI_FOLDER,\n",
    "            )\n",
    "        )\n",
    "        asset_reference = f\"azureml:{data_asset.name}:{data_asset.version}\"\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "\n",
    "If you encounter `ScriptExecution.StreamAccess.NotFound`, verify that:\n",
    "1. Compute cluster has managed identity assigned\n",
    "2. Managed identity has \"Storage Blob Data Reader\" role on storage account\n",
    "3. Storage account firewall allows Azure services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_data_asset(asset: Data, local_path: Path) -> int:\n",
    "    \"\"\"\n",
    "    Validate data asset: file presence, sample readability, token/label alignment.\n",
    "    \n",
    "    Args:\n",
    "        asset: Registered data asset\n",
    "        local_path: Local dataset path for validation\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of validated samples\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If validation fails\n",
    "    \"\"\"\n",
    "    train_file = local_path / \"train.json\"\n",
    "    if not train_file.exists():\n",
    "        raise ValueError(f\"train.json not found in {local_path}\")\n",
    "    \n",
    "    with open(train_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    if not isinstance(data, list) or len(data) == 0:\n",
    "        raise ValueError(\"train.json must contain a non-empty list\")\n",
    "    \n",
    "    sample = data[0]\n",
    "    required_keys = [\"text\", \"annotations\"]\n",
    "    for key in required_keys:\n",
    "        if key not in sample:\n",
    "            raise ValueError(f\"Sample missing required key: {key}\")\n",
    "    \n",
    "    text = sample[\"text\"]\n",
    "    annotations = sample[\"annotations\"]\n",
    "    \n",
    "    if not isinstance(text, str) or len(text) == 0:\n",
    "        raise ValueError(\"Sample text must be a non-empty string\")\n",
    "    \n",
    "    if not isinstance(annotations, list):\n",
    "        raise ValueError(\"Annotations must be a list\")\n",
    "    \n",
    "    for ann in annotations:\n",
    "        if not isinstance(ann, list) or len(ann) != 3:\n",
    "            raise ValueError(\"Each annotation must be [start, end, entity_type]\")\n",
    "        start, end, entity_type = ann\n",
    "        if not (0 <= start < end <= len(text)):\n",
    "            raise ValueError(f\"Invalid annotation span: [{start}, {end}] for text length {len(text)}\")\n",
    "    \n",
    "    return len(data)\n",
    "\n",
    "\n",
    "validate_data_asset(data_asset, DATASET_LOCAL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.3: Environment Definition\n",
    "\n",
    "Define a stable execution environment (Docker image + Conda dependencies) for consistent behavior across all training jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "ENVIRONMENT_NAME = \"resume-ner-training\"\n",
    "CONDA_ENV_PATH = Path(\"../config/environment/conda.yaml\")\n",
    "# Azure ML OpenMPI base image (lightweight, CPU-compatible)\n",
    "# This base image provides MPI support for Azure ML orchestration\n",
    "# PyTorch and other dependencies are installed via conda.yaml for reproducibility\n",
    "# For GPU compute, use: \"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.1-cuda12.1:latest\"\n",
    "DEFAULT_DOCKER_IMAGE = \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conda_environment(path: Path) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load conda environment definition from YAML file.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to conda environment YAML file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parsed conda environment dictionary\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If conda environment file does not exist\n",
    "    \"\"\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Conda environment file not found: {path}\")\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "def compute_environment_hash(conda_deps: Dict[str, Any], docker_image: str) -> str:\n",
    "    \"\"\"\n",
    "    Compute SHA256 hash of environment definition for versioning.\n",
    "    \n",
    "    Args:\n",
    "        conda_deps: Conda environment dependencies dictionary\n",
    "        docker_image: Docker base image name\n",
    "        \n",
    "    Returns:\n",
    "        str: Hexadecimal hash string (truncated to CONFIG_HASH_LENGTH)\n",
    "    \"\"\"\n",
    "    env_spec = {\n",
    "        \"conda_dependencies\": conda_deps,\n",
    "        \"docker_image\": docker_image,\n",
    "    }\n",
    "    env_str = json.dumps(env_spec, sort_keys=True)\n",
    "    full_hash = hashlib.sha256(env_str.encode()).hexdigest()\n",
    "    return full_hash[:CONFIG_HASH_LENGTH]\n",
    "\n",
    "\n",
    "conda_env = load_conda_environment(CONDA_ENV_PATH)\n",
    "docker_image = DEFAULT_DOCKER_IMAGE\n",
    "environment_hash = compute_environment_hash(conda_env, docker_image)\n",
    "environment_version = f\"v{environment_hash}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_environment(\n",
    "    ml_client: MLClient,\n",
    "    name: str,\n",
    "    version: str,\n",
    "    conda_dependencies: Dict[str, Any],\n",
    "    docker_image: str,\n",
    ") -> Environment:\n",
    "    \"\"\"\n",
    "    Get existing environment or create new one based on hash-based versioning.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        name: Environment name\n",
    "        version: Environment version (hash-based)\n",
    "        conda_dependencies: Conda environment dependencies\n",
    "        docker_image: Docker base image (required by Azure ML)\n",
    "        \n",
    "    Returns:\n",
    "        Environment: Azure ML Environment instance\n",
    "    \"\"\"\n",
    "    try:\n",
    "        existing_env = ml_client.environments.get(name=name, version=version)\n",
    "        return existing_env\n",
    "    except ResourceNotFoundError:\n",
    "        # Create environment from conda file with base image\n",
    "        # Azure ML will install conda dependencies on top of the base image\n",
    "        environment = Environment(\n",
    "            name=name,\n",
    "            version=version,\n",
    "            conda_file=conda_dependencies,\n",
    "            image=docker_image,\n",
    "            description=f\"Training environment for Resume NER (hash: {version})\",\n",
    "        )\n",
    "        return ml_client.environments.create_or_update(environment)\n",
    "\n",
    "\n",
    "training_environment = get_or_create_environment(\n",
    "    ml_client=ml_client,\n",
    "    name=ENVIRONMENT_NAME,\n",
    "    version=environment_version,\n",
    "    conda_dependencies=conda_env,\n",
    "    docker_image=docker_image,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running training jobs, we prepare the environment image by submitting a minimal warm-up job. This ensures:\n",
    "\n",
    "- **Docker image is built and cached** before sweep jobs start\n",
    "- **Prevents timeouts** in sweep jobs that would otherwise wait for image preparation\n",
    "- **Faster subsequent runs** since the image is cached after the first build\n",
    "\n",
    "This step is especially important for the first run when the environment image doesn't exist yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "\u001b[32mUploading src (0.04 MBs): 100%|██████████| 40875/40875 [00:01<00:00, 32782.46it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: placid_rail_m1lnvffzzm\n",
      "Web View: https://ml.azure.com/runs/placid_rail_m1lnvffzzm?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "======Starting Image Build on Compute======\n",
      "The run ID for the image build on compute is imgbldrun_f2f1337\n",
      "Additional logs for the run: https://ml.azure.com/experiments/id/prepare_image/runs/imgbldrun_f2f1337?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f\n",
      "2025-12-15T22:44:55: Logging into Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-15T22:44:55: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "\n",
      "2025-12-15T22:44:55: WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "2025-12-15T22:44:55: Configure a credential helper to remove this warning. See\n",
      "2025-12-15T22:44:55: https://docs.docker.com/go/credential-store/\n",
      "\n",
      "2025-12-15T22:44:55: Login Succeeded\n",
      "\n",
      "\n",
      "2025-12-15T22:44:55: Running: ['docker', 'build', '-f', 'azureml-environment-setup/Dockerfile', '.', '-t', 'b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_b44ed019c07f973190f7a7029235d9d0', '-t', 'b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_b44ed019c07f973190f7a7029235d9d0:1']\n",
      "2025-12-15T22:44:56: #0 building with \"default\" instance using docker driver\n",
      "\n",
      "2025-12-15T22:44:56: #1 [internal] load .dockerignore\n",
      "2025-12-15T22:44:56: #1 transferring context: 2B done\n",
      "2025-12-15T22:44:56: #1 DONE 0.1s\n",
      "\n",
      "2025-12-15T22:44:56: #2 [internal] load build definition from Dockerfile\n",
      "2025-12-15T22:44:56: #2 transferring dockerfile: 1.68kB done\n",
      "2025-12-15T22:44:56: #2 DONE 0.1s\n",
      "\n",
      "2025-12-15T22:44:56: #3 [internal] load metadata for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33\n",
      "2025-12-15T22:44:56: #3 DONE 0.4s\n",
      "\n",
      "2025-12-15T22:44:56: #4 [internal] load build context\n",
      "2025-12-15T22:44:56: #4 transferring context: 1.75kB done\n",
      "2025-12-15T22:44:56: #4 DONE 0.1s\n",
      "\n",
      "2025-12-15T22:44:56: #5 [ 1/10] FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33\n",
      "2025-12-15T22:44:56: #5 resolve mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33 0.0s done\n",
      "2025-12-15T22:44:56: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 6.29MB / 153.10MB 0.2s\n",
      "2025-12-15T22:44:56: #5 sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572 0B / 641.60kB 0.2s\n",
      "2025-12-15T22:44:56: #5 sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33 2.43kB / 2.43kB done\n",
      "2025-12-15T22:44:56: #5 sha256:83631454f85b20f6f2f386c8f58cd8ec885a6b678fcbab1c9a21e1c9ceab4493 9.06kB / 9.06kB done\n",
      "2025-12-15T22:44:56: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 0B / 28.58MB 0.2s\n",
      "2025-12-15T22:44:56: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 26.21MB / 153.10MB 0.3s\n",
      "2025-12-15T22:44:56: #5 sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572 641.60kB / 641.60kB 0.2s done\n",
      "2025-12-15T22:44:56: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 12.66MB / 28.58MB 0.3s\n",
      "2025-12-15T22:44:56: #5 sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 0B / 3.61MB 0.3s\n",
      "2025-12-15T22:44:57: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 46.14MB / 153.10MB 0.4s\n",
      "2025-12-15T22:44:57: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 28.58MB / 28.58MB 0.4s\n",
      "2025-12-15T22:44:57: #5 sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 3.61MB / 3.61MB 0.5s\n",
      "2025-12-15T22:44:57: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 95.42MB / 153.10MB 0.6s\n",
      "2025-12-15T22:44:57: #5 extracting sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1\n",
      "2025-12-15T22:44:57: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 115.34MB / 153.10MB 0.7s\n",
      "2025-12-15T22:44:57: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 28.58MB / 28.58MB 0.6s done\n",
      "2025-12-15T22:44:57: #5 sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 3.61MB / 3.61MB 0.6s done\n",
      "2025-12-15T22:44:57: #5 sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 0B / 169B 0.7s\n",
      "2025-12-15T22:44:57: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 0B / 127.20MB 0.7s\n",
      "2025-12-15T22:44:57: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 132.12MB / 153.10MB 0.8s\n",
      "2025-12-15T22:44:57: #5 sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 169B / 169B 0.7s done\n",
      "2025-12-15T22:44:57: #5 sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 0B / 4.17MB 0.8s\n",
      "2025-12-15T22:44:57: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 147.85MB / 153.10MB 0.9s\n",
      "2025-12-15T22:44:57: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 23.07MB / 127.20MB 0.9s\n",
      "2025-12-15T22:44:57: #5 sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 1.05MB / 4.17MB 0.9s\n",
      "2025-12-15T22:44:57: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 41.94MB / 127.20MB 1.0s\n",
      "2025-12-15T22:44:57: #5 sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 4.17MB / 4.17MB 0.9s done\n",
      "2025-12-15T22:44:57: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 0B / 41.39MB 1.0s\n",
      "2025-12-15T22:44:57: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 60.82MB / 127.20MB 1.1s\n",
      "2025-12-15T22:44:57: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 3.15MB / 41.39MB 1.1s\n",
      "2025-12-15T22:44:57: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 88.08MB / 127.20MB 1.3s\n",
      "2025-12-15T22:44:57: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 37.75MB / 41.39MB 1.3s\n",
      "2025-12-15T22:44:58: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 105.91MB / 127.20MB 1.4s\n",
      "2025-12-15T22:44:58: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 41.39MB / 41.39MB 1.4s\n",
      "2025-12-15T22:44:58: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 126.88MB / 127.20MB 1.5s\n",
      "2025-12-15T22:44:58: #5 extracting sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 1.2s done\n",
      "2025-12-15T22:44:59: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 153.10MB / 153.10MB 2.2s done\n",
      "2025-12-15T22:44:59: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 41.39MB / 41.39MB 2.5s done\n",
      "2025-12-15T22:45:00: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 127.20MB / 127.20MB 3.5s done\n",
      "2025-12-15T22:45:00: #5 sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 0B / 197.03kB 3.6s\n",
      "2025-12-15T22:45:00: #5 sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 0B / 5.71MB 3.6s\n",
      "2025-12-15T22:45:00: #5 sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 197.03kB / 197.03kB 3.7s\n",
      "2025-12-15T22:45:00: #5 sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 5.71MB / 5.71MB 3.7s done\n",
      "2025-12-15T22:45:00: #5 sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 197.03kB / 197.03kB 3.7s done\n",
      "2025-12-15T22:45:00: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 0.1s\n",
      "2025-12-15T22:45:05: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 5.2s\n",
      "2025-12-15T22:45:05: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 5.4s done\n",
      "2025-12-15T22:45:09: #5 extracting sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572\n",
      "2025-12-15T22:45:09: #5 extracting sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572 0.0s done\n",
      "2025-12-15T22:45:09: #5 extracting sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94\n",
      "2025-12-15T22:45:10: #5 extracting sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 0.5s done\n",
      "2025-12-15T22:45:10: #5 extracting sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26\n",
      "2025-12-15T22:45:10: #5 extracting sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 done\n",
      "2025-12-15T22:45:10: #5 extracting sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 0.1s\n",
      "2025-12-15T22:45:14: #5 extracting sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 3.7s done\n",
      "2025-12-15T22:45:16: #5 extracting sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725\n",
      "2025-12-15T22:45:17: #5 extracting sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 0.2s done\n",
      "2025-12-15T22:45:17: #5 extracting sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310\n",
      "2025-12-15T22:45:18: #5 extracting sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 0.5s done\n",
      "2025-12-15T22:45:18: #5 extracting sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba\n",
      "2025-12-15T22:45:18: #5 extracting sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 0.0s done\n",
      "2025-12-15T22:45:18: #5 extracting sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 0.0s done\n",
      "2025-12-15T22:45:19: #5 DONE 22.6s\n",
      "\n",
      "2025-12-15T22:45:19: #6 [ 2/10] RUN mkdir -p $HOME/.cache\n",
      "2025-12-15T22:45:19: #6 DONE 0.3s\n",
      "\n",
      "2025-12-15T22:45:19: #7 [ 3/10] COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      "2025-12-15T22:45:19: #7 DONE 0.1s\n",
      "\n",
      "2025-12-15T22:45:19: #8 [ 4/10] RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      "2025-12-15T22:45:21: #8 DONE 1.7s\n",
      "\n",
      "2025-12-15T22:45:21: #9 [ 5/10] COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      "2025-12-15T22:45:21: #9 DONE 0.1s\n",
      "\n",
      "2025-12-15T22:45:21: #10 [ 6/10] RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_1f436580892771040fea38f34f9600b4 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      "2025-12-15T22:45:23: #10 0.595 Retrieving notices: done\n",
      "2025-12-15T22:45:23: #10 2.109 Channels:\n",
      "2025-12-15T22:45:23: #10 2.109  - pytorch\n",
      "2025-12-15T22:45:23: #10 2.109  - conda-forge\n",
      "2025-12-15T22:45:23: #10 2.109  - defaults\n",
      "2025-12-15T22:45:23: #10 2.109 Platform: linux-64\n",
      "2025-12-15T22:45:37: #10 2.109 Collecting package metadata (repodata.json): ...working... done\n",
      "2025-12-15T22:45:43: #10 16.20 Solving environment: ...working... done\n",
      "2025-12-15T22:45:43: #10 21.87 \n",
      "2025-12-15T22:45:43: #10 21.87 \n",
      "2025-12-15T22:45:43: #10 21.87 ==> WARNING: A newer version of conda exists. <==\n",
      "2025-12-15T22:45:43: #10 21.87     current version: 25.1.1\n",
      "2025-12-15T22:45:43: #10 21.87     latest version: 25.11.1\n",
      "2025-12-15T22:45:43: #10 21.87 \n",
      "2025-12-15T22:45:43: #10 21.87 Please update conda by running\n",
      "2025-12-15T22:45:43: #10 21.87 \n",
      "2025-12-15T22:45:43: #10 21.87     $ conda update -n base -c conda-forge conda\n",
      "2025-12-15T22:45:43: #10 21.87 \n",
      "2025-12-15T22:45:43: #10 21.87 \n",
      "2025-12-15T22:45:43: #10 21.97 \n",
      "2025-12-15T22:45:43: mkl-2025.3.0         | 119.4 MB  |            |   0% \n",
      "2025-12-15T22:45:43: libtorch-2.9.1       | 57.9 MB   |            |   0% \u001b[A\n",
      "2025-12-15T22:45:43: #10 21.97 \n",
      "2025-12-15T22:45:43: python-3.10.19       | 24.1 MB   |            |   0% \u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.97 \n",
      "2025-12-15T22:45:43: #10 21.97 \n",
      "2025-12-15T22:45:43: pytorch-2.9.1        | 20.4 MB   |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.97 \n",
      "2025-12-15T22:45:43: #10 21.97 \n",
      "2025-12-15T22:45:43: #10 21.97 \n",
      "2025-12-15T22:45:43: numpy-2.2.6          | 7.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: llvm-openmp-21.1.7   | 5.8 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: libstdcxx-15.2.0     | 5.6 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: libprotobuf-6.31.1   | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: sympy-1.14.0         | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: tk-8.6.13            | 3.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: openssl-3.6.0        | 3.0 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: libhwloc-2.12.1      | 2.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: sleef-3.9.0          | 1.9 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: libabseil-20250512.1 | 1.2 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: networkx-3.4.2       | 1.2 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: pip-25.3             | 1.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: libgcc-15.2.0        | 1018 KB   |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: libsqlite-3.51.1     | 917 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: libuv-1.51.0         | 874 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: #10 21.98 \n",
      "2025-12-15T22:45:43: mkl-2025.3.0         | 119.4 MB  | 6          |   6% \n",
      "2025-12-15T22:45:43: #10 22.07 \n",
      "2025-12-15T22:45:43: python-3.10.19       | 24.1 MB   | 8          |   9% \u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 22.10 \n",
      "2025-12-15T22:45:43: #10 22.10 \n",
      "2025-12-15T22:45:43: #10 22.10 \n",
      "2025-12-15T22:45:43: mkl-2025.3.0         | 119.4 MB  | #2         |  12% \n",
      "2025-12-15T22:45:43: #10 22.17 \n",
      "2025-12-15T22:45:43: #10 22.17 \n",
      "2025-12-15T22:45:43: pytorch-2.9.1        | 20.4 MB   |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 22.17 \n",
      "2025-12-15T22:45:43: python-3.10.19       | 24.1 MB   | ###8       |  39% \u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 22.20 \n",
      "2025-12-15T22:45:43: #10 22.20 \n",
      "2025-12-15T22:45:43: #10 22.20 \n",
      "2025-12-15T22:45:43: numpy-2.2.6          | 7.5 MB    | ######6    |  67% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: libtorch-2.9.1       | 57.9 MB   |            |   0% \u001b[A\n",
      "2025-12-15T22:45:43: #10 22.27 \n",
      "2025-12-15T22:45:43: #10 22.27 \n",
      "2025-12-15T22:45:43: pytorch-2.9.1        | 20.4 MB   | #5         |  16% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: libtorch-2.9.1       | 57.9 MB   | 5          |   5% \u001b[A\n",
      "2025-12-15T22:45:43: #10 22.33 \n",
      "2025-12-15T22:45:43: python-3.10.19       | 24.1 MB   | ######     |  60% \u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 22.37 \n",
      "2025-12-15T22:45:43: #10 22.37 \n",
      "2025-12-15T22:45:43: mkl-2025.3.0         | 119.4 MB  | #8         |  18% \n",
      "2025-12-15T22:45:43: libtorch-2.9.1       | 57.9 MB   | #1         |  11% \u001b[A\n",
      "2025-12-15T22:45:43: #10 22.45 \n",
      "2025-12-15T22:45:43: python-3.10.19       | 24.1 MB   | #######7   |  78% \u001b[A\u001b[A\n",
      "2025-12-15T22:45:43: #10 22.47 \n",
      "2025-12-15T22:45:43: #10 22.47 \n",
      "2025-12-15T22:45:43: #10 22.47 \n",
      "2025-12-15T22:45:44: numpy-2.2.6          | 7.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: #10 22.47 \n",
      "2025-12-15T22:45:44: #10 22.47 \n",
      "2025-12-15T22:45:44: pytorch-2.9.1        | 20.4 MB   | ####9      |  50% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: libtorch-2.9.1       | 57.9 MB   | #7         |  17% \u001b[A\n",
      "2025-12-15T22:45:44: #10 22.52 \n",
      "2025-12-15T22:45:44: #10 22.52 \n",
      "2025-12-15T22:45:44: #10 22.52 \n",
      "2025-12-15T22:45:44: #10 22.52 \n",
      "2025-12-15T22:45:44: mkl-2025.3.0         | 119.4 MB  | ##3        |  23% \n",
      "2025-12-15T22:45:44: #10 22.59 \n",
      "2025-12-15T22:45:44: #10 22.59 \n",
      "2025-12-15T22:45:44: pytorch-2.9.1        | 20.4 MB   | ######3    |  64% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: #10 22.59 \n",
      "2025-12-15T22:45:44: python-3.10.19       | 24.1 MB   | #########4 |  94% \u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: libtorch-2.9.1       | 57.9 MB   | ##2        |  22% \u001b[A\n",
      "2025-12-15T22:45:44: #10 22.62 \n",
      "2025-12-15T22:45:44: #10 22.62 \n",
      "2025-12-15T22:45:44: #10 22.62 \n",
      "2025-12-15T22:45:44: #10 22.62 \n",
      "2025-12-15T22:45:44: llvm-openmp-21.1.7   | 5.8 MB    | ####4      |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: #10 22.70 \n",
      "2025-12-15T22:45:44: #10 22.70 \n",
      "2025-12-15T22:45:44: pytorch-2.9.1        | 20.4 MB   | #######7   |  77% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: libtorch-2.9.1       | 57.9 MB   | ##6        |  27% \u001b[A\n",
      "2025-12-15T22:45:44: #10 22.72 \n",
      "2025-12-15T22:45:44: #10 22.72 \n",
      "2025-12-15T22:45:44: #10 22.72 \n",
      "2025-12-15T22:45:44: #10 22.72 \n",
      "2025-12-15T22:45:44: mkl-2025.3.0         | 119.4 MB  | ##6        |  27% \n",
      "2025-12-15T22:45:44: #10 22.80 \n",
      "2025-12-15T22:45:44: #10 22.80 \n",
      "2025-12-15T22:45:44: pytorch-2.9.1        | 20.4 MB   | #########2 |  93% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: mkl-2025.3.0         | 119.4 MB  | ###        |  30% \n",
      "2025-12-15T22:45:44: #10 22.88 \n",
      "2025-12-15T22:45:44: #10 22.88 \n",
      "2025-12-15T22:45:44: #10 22.88 \n",
      "2025-12-15T22:45:44: #10 22.88 \n",
      "2025-12-15T22:45:44: llvm-openmp-21.1.7   | 5.8 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: libtorch-2.9.1       | 57.9 MB   | ###8       |  38% \u001b[A\n",
      "2025-12-15T22:45:44: #10 22.93 \n",
      "2025-12-15T22:45:44: #10 22.93 \n",
      "2025-12-15T22:45:44: #10 22.93 \n",
      "2025-12-15T22:45:44: #10 22.93 \n",
      "2025-12-15T22:45:44: #10 22.93 \n",
      "2025-12-15T22:45:44: mkl-2025.3.0         | 119.4 MB  | ###3       |  33% \n",
      "2025-12-15T22:45:44: libtorch-2.9.1       | 57.9 MB   | ####3      |  43% \u001b[A\n",
      "2025-12-15T22:45:44: #10 23.03 \n",
      "2025-12-15T22:45:44: #10 23.03 \n",
      "2025-12-15T22:45:44: #10 23.03 \n",
      "2025-12-15T22:45:44: #10 23.03 \n",
      "2025-12-15T22:45:44: #10 23.03 \n",
      "2025-12-15T22:45:44: mkl-2025.3.0         | 119.4 MB  | ###6       |  36% \n",
      "2025-12-15T22:45:44: mkl-2025.3.0         | 119.4 MB  | ###9       |  39% \n",
      "2025-12-15T22:45:44: libtorch-2.9.1       | 57.9 MB   | #####5     |  55% \u001b[A\n",
      "2025-12-15T22:45:44: #10 23.27 \n",
      "2025-12-15T22:45:44: #10 23.27 \n",
      "2025-12-15T22:45:44: #10 23.27 \n",
      "2025-12-15T22:45:44: #10 23.27 \n",
      "2025-12-15T22:45:44: #10 23.27 \n",
      "2025-12-15T22:45:44: libstdcxx-15.2.0     | 5.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: #10 23.27 \n",
      "2025-12-15T22:45:44: #10 23.27 \n",
      "2025-12-15T22:45:44: #10 23.27 \n",
      "2025-12-15T22:45:44: #10 23.27 \n",
      "2025-12-15T22:45:44: #10 23.27 \n",
      "2025-12-15T22:45:44: mkl-2025.3.0         | 119.4 MB  | ####2      |  42% \n",
      "2025-12-15T22:45:44: #10 23.32 \n",
      "2025-12-15T22:45:44: #10 23.32 \n",
      "2025-12-15T22:45:44: #10 23.32 \n",
      "2025-12-15T22:45:44: #10 23.32 \n",
      "2025-12-15T22:45:44: #10 23.32 \n",
      "2025-12-15T22:45:44: #10 23.32 \n",
      "2025-12-15T22:45:44: libprotobuf-6.31.1   | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: mkl-2025.3.0         | 119.4 MB  | ####5      |  45% \n",
      "2025-12-15T22:45:44: #10 23.41 \n",
      "2025-12-15T22:45:44: python-3.10.19       | 24.1 MB   | ########## | 100% \u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: #10 23.42 \n",
      "2025-12-15T22:45:44: #10 23.42 \n",
      "2025-12-15T22:45:44: #10 23.42 \n",
      "2025-12-15T22:45:44: #10 23.42 \n",
      "2025-12-15T22:45:44: #10 23.42 \n",
      "2025-12-15T22:45:44: #10 23.42 \n",
      "2025-12-15T22:45:44: libprotobuf-6.31.1   | 4.4 MB    | ######1    |  62% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: libtorch-2.9.1       | 57.9 MB   | ######6    |  66% \u001b[A\n",
      "2025-12-15T22:45:44: #10 23.46 \n",
      "2025-12-15T22:45:44: #10 23.46 \n",
      "2025-12-15T22:45:44: #10 23.46 \n",
      "2025-12-15T22:45:44: #10 23.46 \n",
      "2025-12-15T22:45:44: #10 23.46 \n",
      "2025-12-15T22:45:44: #10 23.46 \n",
      "2025-12-15T22:45:44: #10 23.46 \n",
      "2025-12-15T22:45:44: sympy-1.14.0         | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:44: #10 23.52 \n",
      "2025-12-15T22:45:44: #10 23.52 \n",
      "2025-12-15T22:45:45: mkl-2025.3.0         | 119.4 MB  | ####8      |  48% \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: sympy-1.14.0         | 4.4 MB    | ######1    |  62% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: #10 23.56 \n",
      "2025-12-15T22:45:45: tk-8.6.13            | 3.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: libtorch-2.9.1       | 57.9 MB   | #######1   |  71% \u001b[A\n",
      "2025-12-15T22:45:45: #10 23.64 \n",
      "2025-12-15T22:45:45: #10 23.64 \n",
      "2025-12-15T22:45:45: #10 23.64 \n",
      "2025-12-15T22:45:45: #10 23.64 \n",
      "2025-12-15T22:45:45: #10 23.64 \n",
      "2025-12-15T22:45:45: #10 23.64 \n",
      "2025-12-15T22:45:45: libprotobuf-6.31.1   | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 23.65 \n",
      "2025-12-15T22:45:45: #10 23.65 \n",
      "2025-12-15T22:45:45: #10 23.65 \n",
      "2025-12-15T22:45:45: #10 23.65 \n",
      "2025-12-15T22:45:45: #10 23.65 \n",
      "2025-12-15T22:45:45: #10 23.65 \n",
      "2025-12-15T22:45:45: mkl-2025.3.0         | 119.4 MB  | #####      |  51% \n",
      "2025-12-15T22:45:45: #10 23.66 \n",
      "2025-12-15T22:45:45: #10 23.66 \n",
      "2025-12-15T22:45:45: #10 23.66 \n",
      "2025-12-15T22:45:45: #10 23.66 \n",
      "2025-12-15T22:45:45: #10 23.66 \n",
      "2025-12-15T22:45:45: #10 23.66 \n",
      "2025-12-15T22:45:45: #10 23.66 \n",
      "2025-12-15T22:45:45: #10 23.66 \n",
      "2025-12-15T22:45:45: tk-8.6.13            | 3.1 MB    | ########6  |  87% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: libtorch-2.9.1       | 57.9 MB   | #######6   |  76% \u001b[A\n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: openssl-3.6.0        | 3.0 MB    |            |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: #10 23.69 \n",
      "2025-12-15T22:45:45: mkl-2025.3.0         | 119.4 MB  | #####3     |  53% \n",
      "2025-12-15T22:45:45: libtorch-2.9.1       | 57.9 MB   | ########1  |  81% \u001b[A\n",
      "2025-12-15T22:45:45: #10 23.79 \n",
      "2025-12-15T22:45:45: #10 23.79 \n",
      "2025-12-15T22:45:45: #10 23.79 \n",
      "2025-12-15T22:45:45: #10 23.79 \n",
      "2025-12-15T22:45:45: #10 23.79 \n",
      "2025-12-15T22:45:45: #10 23.79 \n",
      "2025-12-15T22:45:45: #10 23.79 \n",
      "2025-12-15T22:45:45: #10 23.79 \n",
      "2025-12-15T22:45:45: #10 23.79 \n",
      "2025-12-15T22:45:45: openssl-3.6.0        | 3.0 MB    | #########3 |  93% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: #10 23.80 \n",
      "2025-12-15T22:45:45: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 23.81 \n",
      "2025-12-15T22:45:45: #10 23.81 \n",
      "2025-12-15T22:45:45: #10 23.81 \n",
      "2025-12-15T22:45:45: #10 23.81 \n",
      "2025-12-15T22:45:45: #10 23.81 \n",
      "2025-12-15T22:45:45: #10 23.81 \n",
      "2025-12-15T22:45:45: #10 23.81 \n",
      "2025-12-15T22:45:45: #10 23.81 \n",
      "2025-12-15T22:45:45: tk-8.6.13            | 3.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 23.84 \n",
      "2025-12-15T22:45:45: #10 23.84 \n",
      "2025-12-15T22:45:45: #10 23.84 \n",
      "2025-12-15T22:45:45: #10 23.84 \n",
      "2025-12-15T22:45:45: #10 23.84 \n",
      "2025-12-15T22:45:45: #10 23.84 \n",
      "2025-12-15T22:45:45: #10 23.84 \n",
      "2025-12-15T22:45:45: #10 23.84 \n",
      "2025-12-15T22:45:45: #10 23.84 \n",
      "2025-12-15T22:45:45: #10 23.84 \n",
      "2025-12-15T22:45:45: libhwloc-2.12.1      | 2.3 MB    |            |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 23.85 \n",
      "2025-12-15T22:45:45: #10 23.85 \n",
      "2025-12-15T22:45:45: #10 23.85 \n",
      "2025-12-15T22:45:45: #10 23.85 \n",
      "2025-12-15T22:45:45: #10 23.85 \n",
      "2025-12-15T22:45:45: #10 23.85 \n",
      "2025-12-15T22:45:45: #10 23.85 \n",
      "2025-12-15T22:45:45: #10 23.85 \n",
      "2025-12-15T22:45:45: #10 23.85 \n",
      "2025-12-15T22:45:45: #10 23.85 \n",
      "2025-12-15T22:45:45: #10 23.85 \n",
      "2025-12-15T22:45:45: mkl-2025.3.0         | 119.4 MB  | #####5     |  56% \n",
      "2025-12-15T22:45:45: libtorch-2.9.1       | 57.9 MB   | ########6  |  86% \u001b[A\n",
      "2025-12-15T22:45:45: #10 23.91 \n",
      "2025-12-15T22:45:45: #10 23.91 \n",
      "2025-12-15T22:45:45: #10 23.91 \n",
      "2025-12-15T22:45:45: #10 23.91 \n",
      "2025-12-15T22:45:45: #10 23.91 \n",
      "2025-12-15T22:45:45: #10 23.91 \n",
      "2025-12-15T22:45:45: #10 23.91 \n",
      "2025-12-15T22:45:45: #10 23.91 \n",
      "2025-12-15T22:45:45: #10 23.91 \n",
      "2025-12-15T22:45:45: openssl-3.6.0        | 3.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: #10 23.97 \n",
      "2025-12-15T22:45:45: mkl-2025.3.0         | 119.4 MB  | #####7     |  58% \n",
      "2025-12-15T22:45:45: libtorch-2.9.1       | 57.9 MB   | #########  |  91% \u001b[A\n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: #10 24.00 \n",
      "2025-12-15T22:45:45: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: #10 24.02 \n",
      "2025-12-15T22:45:45: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: #10 24.04 \n",
      "2025-12-15T22:45:45: networkx-3.4.2       | 1.2 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: pip-25.3             | 1.1 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: #10 24.06 \n",
      "2025-12-15T22:45:45: mkl-2025.3.0         | 119.4 MB  | ######     |  60% \n",
      "2025-12-15T22:45:45: libtorch-2.9.1       | 57.9 MB   | #########5 |  95% \u001b[A\n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: #10 24.11 \n",
      "2025-12-15T22:45:45: libgcc-15.2.0        | 1018 KB   | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: #10 24.14 \n",
      "2025-12-15T22:45:45: networkx-3.4.2       | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: #10 24.15 \n",
      "2025-12-15T22:45:45: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: #10 24.18 \n",
      "2025-12-15T22:45:45: libsqlite-3.51.1     | 917 KB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: #10 24.19 \n",
      "2025-12-15T22:45:45: mkl-2025.3.0         | 119.4 MB  | ######2    |  63% \n",
      "2025-12-15T22:45:45: #10 24.21 \n",
      "2025-12-15T22:45:45: #10 24.21 \n",
      "2025-12-15T22:45:45: #10 24.21 \n",
      "2025-12-15T22:45:45: #10 24.21 \n",
      "2025-12-15T22:45:45: #10 24.21 \n",
      "2025-12-15T22:45:45: libstdcxx-15.2.0     | 5.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45: #10 24.23 \n",
      "2025-12-15T22:45:45:  ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: #10 24.24 \n",
      "2025-12-15T22:45:45: libsqlite-3.51.1     | 917 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: #10 24.28 \n",
      "2025-12-15T22:45:45: mkl-2025.3.0         | 119.4 MB  | ######5    |  65% \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: #10 24.36 \n",
      "2025-12-15T22:45:45: mkl-2025.3.0         | 119.4 MB  | ######8    |  69% \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:45: #10 24.46 \n",
      "2025-12-15T22:45:46: mkl-2025.3.0         | 119.4 MB  | #######1   |  72% \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: libuv-1.51.0         | 874 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:46: #10 24.56 \n",
      "2025-12-15T22:45:47: mkl-2025.3.0         | 119.4 MB  | #########9 |  99% \n",
      "2025-12-15T22:45:47: libtorch-2.9.1       | 57.9 MB   | ########## | 100% \u001b[A\n",
      "2025-12-15T22:45:48: libtorch-2.9.1       | 57.9 MB   | ########## | 100% \u001b[A\n",
      "2025-12-15T22:45:48: #10 26.62 \n",
      "2025-12-15T22:45:48: #10 26.62 \n",
      "2025-12-15T22:45:48: #10 26.62 \n",
      "2025-12-15T22:45:48: numpy-2.2.6          | 7.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:48: #10 27.35 \n",
      "2025-12-15T22:45:48: #10 27.35 \n",
      "2025-12-15T22:45:48: #10 27.35 \n",
      "2025-12-15T22:45:48: #10 27.35 \n",
      "2025-12-15T22:45:48: #10 27.35 \n",
      "2025-12-15T22:45:48: #10 27.35 \n",
      "2025-12-15T22:45:49: mkl-2025.3.0         | 119.4 MB  | ########## | 100% \n",
      "2025-12-15T22:45:49: #10 28.25 \n",
      "2025-12-15T22:45:50: python-3.10.19       | 24.1 MB   | ########## | 100% \u001b[A\u001b[A\n",
      "2025-12-15T22:45:50: #10 28.88 \n",
      "2025-12-15T22:45:50: #10 28.88 \n",
      "2025-12-15T22:45:50: #10 28.88 \n",
      "2025-12-15T22:45:50: #10 28.88 \n",
      "2025-12-15T22:45:50: #10 28.88 \n",
      "2025-12-15T22:45:50: #10 28.88 \n",
      "2025-12-15T22:45:50: #10 28.88 \n",
      "2025-12-15T22:45:50: #10 28.88 \n",
      "2025-12-15T22:45:50: tk-8.6.13            | 3.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:50: #10 29.10 \n",
      "2025-12-15T22:45:50: #10 29.10 \n",
      "2025-12-15T22:45:50: #10 29.10 \n",
      "2025-12-15T22:45:50: #10 29.10 \n",
      "2025-12-15T22:45:50: #10 29.10 \n",
      "2025-12-15T22:45:50: #10 29.10 \n",
      "2025-12-15T22:45:50: #10 29.10 \n",
      "2025-12-15T22:45:50: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:50: #10 29.20 \n",
      "2025-12-15T22:45:50: #10 29.20 \n",
      "2025-12-15T22:45:50: #10 29.20 \n",
      "2025-12-15T22:45:50: #10 29.20 \n",
      "2025-12-15T22:45:50: #10 29.20 \n",
      "2025-12-15T22:45:50: #10 29.20 \n",
      "2025-12-15T22:45:50: #10 29.20 \n",
      "2025-12-15T22:45:50: #10 29.20 \n",
      "2025-12-15T22:45:50: #10 29.20 \n",
      "2025-12-15T22:45:50: #10 29.20 \n",
      "2025-12-15T22:45:50: #10 29.20 \n",
      "2025-12-15T22:45:50: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:50: #10 29.21 \n",
      "2025-12-15T22:45:50: #10 29.21 \n",
      "2025-12-15T22:45:50: #10 29.21 \n",
      "2025-12-15T22:45:50: #10 29.21 \n",
      "2025-12-15T22:45:50: #10 29.21 \n",
      "2025-12-15T22:45:50: #10 29.21 \n",
      "2025-12-15T22:45:50: #10 29.21 \n",
      "2025-12-15T22:45:50: #10 29.21 \n",
      "2025-12-15T22:45:50: #10 29.21 \n",
      "2025-12-15T22:45:51: openssl-3.6.0        | 3.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:51: #10 29.87 \n",
      "2025-12-15T22:45:51: #10 29.87 \n",
      "2025-12-15T22:45:51: #10 29.87 \n",
      "2025-12-15T22:45:51: #10 29.87 \n",
      "2025-12-15T22:45:51: #10 29.87 \n",
      "2025-12-15T22:45:51: #10 29.87 \n",
      "2025-12-15T22:45:51: #10 29.87 \n",
      "2025-12-15T22:45:51: #10 29.87 \n",
      "2025-12-15T22:45:51: #10 29.87 \n",
      "2025-12-15T22:45:51: #10 29.87 \n",
      "2025-12-15T22:45:51: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: libabseil-20250512.1 | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: #10 30.03 \n",
      "2025-12-15T22:45:51: libabseil-20250512.1 | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:51: #10 30.50 \n",
      "2025-12-15T22:45:52: networkx-3.4.2       | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: #10 30.50 \n",
      "2025-12-15T22:45:52: networkx-3.4.2       | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: #10 30.59 \n",
      "2025-12-15T22:45:52: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: libgcc-15.2.0        | 1018 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: #10 30.62 \n",
      "2025-12-15T22:45:52: libgcc-15.2.0        | 1018 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: libsqlite-3.51.1     | 917 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:52: #10 30.65 \n",
      "2025-12-15T22:45:53: libsqlite-3.51.1     | 917 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:53: #10 31.78 \n",
      "2025-12-15T22:45:53: #10 31.78 \n",
      "2025-12-15T22:45:53: pytorch-2.9.1        | 20.4 MB   | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:53: #10 31.84 \n",
      "2025-12-15T22:45:54: libuv-1.51.0         | 874 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54:  ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:54: #10 33.22 \n",
      "2025-12-15T22:45:59: mkl-2025.3.0         | 119.4 MB  | ########## | 100% \n",
      "2025-12-15T22:45:59: libtorch-2.9.1       | 57.9 MB   | ########## | 100% \u001b[A\n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59:                                                      \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\n",
      "2025-12-15T22:45:59: #10 37.96 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: \u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: \u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: \u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: #10 37.97 \n",
      "2025-12-15T22:45:59: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A done\n",
      "2025-12-15T22:46:00: #10 37.97 Preparing transaction: done\n",
      "2025-12-15T22:46:02: #10 38.73 Verifying transaction: done\n",
      "2025-12-15T22:46:12: #10 41.42 Executing transaction: done\n",
      "2025-12-15T22:48:14: #10 51.17 Installing pip dependencies: | Ran pip subprocess with arguments:\n",
      "2025-12-15T22:48:14: #10 172.7 ['/azureml-envs/azureml_1f436580892771040fea38f34f9600b4/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt', '--exists-action=b']\n",
      "2025-12-15T22:48:14: #10 172.7 Pip subprocess output:\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azureml-defaults (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azureml_defaults-1.61.0-py3-none-any.whl.metadata (914 bytes)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting transformers<5.0.0,>=4.35.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting safetensors>=0.4.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 3))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting datasets>=2.12.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pandas>=2.0.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 5))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting scikit-learn>=1.3.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 6))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-ai-ml>=1.0.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_ai_ml-1.30.0-py3-none-any.whl.metadata (40 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-identity>=1.12.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 8))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_identity-1.25.1-py3-none-any.whl.metadata (88 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-storage-blob>=12.17.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 9))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_blob-12.27.1-py3-none-any.whl.metadata (26 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pyyaml>=6.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 10))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting tqdm>=4.65.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 11))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting seqeval>=1.2.2 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 12))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Installing build dependencies: started\n",
      "2025-12-15T22:48:14: #10 172.7   Installing build dependencies: finished with status 'done'\n",
      "2025-12-15T22:48:14: #10 172.7   Getting requirements to build wheel: started\n",
      "2025-12-15T22:48:14: #10 172.7   Getting requirements to build wheel: finished with status 'done'\n",
      "2025-12-15T22:48:14: #10 172.7   Installing backend dependencies: started\n",
      "2025-12-15T22:48:14: #10 172.7   Installing backend dependencies: finished with status 'done'\n",
      "2025-12-15T22:48:14: #10 172.7   Preparing metadata (pyproject.toml): started\n",
      "2025-12-15T22:48:14: #10 172.7   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting sentencepiece>=0.1.99 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 13))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting mlflow (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading mlflow-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azureml-mlflow (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 15))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azureml_mlflow-1.61.0.post1-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting onnxruntime (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 16))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading onnxruntime-1.23.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Requirement already satisfied: filelock in /azureml-envs/azureml_1f436580892771040fea38f34f9600b4/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2)) (3.20.0)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting huggingface-hub<1.0,>=0.34.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Requirement already satisfied: numpy>=1.17 in /azureml-envs/azureml_1f436580892771040fea38f34f9600b4/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2)) (2.2.6)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting packaging>=20.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2))\n",
      "2025-12-15T22:48:14: #10 172.7   Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting requests (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Requirement already satisfied: fsspec>=2023.5.0 in /azureml-envs/azureml_1f436580892771040fea38f34f9600b4/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2)) (2025.12.0)\n",
      "2025-12-15T22:48:14: #10 172.7 Requirement already satisfied: typing-extensions>=3.7.4.3 in /azureml-envs/azureml_1f436580892771040fea38f34f9600b4/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2)) (4.15.0)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azureml-inference-server-http~=1.4 (from azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azureml_inference_server_http-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azureml-core~=1.61.0 (from azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azureml_core-1.61.0.post1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azureml-dataset-runtime~=1.61.0 (from azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azureml_dataset_runtime-1.61.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pytz (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting backports.tempfile (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading backports.tempfile-1.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pathspec<1.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting msal<2.0.0,>=1.15.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting msal-extensions<=2.0.0,>=0.3.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting knack<0.13.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading knack-0.12.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-core<2.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_core-1.37.0-py3-none-any.whl.metadata (47 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pkginfo (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pkginfo-1.12.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting argcomplete<4 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading argcomplete-3.6.3-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting humanfriendly<11.0,>=4.7 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting paramiko<4.0.0,>=2.0.8 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-mgmt-resource<=24.0.0,>=15.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_mgmt_resource-24.0.0-py3-none-any.whl.metadata (43 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-mgmt-containerregistry<15,>=8.2.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_mgmt_containerregistry-14.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-mgmt-storage<=24.0.0,>=16.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_mgmt_storage-24.0.0-py3-none-any.whl.metadata (36 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-mgmt-keyvault<12.0.0,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_mgmt_keyvault-11.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-mgmt-authorization<5,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-mgmt-network<=30.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_mgmt_network-30.0.0-py3-none-any.whl.metadata (94 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-graphrbac<1.0.0,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_graphrbac-0.61.2-py2.py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-common<2.0.0,>=1.1.12 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting msrest<=0.7.1,>=0.5.1 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting msrestazure<=0.7,>=0.4.33 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting urllib3<3.0.0,>1.26.17 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting python-dateutil<3.0.0,>=2.7.3 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting ndg-httpsclient<=0.5.1 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading ndg_httpsclient-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting SecretStorage<4.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading secretstorage-3.5.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting jsonpickle<5.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading jsonpickle-4.1.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting contextlib2<22.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting docker<8.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting PyJWT<3.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting adal<=1.2.7,>=1.2.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading adal-1.2.7-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pyopenssl<26.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting jmespath<2.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting cryptography>=1.1.0 (from adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting isodate<1.0.0,>=0.6.1 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-mgmt-core<2.0.0,>=1.3.2 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_mgmt_core-1.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azureml-dataprep<5.5.0a,>=5.1.0a (from azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azureml_dataprep-5.4.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pyarrow<21.0.0,>=0.17.0 (from azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azureml-dataprep-native<43.0.0,>=42.0.0 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azureml_dataprep_native-42.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azureml-dataprep-rslex~=2.25.1 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azureml_dataprep_rslex-2.25.2-cp310-cp310-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting cloudpickle<3.0.0,>=1.1.0 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-identity>=1.12.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 8))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_identity-1.17.0-py3-none-any.whl.metadata (79 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting jsonschema (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Requirement already satisfied: pip>=25.3 in /azureml-envs/azureml_1f436580892771040fea38f34f9600b4/lib/python3.10/site-packages (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1)) (25.3)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting fusepy<4.0.0,>=3.0.1 (from azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Installing build dependencies: started\n",
      "2025-12-15T22:48:14: #10 172.7   Installing build dependencies: finished with status 'done'\n",
      "2025-12-15T22:48:14: #10 172.7   Getting requirements to build wheel: started\n",
      "2025-12-15T22:48:14: #10 172.7   Getting requirements to build wheel: finished with status 'done'\n",
      "2025-12-15T22:48:14: #10 172.7   Preparing metadata (pyproject.toml): started\n",
      "2025-12-15T22:48:14: #10 172.7   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting flask~=3.1.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting flask-cors~=6.0.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting gunicorn>=23.0.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting inference-schema~=1.8.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading inference_schema-1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-sdk==1.33.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-api==1.33.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_api-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-semantic-conventions (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry_exporter-1.0.0b46-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pydantic~=2.11.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pydantic-settings (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting werkzeug>=3.0.3 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting certifi>=2024.7.4 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting deprecated>=1.2.6 (from opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-semantic-conventions (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting blinker>=1.9.0 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting click>=8.1.3 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting itsdangerous>=2.2.0 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Requirement already satisfied: jinja2>=3.1.2 in /azureml-envs/azureml_1f436580892771040fea38f34f9600b4/lib/python3.10/site-packages (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1)) (3.1.6)\n",
      "2025-12-15T22:48:14: #10 172.7 Requirement already satisfied: markupsafe>=2.1.1 in /azureml-envs/azureml_1f436580892771040fea38f34f9600b4/lib/python3.10/site-packages (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1)) (3.0.3)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting wrapt<=1.16.0,>=1.14.0 (from inference-schema~=1.8.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pygments (from knack<0.13.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting tabulate (from knack<0.13.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting cffi>=2.0.0 (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting requests-oauthlib>=0.5.0 (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting six (from msrestazure<=0.7,>=0.4.33->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pyasn1>=0.1.1 (from ndg-httpsclient<=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting bcrypt>=3.2 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pynacl>=1.5 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pynacl-1.6.1-cp38-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting annotated-types>=0.6.0 (from pydantic~=2.11.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pydantic-core==2.33.2 (from pydantic~=2.11.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting typing-inspection>=0.4.0 (from pydantic~=2.11.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting charset_normalizer<4,>=2 (from requests->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting idna<4,>=2.5 (from requests->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting jeepney>=0.6 (from SecretStorage<4.0.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading jeepney-0.9.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting datasets>=2.12.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading datasets-4.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading datasets-4.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting xxhash (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting multiprocess<0.70.17 (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 2))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting tzdata>=2022.7 (from pandas>=2.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 5))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting scipy>=1.8.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 6))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting joblib>=1.2.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 6))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 6))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting marshmallow<4.0.0,>=3.5 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting strictyaml<2.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting colorama<1.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-storage-file-share (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_file_share-12.23.1-py3-none-any.whl.metadata (52 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_file_datalake-12.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pydash<9.0.0,>=6.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pydash-8.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.8.3-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting attrs>=22.2.0 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting referencing>=0.28.4 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting rpds-py>=0.7.1 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting mlflow-skinny==3.7.0 (from mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading mlflow_skinny-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting mlflow-tracing==3.7.0 (from mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading mlflow_tracing-3.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting alembic!=1.10.0,<2 (from mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting graphene<4 (from mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting huey<3,>=2.5.0 (from mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading huey-2.5.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting matplotlib<4 (from mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting sqlalchemy<3,>=1.4.0 (from mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading sqlalchemy-2.0.45-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading cachetools-6.2.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading databricks_sdk-0.74.0-py3-none-any.whl.metadata (40 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting fastapi<1 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading fastapi-0.124.4-py3-none-any.whl.metadata (30 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading sqlparse-0.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting uvicorn<1 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting Mako (from alembic!=1.10.0,<2->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting tomli (from alembic!=1.10.0,<2->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Using cached tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading google_auth-2.44.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting starlette<0.51.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting cycler>=0.10 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting fonttools>=4.22.0 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting kiwisolver>=1.3.1 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pillow>=8 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pyparsing>=3 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading greenlet-3.3.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting anyio<5,>=3.6.2 (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 14))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of azureml-mlflow to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azureml-mlflow (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 15))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azureml_mlflow-1.61.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azureml_mlflow-1.60.0.post1-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azureml_mlflow-1.60.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-storage-blob>=12.17.0 (from -r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 9))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting coloredlogs (from onnxruntime->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 16))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting flatbuffers (from onnxruntime->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 16))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "2025-12-15T22:48:14: #10 172.7 Requirement already satisfied: sympy in /azureml-envs/azureml_1f436580892771040fea38f34f9600b4/lib/python3.10/site-packages (from onnxruntime->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 16)) (1.14.0)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 4))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of azure-storage-file-datalake to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_file_datalake-12.21.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_file_datalake-12.19.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_file_datalake-12.18.1-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_file_datalake-12.18.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_file_datalake-12.17.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_file_datalake-12.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is still looking at multiple versions of azure-storage-file-datalake to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_file_datalake-12.15.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_storage_file_datalake-12.14.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting pycparser (from cffi>=2.0.0->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-core-tracing-opentelemetry~=1.0.0b11 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of azure-monitor-opentelemetry to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.8.2-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.8.1-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.8.0-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-django~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_django-0.60b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-fastapi~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_fastapi-0.60b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-flask~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_flask-0.60b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-psycopg2~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_psycopg2-0.60b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-requests~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_requests-0.60b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-urllib~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib-0.60b1-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-urllib3~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib3-0.60b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-resource-detector-azure~=0.1.5 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl.metadata (5.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.6.13-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.6.12-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-django<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_django-0.52b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-flask<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_flask-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-psycopg2<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_psycopg2-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-requests<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_requests-0.52b1-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-urllib<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib-0.52b1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-urllib3<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib3-0.52b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.6.11-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is still looking at multiple versions of azure-monitor-opentelemetry to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.6.10-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.6.9-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.6.8-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry-1.6.7-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of azure-monitor-opentelemetry-exporter to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry_exporter-1.0.0b45-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry_exporter-1.0.0b44-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry_exporter-1.0.0b43-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry_exporter-1.0.0b42-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry_exporter-1.0.0b41-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading azure_monitor_opentelemetry_exporter-1.0.0b40-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting psutil<8,>=5.9 (from azure-monitor-opentelemetry-exporter->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-wsgi==0.60b1 (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_wsgi-0.60b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation==0.60b1 (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation-0.60b1-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-django to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_django-0.60b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-wsgi==0.60b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_wsgi-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation==0.60b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation-0.60b0-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_django-0.59b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-wsgi==0.59b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_wsgi-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_django-0.58b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-wsgi==0.58b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_wsgi-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation==0.58b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_django-0.57b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-wsgi==0.57b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_wsgi-0.57b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation==0.57b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_django-0.56b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-wsgi==0.56b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_wsgi-0.56b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation==0.56b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation-0.56b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_django-0.55b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-wsgi==0.55b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_wsgi-0.55b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_django-0.55b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-wsgi==0.55b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_wsgi-0.55b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation==0.55b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation-0.55b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-django to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_django-0.54b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-wsgi==0.54b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_wsgi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_django-0.54b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-wsgi==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_wsgi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-util-http==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-asgi==0.60b1 (from opentelemetry-instrumentation-fastapi~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_asgi-0.60b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_fastapi-0.60b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-asgi==0.60b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_asgi-0.60b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_fastapi-0.59b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-asgi==0.59b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_asgi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_fastapi-0.58b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-asgi==0.58b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_asgi-0.58b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_fastapi-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-asgi==0.57b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_asgi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_fastapi-0.56b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-asgi==0.56b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_asgi-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_fastapi-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-asgi==0.55b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_asgi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-asgi==0.54b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b0->opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading asgiref-3.11.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-flask to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-flask~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_flask-0.60b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_flask-0.59b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_flask-0.58b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_flask-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_flask-0.56b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_flask-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_flask-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-flask to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_flask-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_flask-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-dbapi==0.60b1 (from opentelemetry-instrumentation-psycopg2~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_dbapi-0.60b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-psycopg2 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_psycopg2-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-dbapi==0.60b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_dbapi-0.60b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_psycopg2-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-dbapi==0.59b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_dbapi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_psycopg2-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-dbapi==0.58b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_dbapi-0.58b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_psycopg2-0.57b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-dbapi==0.57b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_dbapi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_psycopg2-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-dbapi==0.56b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_dbapi-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_psycopg2-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-dbapi==0.55b1 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_dbapi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_psycopg2-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-dbapi==0.55b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_dbapi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-psycopg2 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_psycopg2-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-dbapi==0.54b1 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_dbapi-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_psycopg2-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-dbapi==0.54b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_dbapi-0.54b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-requests to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-requests~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_requests-0.60b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_requests-0.59b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_requests-0.58b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_requests-0.57b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_requests-0.56b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_requests-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_requests-0.55b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-requests to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_requests-0.54b1-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_requests-0.54b0-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-urllib to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-urllib~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib-0.60b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib-0.59b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib-0.58b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib-0.57b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib-0.56b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib-0.55b1-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib-0.55b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-urllib to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib-0.54b1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib-0.54b0-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting opentelemetry-instrumentation-urllib3~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 7))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib3-0.60b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib3-0.59b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib3-0.58b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib3-0.57b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib3-0.56b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib3-0.55b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib3-0.55b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib3-0.54b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading opentelemetry_instrumentation_urllib3-0.54b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Collecting backports.weakref (from backports.tempfile->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 1))\n",
      "2025-12-15T22:48:14: #10 172.7   Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Requirement already satisfied: mpmath<1.4,>=1.1.0 in /azureml-envs/azureml_1f436580892771040fea38f34f9600b4/lib/python3.10/site-packages (from sympy->onnxruntime->-r /azureml-environment-setup/condaenv.7x3nrdd5.requirements.txt (line 16)) (1.3.0)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 109.0 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 566.1/566.1 kB 18.6 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 72.1 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 93.1 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azureml_defaults-1.61.0-py3-none-any.whl (2.1 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azureml_core-1.61.0.post1-py3-none-any.whl (3.3 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 93.1 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading argcomplete-3.6.3-py3-none-any.whl (43 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_core-1.37.0-py3-none-any.whl (214 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_graphrbac-0.61.2-py2.py3-none-any.whl (142 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl (1.1 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 49.0 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_mgmt_containerregistry-14.0.0-py3-none-any.whl (1.7 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 33.5 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_mgmt_core-1.6.0-py3-none-any.whl (29 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_mgmt_keyvault-11.0.0-py3-none-any.whl (308 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_mgmt_network-30.0.0-py3-none-any.whl (614 kB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 614.0/614.0 kB 9.1 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_mgmt_resource-24.0.0-py3-none-any.whl (3.6 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 49.3 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_mgmt_storage-24.0.0-py3-none-any.whl (290 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azureml_dataset_runtime-1.61.0-py3-none-any.whl (2.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azureml_dataprep-5.4.2-py3-none-any.whl (253 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_identity-1.17.0-py3-none-any.whl (173 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 770.3/770.3 kB 25.0 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azureml_dataprep_native-42.1.0-cp310-cp310-manylinux1_x86_64.whl (187 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azureml_dataprep_rslex-2.25.2-cp310-cp310-manylinux1_x86_64.whl (26.1 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.1/26.1 MB 80.7 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azureml_inference_server_http-1.5.0-py3-none-any.whl (42 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_api-1.33.0-py3-none-any.whl (65 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl (118 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl (194 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading inference_schema-1.8-py3-none-any.whl (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading jsonpickle-4.1.1-py3-none-any.whl (47 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading knack-0.12.0-py3-none-any.whl (60 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading msal-1.34.0-py3-none-any.whl (116 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 111.1 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl (40 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading paramiko-3.5.1-py3-none-any.whl (227 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.3/42.3 MB 53.5 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 66.0 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pyopenssl-25.3.0-py3-none-any.whl (57 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading secretstorage-3.5.0-py3-none-any.whl (15 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 130.0 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.7/9.7 MB 61.5 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_ai_ml-1.30.0-py3-none-any.whl (13.3 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.3/13.3 MB 100.5 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 56.1 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading mlflow-3.7.0-py3-none-any.whl (8.9 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.9/8.9 MB 50.2 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading mlflow_skinny-3.7.0-py3-none-any.whl (2.4 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 62.0 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading mlflow_tracing-3.7.0-py3-none-any.whl (1.3 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 56.0 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading alembic-1.17.2-py3-none-any.whl (248 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading cachetools-6.2.4-py3-none-any.whl (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading databricks_sdk-0.74.0-py3-none-any.whl (764 kB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 764.2/764.2 kB 37.9 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading fastapi-0.124.4-py3-none-any.whl (113 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading google_auth-2.44.0-py2.py3-none-any.whl (228 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading huey-2.5.5-py3-none-any.whl (76 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.7/8.7 MB 137.7 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 37.7/37.7 MB 68.8 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading sqlalchemy-2.0.45-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 100.4 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading sqlparse-0.5.4-py3-none-any.whl (45 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azureml_mlflow-1.60.0-py3-none-any.whl (1.0 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 35.2 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading onnxruntime-1.23.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.4/17.4 MB 111.8 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 55.7 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_storage_file_datalake-12.14.0-py3-none-any.whl (251 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 85.8 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading greenlet-3.3.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (586 kB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 586.9/586.9 kB 24.2 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading jeepney-0.9.0-py3-none-any.whl (49 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 53.0 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 121.6 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pynacl-1.6.1-cp38-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 47.8 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 791.7/791.7 kB 29.8 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_monitor_opentelemetry-1.6.7-py3-none-any.whl (23 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl (11 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_monitor_opentelemetry_exporter-1.0.0b40-py2.py3-none-any.whl (159 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_instrumentation_django-0.54b0-py3-none-any.whl (19 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl (31 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_instrumentation_wsgi-0.54b0-py3-none-any.whl (14 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl (7.3 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl (16 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading asgiref-3.11.0-py3-none-any.whl (24 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_instrumentation_flask-0.54b0-py3-none-any.whl (14 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_instrumentation_psycopg2-0.54b0-py3-none-any.whl (10 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_instrumentation_dbapi-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_instrumentation_requests-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_instrumentation_urllib-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_instrumentation_urllib3-0.54b0-py3-none-any.whl (13 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl (14 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading azure_storage_file_share-12.23.1-py3-none-any.whl (307 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pkginfo-1.12.1.2-py3-none-any.whl (32 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "2025-12-15T22:48:14: #10 172.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 54.7 MB/s  0:00:00\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Using cached tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "2025-12-15T22:48:14: #10 172.7 Building wheels for collected packages: fusepy, seqeval\n",
      "2025-12-15T22:48:14: #10 172.7   Building wheel for fusepy (pyproject.toml): started\n",
      "2025-12-15T22:48:14: #10 172.7   Building wheel for fusepy (pyproject.toml): finished with status 'done'\n",
      "2025-12-15T22:48:14: #10 172.7   Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10537 sha256=a6e14292e730ff9c14bb33e4086bf9716b485afc9c77a627d1d9189290f24b8d\n",
      "2025-12-15T22:48:14: #10 172.7   Stored in directory: /root/.cache/pip/wheels/c0/18/f6/f0d6be9d0435e2677ce5cc758e91da50053dce456a346f08c5\n",
      "2025-12-15T22:48:14: #10 172.7   Building wheel for seqeval (pyproject.toml): started\n",
      "2025-12-15T22:48:14: #10 172.7   Building wheel for seqeval (pyproject.toml): finished with status 'done'\n",
      "2025-12-15T22:48:14: #10 172.7   Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16250 sha256=16b9348822c9fc15a4541535f8d932d168f6d3811f0c81ad5f6d9c5ca7dd78b3\n",
      "2025-12-15T22:48:14: #10 172.7   Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "2025-12-15T22:48:14: #10 172.7 Successfully built fusepy seqeval\n",
      "2025-12-15T22:48:14: #10 172.7 Installing collected packages: pytz, huey, fusepy, flatbuffers, fixedint, backports.weakref, azureml-dataprep-rslex, azure-common, zipp, xxhash, wrapt, werkzeug, urllib3, tzdata, typing-inspection, tqdm, tomli, threadpoolctl, tabulate, sqlparse, smmap, six, sentencepiece, scipy, safetensors, rpds-py, regex, pyyaml, python-dotenv, PySocks, pyparsing, PyJWT, pygments, pydash, pydantic-core, pycparser, pyasn1, pyarrow, psutil, protobuf, propcache, pkginfo, pillow, pathspec, packaging, opentelemetry-util-http, oauthlib, multidict, Mako, kiwisolver, jsonpickle, joblib, jmespath, jeepney, itsdangerous, isodate, idna, humanfriendly, hf-xet, h11, greenlet, graphql-core, fsspec, frozenlist, fonttools, exceptiongroup, dill, cycler, contourpy, contextlib2, colorama, cloudpickle, click, charset_normalizer, certifi, cachetools, blinker, bcrypt, backports.tempfile, azureml-dataprep-native, attrs, async-timeout, asgiref, argcomplete, annotated-types, annotated-doc, aiohappyeyeballs, yarl, uvicorn, sqlalchemy, scikit-learn, rsa, requests, referencing, python-dateutil, pydantic, pyasn1-modules, opentelemetry-proto, multiprocess, marshmallow, knack, importlib-metadata, gunicorn, graphql-relay, gitdb, flask, deprecated, coloredlogs, cffi, anyio, aiosignal, strictyaml, starlette, seqeval, requests-oauthlib, pynacl, pydantic-settings, pandas, opentelemetry-api, onnxruntime, matplotlib, jsonschema-specifications, inference-schema, huggingface-hub, graphene, google-auth, gitpython, flask-cors, docker, cryptography, azure-core, alembic, aiohttp, tokenizers, SecretStorage, pyopenssl, paramiko, opentelemetry-semantic-conventions, msrest, jsonschema, fastapi, databricks-sdk, azure-storage-file-share, azure-storage-blob, azure-mgmt-core, azure-core-tracing-opentelemetry, adal, transformers, opentelemetry-sdk, opentelemetry-instrumentation, ndg-httpsclient, msrestazure, msal, datasets, azure-storage-file-datalake, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-network, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, opentelemetry-resource-detector-azure, opentelemetry-instrumentation-wsgi, opentelemetry-instrumentation-urllib3, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-dbapi, opentelemetry-instrumentation-asgi, msal-extensions, mlflow-tracing, mlflow-skinny, azure-graphrbac, opentelemetry-instrumentation-psycopg2, opentelemetry-instrumentation-flask, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-django, mlflow, azureml-core, azure-identity, azureml-mlflow, azureml-dataprep, azure-monitor-opentelemetry-exporter, azureml-inference-server-http, azureml-dataset-runtime, azure-monitor-opentelemetry, azure-ai-ml, azureml-defaults\n",
      "2025-12-15T22:48:14: #10 172.7   Attempting uninstall: fsspec\n",
      "2025-12-15T22:48:14: #10 172.7     Found existing installation: fsspec 2025.12.0\n",
      "2025-12-15T22:48:14: #10 172.7     Uninstalling fsspec-2025.12.0:\n",
      "2025-12-15T22:48:14: #10 172.7       Successfully uninstalled fsspec-2025.12.0\n",
      "2025-12-15T22:48:14: #10 172.7 \n",
      "2025-12-15T22:48:14: #10 172.7 Successfully installed Mako-1.3.10 PyJWT-2.10.1 PySocks-1.7.1 SecretStorage-3.5.0 adal-1.2.7 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 alembic-1.17.2 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.12.0 argcomplete-3.6.3 asgiref-3.11.0 async-timeout-5.0.1 attrs-25.4.0 azure-ai-ml-1.30.0 azure-common-1.1.28 azure-core-1.37.0 azure-core-tracing-opentelemetry-1.0.0b12 azure-graphrbac-0.61.2 azure-identity-1.17.0 azure-mgmt-authorization-4.0.0 azure-mgmt-containerregistry-14.0.0 azure-mgmt-core-1.6.0 azure-mgmt-keyvault-11.0.0 azure-mgmt-network-30.0.0 azure-mgmt-resource-24.0.0 azure-mgmt-storage-24.0.0 azure-monitor-opentelemetry-1.6.7 azure-monitor-opentelemetry-exporter-1.0.0b40 azure-storage-blob-12.19.0 azure-storage-file-datalake-12.14.0 azure-storage-file-share-12.23.1 azureml-core-1.61.0.post1 azureml-dataprep-5.4.2 azureml-dataprep-native-42.1.0 azureml-dataprep-rslex-2.25.2 azureml-dataset-runtime-1.61.0 azureml-defaults-1.61.0 azureml-inference-server-http-1.5.0 azureml-mlflow-1.60.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-5.0.0 blinker-1.9.0 cachetools-6.2.4 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 cloudpickle-2.2.1 colorama-0.4.6 coloredlogs-15.0.1 contextlib2-21.6.0 contourpy-1.3.2 cryptography-46.0.3 cycler-0.12.1 databricks-sdk-0.74.0 datasets-4.0.0 deprecated-1.3.1 dill-0.3.8 docker-7.1.0 exceptiongroup-1.3.1 fastapi-0.124.4 fixedint-0.1.6 flask-3.1.2 flask-cors-6.0.2 flatbuffers-25.9.23 fonttools-4.61.1 frozenlist-1.8.0 fsspec-2025.3.0 fusepy-3.0.1 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.44.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 greenlet-3.3.0 gunicorn-23.0.0 h11-0.16.0 hf-xet-1.2.0 huey-2.5.5 huggingface-hub-0.36.0 humanfriendly-10.0 idna-3.11 importlib-metadata-8.6.1 inference-schema-1.8 isodate-0.7.2 itsdangerous-2.2.0 jeepney-0.9.0 jmespath-1.0.1 joblib-1.5.3 jsonpickle-4.1.1 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kiwisolver-1.4.9 knack-0.12.0 marshmallow-3.26.1 matplotlib-3.10.8 mlflow-3.7.0 mlflow-skinny-3.7.0 mlflow-tracing-3.7.0 msal-1.34.0 msal-extensions-1.3.1 msrest-0.7.1 msrestazure-0.6.4.post1 multidict-6.7.0 multiprocess-0.70.16 ndg-httpsclient-0.5.1 oauthlib-3.3.1 onnxruntime-1.23.2 opentelemetry-api-1.33.0 opentelemetry-instrumentation-0.54b0 opentelemetry-instrumentation-asgi-0.54b0 opentelemetry-instrumentation-dbapi-0.54b0 opentelemetry-instrumentation-django-0.54b0 opentelemetry-instrumentation-fastapi-0.54b0 opentelemetry-instrumentation-flask-0.54b0 opentelemetry-instrumentation-psycopg2-0.54b0 opentelemetry-instrumentation-requests-0.54b0 opentelemetry-instrumentation-urllib-0.54b0 opentelemetry-instrumentation-urllib3-0.54b0 opentelemetry-instrumentation-wsgi-0.54b0 opentelemetry-proto-1.39.1 opentelemetry-resource-detector-azure-0.1.5 opentelemetry-sdk-1.33.0 opentelemetry-semantic-conventions-0.54b0 opentelemetry-util-http-0.54b0 packaging-25.0 pandas-2.3.3 paramiko-3.5.1 pathspec-0.12.1 pillow-12.0.0 pkginfo-1.12.1.2 propcache-0.4.1 protobuf-6.33.2 psutil-7.1.3 pyarrow-20.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.23 pydantic-2.11.10 pydantic-core-2.33.2 pydantic-settings-2.12.0 pydash-8.0.5 pygments-2.19.2 pynacl-1.6.1 pyopenssl-25.3.0 pyparsing-3.2.5 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 pytz-2025.2 pyyaml-6.0.3 referencing-0.37.0 regex-2025.11.3 requests-2.32.5 requests-oauthlib-2.0.0 rpds-py-0.30.0 rsa-4.9.1 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 sentencepiece-0.2.1 seqeval-1.2.2 six-1.17.0 smmap-5.0.2 sqlalchemy-2.0.45 sqlparse-0.5.4 starlette-0.50.0 strictyaml-1.7.3 tabulate-0.9.0 threadpoolctl-3.6.0 tokenizers-0.22.1 tomli-2.3.0 tqdm-4.67.1 transformers-4.57.3 typing-inspection-0.4.2 tzdata-2025.3 urllib3-2.6.2 uvicorn-0.38.0 werkzeug-3.1.4 wrapt-1.16.0 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0\n",
      "2025-12-15T22:48:14: #10 172.8 \n",
      "2025-12-15T22:48:14: #10 172.done\n",
      "2025-12-15T22:48:14: #10 172.8 #\n",
      "2025-12-15T22:48:14: #10 172.8 # To activate this environment, use\n",
      "2025-12-15T22:48:14: #10 172.8 #\n",
      "2025-12-15T22:48:14: #10 172.8 #     $ conda activate /azureml-envs/azureml_1f436580892771040fea38f34f9600b4\n",
      "2025-12-15T22:48:14: #10 172.8 #\n",
      "2025-12-15T22:48:14: #10 172.8 # To deactivate an active environment, use\n",
      "2025-12-15T22:48:14: #10 172.8 #\n",
      "2025-12-15T22:48:14: #10 172.8 #     $ conda deactivate\n",
      "2025-12-15T22:48:14: #10 172.8 \n",
      "2025-12-15T22:48:20: #10 DONE 179.1s\n",
      "\n",
      "2025-12-15T22:48:20: #11 [ 7/10] COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      "2025-12-15T22:48:20: #11 DONE 0.2s\n",
      "\n",
      "2025-12-15T22:48:20: #12 [ 8/10] RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      "2025-12-15T22:48:21: #12 DONE 0.3s\n",
      "\n",
      "2025-12-15T22:48:21: #13 [ 9/10] RUN rm -rf azureml-environment-setup\n",
      "2025-12-15T22:48:21: #13 DONE 0.3s\n",
      "\n",
      "2025-12-15T22:48:21: #14 exporting to image\n",
      "2025-12-15T22:48:21: #14 exporting layers\n",
      "2025-12-15T22:48:43: #14 exporting layers 21.9s done\n",
      "2025-12-15T22:48:43: #14 writing image sha256:58687cb4056eb1babbafeb711196d232af61f71a3b24889d54ccd7fb39451a4c done\n",
      "2025-12-15T22:48:43: #14 naming to b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_b44ed019c07f973190f7a7029235d9d0 done\n",
      "2025-12-15T22:48:43: #14 naming to b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_b44ed019c07f973190f7a7029235d9d0:1 done\n",
      "2025-12-15T22:48:43: #14 DONE 21.9s\n",
      "\n",
      "\n",
      "2025-12-15T22:48:43: Logging into Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-15T22:48:43: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "2025-12-15T22:48:43: Login Succeeded\n",
      "\n",
      "\n",
      "2025-12-15T22:48:43: Using default tag: latest\n",
      "2025-12-15T22:48:43: The push refers to repository [b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_b44ed019c07f973190f7a7029235d9d0]\n",
      "2025-12-15T22:48:43: 457b84321234: Preparing\n",
      "2025-12-15T22:48:43: 5f70bf18a086: Preparing\n",
      "2025-12-15T22:48:43: dbe9b97a22ad: Preparing\n",
      "2025-12-15T22:48:43: 818378d5ce23: Preparing\n",
      "2025-12-15T22:48:43: 745ffdf83bb8: Preparing\n",
      "2025-12-15T22:48:43: 45fa74c666fc: Preparing\n",
      "2025-12-15T22:48:43: 13734e70cb5a: Preparing\n",
      "2025-12-15T22:48:43: 5f70bf18a086: Preparing\n",
      "2025-12-15T22:48:43: 6b0c1cfc8f15: Preparing\n",
      "2025-12-15T22:48:43: d0b10cfca986: Preparing\n",
      "2025-12-15T22:48:43: 2baf6d5fcdda: Preparing\n",
      "2025-12-15T22:48:43: 947277ce5638: Preparing\n",
      "2025-12-15T22:48:43: 2ea0beed9e18: Preparing\n",
      "2025-12-15T22:48:43: 7d3ba5b124ef: Preparing\n",
      "2025-12-15T22:48:43: cd1cc5cf0a38: Preparing\n",
      "2025-12-15T22:48:43: fa26ceb8799b: Preparing\n",
      "2025-12-15T22:48:43: 44bfba9b2552: Preparing\n",
      "2025-12-15T22:48:43: fffe76c64ef2: Preparing\n",
      "2025-12-15T22:48:43: 947277ce5638: Waiting\n",
      "2025-12-15T22:48:43: 2ea0beed9e18: Waiting\n",
      "2025-12-15T22:48:43: 45fa74c666fc: Waiting\n",
      "2025-12-15T22:48:43: 13734e70cb5a: Waiting\n",
      "2025-12-15T22:48:43: 6b0c1cfc8f15: Waiting\n",
      "2025-12-15T22:48:43: d0b10cfca986: Waiting\n",
      "2025-12-15T22:48:43: 2baf6d5fcdda: Waiting\n",
      "2025-12-15T22:48:43: 7d3ba5b124ef: Waiting\n",
      "2025-12-15T22:48:43: cd1cc5cf0a38: Waiting\n",
      "2025-12-15T22:48:43: fa26ceb8799b: Waiting\n",
      "2025-12-15T22:48:43: 44bfba9b2552: Waiting\n",
      "2025-12-15T22:48:43: fffe76c64ef2: Waiting\n",
      "2025-12-15T22:48:43: 5f70bf18a086: Pushed\n",
      "2025-12-15T22:48:44: 745ffdf83bb8: Pushed\n",
      "2025-12-15T22:48:44: 457b84321234: Pushed\n",
      "2025-12-15T22:48:44: dbe9b97a22ad: Pushed\n",
      "2025-12-15T22:48:44: 13734e70cb5a: Pushed\n",
      "2025-12-15T22:48:44: 6b0c1cfc8f15: Pushed\n",
      "2025-12-15T22:48:44: 45fa74c666fc: Pushed\n",
      "2025-12-15T22:48:44: d0b10cfca986: Pushed\n",
      "2025-12-15T22:48:45: 7d3ba5b124ef: Pushed\n",
      "2025-12-15T22:48:45: 947277ce5638: Pushed\n",
      "2025-12-15T22:48:46: cd1cc5cf0a38: Pushed\n",
      "2025-12-15T22:48:46: fa26ceb8799b: Pushed\n",
      "2025-12-15T22:48:49: 2baf6d5fcdda: Pushed\n",
      "2025-12-15T22:48:51: fffe76c64ef2: Pushed\n",
      "2025-12-15T22:49:01: 2ea0beed9e18: Pushed\n",
      "2025-12-15T22:49:09: 44bfba9b2552: Pushed\n",
      "2025-12-15T22:50:30: 818378d5ce23: Pushed\n",
      "2025-12-15T22:50:31: latest: digest: sha256:24dbc73683018f5898e55f3ce5ac7e8ac30520ea6de4c46bd7f24bec05d870e2 size: 4092\n",
      "\n",
      "\n",
      "2025-12-15T22:50:31: The push refers to repository [b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_b44ed019c07f973190f7a7029235d9d0]\n",
      "2025-12-15T22:50:31: 457b84321234: Preparing\n",
      "2025-12-15T22:50:31: 5f70bf18a086: Preparing\n",
      "2025-12-15T22:50:31: dbe9b97a22ad: Preparing\n",
      "2025-12-15T22:50:31: 818378d5ce23: Preparing\n",
      "2025-12-15T22:50:31: 745ffdf83bb8: Preparing\n",
      "2025-12-15T22:50:31: 45fa74c666fc: Preparing\n",
      "2025-12-15T22:50:31: 13734e70cb5a: Preparing\n",
      "2025-12-15T22:50:31: 5f70bf18a086: Preparing\n",
      "2025-12-15T22:50:31: 6b0c1cfc8f15: Preparing\n",
      "2025-12-15T22:50:31: d0b10cfca986: Preparing\n",
      "2025-12-15T22:50:31: 2baf6d5fcdda: Preparing\n",
      "2025-12-15T22:50:31: 947277ce5638: Preparing\n",
      "2025-12-15T22:50:31: 2ea0beed9e18: Preparing\n",
      "2025-12-15T22:50:31: 7d3ba5b124ef: Preparing\n",
      "2025-12-15T22:50:31: cd1cc5cf0a38: Preparing\n",
      "2025-12-15T22:50:31: fa26ceb8799b: Preparing\n",
      "2025-12-15T22:50:31: 44bfba9b2552: Preparing\n",
      "2025-12-15T22:50:31: fffe76c64ef2: Preparing\n",
      "2025-12-15T22:50:31: 45fa74c666fc: Waiting\n",
      "2025-12-15T22:50:31: 13734e70cb5a: Waiting\n",
      "2025-12-15T22:50:31: 6b0c1cfc8f15: Waiting\n",
      "2025-12-15T22:50:31: d0b10cfca986: Waiting\n",
      "2025-12-15T22:50:31: 2baf6d5fcdda: Waiting\n",
      "2025-12-15T22:50:31: 947277ce5638: Waiting\n",
      "2025-12-15T22:50:31: 2ea0beed9e18: Waiting\n",
      "2025-12-15T22:50:31: 7d3ba5b124ef: Waiting\n",
      "2025-12-15T22:50:31: cd1cc5cf0a38: Waiting\n",
      "2025-12-15T22:50:31: fa26ceb8799b: Waiting\n",
      "2025-12-15T22:50:31: 44bfba9b2552: Waiting\n",
      "2025-12-15T22:50:31: fffe76c64ef2: Waiting\n",
      "2025-12-15T22:50:31: 818378d5ce23: Layer already exists\n",
      "2025-12-15T22:50:31: dbe9b97a22ad: Layer already exists\n",
      "2025-12-15T22:50:31: 745ffdf83bb8: Layer already exists\n",
      "2025-12-15T22:50:31: 457b84321234: Layer already exists\n",
      "2025-12-15T22:50:31: 5f70bf18a086: Layer already exists\n",
      "2025-12-15T22:50:31: 45fa74c666fc: Layer already exists\n",
      "2025-12-15T22:50:31: 13734e70cb5a: Layer already exists\n",
      "2025-12-15T22:50:31: 6b0c1cfc8f15: Layer already exists\n",
      "2025-12-15T22:50:31: 2baf6d5fcdda: Layer already exists\n",
      "2025-12-15T22:50:31: d0b10cfca986: Layer already exists\n",
      "2025-12-15T22:50:31: 947277ce5638: Layer already exists\n",
      "2025-12-15T22:50:31: 2ea0beed9e18: Layer already exists\n",
      "2025-12-15T22:50:31: 7d3ba5b124ef: Layer already exists\n",
      "2025-12-15T22:50:31: fa26ceb8799b: Layer already exists\n",
      "2025-12-15T22:50:31: cd1cc5cf0a38: Layer already exists\n",
      "2025-12-15T22:50:31: 44bfba9b2552: Layer already exists\n",
      "2025-12-15T22:50:31: fffe76c64ef2: Layer already exists\n",
      "2025-12-15T22:50:31: 1: digest: sha256:24dbc73683018f5898e55f3ce5ac7e8ac30520ea6de4c46bd7f24bec05d870e2 size: 4092\n",
      "\n",
      "\n",
      "2025-12-15T22:50:32: #### Image for post-processing commands: b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_b44ed019c07f973190f7a7029235d9d0:latest\n",
      "2025-12-15T22:50:32: #### Image digest: sha256:24dbc73683018f5898e55f3ce5ac7e8ac30520ea6de4c46bd7f24bec05d870e2\n",
      "2025-12-15T22:50:32: \n",
      "\n",
      "#### Found send_dependencies.py at: /tmp/tmpumwk0672/azureml-environment-setup/send_dependencies.py\n",
      "2025-12-15T22:50:32: #### Attempting to run dependencies script\n",
      "\n",
      "\n",
      "2025-12-15T22:50:36: Report materialized dependencies for the environment\n",
      "2025-12-15T22:50:36: Reading environment context\n",
      "2025-12-15T22:50:36: Exporting conda environment\n",
      "2025-12-15T22:50:36: Sending request with materialized conda environment details\n",
      "2025-12-15T22:50:36: Successfully sent materialized environment dependencies\n",
      "\n",
      "\n",
      "2025-12-15T22:50:37: e9f2c4f93f3ef32c13ea4cbaa273b968cc322b878b863d5e196afccd146bdd72\n",
      "\n",
      "\n",
      "2025-12-15T22:50:37: #### Cleaning up local image cache\n",
      "2025-12-15T22:50:37: Deleting b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_b44ed019c07f973190f7a7029235d9d0 from local machine\n",
      "2025-12-15T22:50:37: Error response from daemon: page not found\n",
      "\n",
      "\n",
      "2025-12-15T22:50:37: Logging out of Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-15T22:50:37: Removing login credentials for https://index.docker.io/v1/\n",
      "\n",
      "\n",
      "2025-12-15T22:50:37: Logging out of Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-15T22:50:37: Removing login credentials for https://index.docker.io/v1/\n",
      "\n",
      "\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: placid_rail_m1lnvffzzm\n",
      "Web View: https://ml.azure.com/runs/placid_rail_m1lnvffzzm?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "def prepare_environment_image(\n",
    "    ml_client: MLClient,\n",
    "    environment: Environment,\n",
    "    compute_cluster: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Prepare environment image by submitting a minimal warm-up job if not already built.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        environment: Environment to prepare\n",
    "        compute_cluster: Compute cluster name for warm-up job\n",
    "        \n",
    "    Raises:\n",
    "        RuntimeError: If warm-up job fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        jobs = ml_client.jobs.list(\n",
    "            display_name=\"environment-warmup\",\n",
    "            list_view_type=\"All\",\n",
    "        )\n",
    "        for i, job in enumerate(jobs):\n",
    "            if i >= 10:\n",
    "                break\n",
    "            if (job.status == \"Completed\" and \n",
    "                hasattr(job, 'environment') and job.environment and\n",
    "                getattr(job.environment, 'name', None) == environment.name and\n",
    "                getattr(job.environment, 'version', None) == environment.version):\n",
    "                return\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    warmup_job = command(\n",
    "        code=\"../src\",\n",
    "        command=\"python -c 'import torch; print(f\\\"PyTorch: {torch.__version__}\\\"); print(\\\"Environment ready!\\\")'\",\n",
    "        environment=environment,\n",
    "        compute=compute_cluster,\n",
    "        display_name=\"environment-warmup\",\n",
    "        description=\"Warm-up job to prepare environment image before actual training\",\n",
    "    )\n",
    "    \n",
    "    submitted_warmup = ml_client.jobs.create_or_update(warmup_job)\n",
    "    ml_client.jobs.stream(submitted_warmup.name)\n",
    "    \n",
    "    completed_warmup = ml_client.jobs.get(submitted_warmup.name)\n",
    "    \n",
    "    if completed_warmup.status != \"Completed\":\n",
    "        raise RuntimeError(\n",
    "            f\"Environment warm-up job failed with status: {completed_warmup.status}. \"\n",
    "            f\"Check the job logs to diagnose environment build issues.\"\n",
    "        )\n",
    "\n",
    "\n",
    "prepare_environment_image(\n",
    "    ml_client=ml_client,\n",
    "    environment=training_environment,\n",
    "    compute_cluster=configs[\"env\"][\"compute\"][\"training_cluster\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.4: The Dry Run\n",
    "\n",
    "Submit a minimal sweep job using `smoke.yaml` to validate the sweep mechanism and pipeline integrity before launching the production HPO sweep.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.entities import Job\n",
    "from azure.ai.ml.sweep import SweepJob, Objective, SweepJobLimits, Choice, Uniform, LogUniform\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "TRAINING_SCRIPT_PATH = Path(\"../src/train.py\")\n",
    "DRY_RUN_JOB_NAME = \"dry-run-sweep\"\n",
    "SMOKE_HPO_CONFIG_PATH = Path(\"../config/hpo/smoke.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_space(hpo_config: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Convert HPO config to Azure ML search space format using proper search space objects.\n",
    "    \n",
    "    Args:\n",
    "        hpo_config: HPO configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        dict: Azure ML search space dictionary with Choice/Uniform/LogUniform objects\n",
    "    \"\"\"\n",
    "    search_space = {}\n",
    "    for param_name, param_config in hpo_config[\"search_space\"].items():\n",
    "        param_type = param_config[\"type\"]\n",
    "        if param_type == \"choice\":\n",
    "            search_space[param_name] = Choice(values=param_config[\"values\"])\n",
    "        elif param_type == \"uniform\":\n",
    "            search_space[param_name] = Uniform(\n",
    "                min_value=float(param_config[\"min\"]),\n",
    "                max_value=float(param_config[\"max\"]),\n",
    "            )\n",
    "        elif param_type == \"loguniform\":\n",
    "            search_space[param_name] = LogUniform(\n",
    "                min_value=float(param_config[\"min\"]),\n",
    "                max_value=float(param_config[\"max\"]),\n",
    "            )\n",
    "    return search_space\n",
    "\n",
    "\n",
    "def create_dry_run_sweep_job_for_backbone(\n",
    "    ml_client: MLClient,\n",
    "    script_path: Path,\n",
    "    data_asset: Data,\n",
    "    environment: Environment,\n",
    "    compute_cluster: str,\n",
    "    backbone: str,\n",
    "    configs: Dict[str, Any],\n",
    "    config_metadata: Dict[str, str],\n",
    ") -> SweepJob:\n",
    "    \"\"\"\n",
    "    Create a dry run Azure ML Sweep Job for a specific backbone model using smoke HPO config.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        script_path: Path to training script\n",
    "        data_asset: Registered data asset\n",
    "        environment: Training environment\n",
    "        compute_cluster: Compute cluster name\n",
    "        backbone: Backbone model name (e.g., \"distilbert\", \"deberta\")\n",
    "        configs: Configuration dictionaries\n",
    "        config_metadata: Configuration metadata for tagging\n",
    "        \n",
    "    Returns:\n",
    "        SweepJob: Azure ML Sweep Job definition\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If training script or smoke HPO config does not exist\n",
    "    \"\"\"\n",
    "    if not script_path.exists():\n",
    "        raise FileNotFoundError(f\"Training script not found: {script_path}\")\n",
    "    \n",
    "    smoke_hpo_config = load_config_file(SMOKE_HPO_CONFIG_PATH)\n",
    "    \n",
    "    smoke_hpo_config_without_backbone = {\n",
    "        \"search_space\": {\n",
    "            k: v for k, v in smoke_hpo_config[\"search_space\"].items() if k != \"backbone\"\n",
    "        }\n",
    "    }\n",
    "    search_space_without_backbone = create_search_space(smoke_hpo_config_without_backbone)\n",
    "    \n",
    "    dry_run_trials_per_backbone = max(2, smoke_hpo_config[\"sampling\"][\"max_trials\"] // 2)\n",
    "    \n",
    "    command_args = (\n",
    "        f\"--data-asset ${{{{inputs.data}}}} \"\n",
    "        f\"--config-dir config \"\n",
    "        f\"--backbone {backbone} \"\n",
    "        f\"--learning-rate ${{{{search_space.learning_rate}}}} \"\n",
    "        f\"--batch-size ${{{{search_space.batch_size}}}} \"\n",
    "        f\"--dropout ${{{{search_space.dropout}}}} \"\n",
    "        f\"--weight-decay ${{{{search_space.weight_decay}}}}\"\n",
    "    )\n",
    "    \n",
    "    # Use the registered data asset directly so AML resolves the datastore/paths\n",
    "    data_input = Input(\n",
    "        type=\"uri_folder\",\n",
    "        path=f\"azureml:{data_asset.name}:{data_asset.version}\",\n",
    "        mode=\"mount\",\n",
    "    )\n",
    "    \n",
    "    trial_job = command(\n",
    "        code=\"..\",\n",
    "        command=f\"python src/{script_path.name} {command_args}\",\n",
    "        inputs={\n",
    "            \"data\": data_input,\n",
    "        },\n",
    "        environment=environment,\n",
    "        compute=compute_cluster,\n",
    "    )\n",
    "    \n",
    "    objective = Objective(\n",
    "        goal=smoke_hpo_config[\"objective\"][\"goal\"],\n",
    "        primary_metric=smoke_hpo_config[\"objective\"][\"metric\"],\n",
    "    )\n",
    "    \n",
    "    timeout_seconds = smoke_hpo_config[\"sampling\"][\"timeout_minutes\"] * 60\n",
    "    limits = SweepJobLimits(\n",
    "        max_total_trials=dry_run_trials_per_backbone,\n",
    "        timeout=timeout_seconds,\n",
    "    )\n",
    "    \n",
    "    sweep_job = SweepJob(\n",
    "        trial=trial_job,\n",
    "        search_space=search_space_without_backbone,\n",
    "        sampling_algorithm=smoke_hpo_config[\"sampling\"][\"algorithm\"],\n",
    "        objective=objective,\n",
    "        limits=limits,\n",
    "        inputs={\n",
    "            \"data\": data_input,\n",
    "        },\n",
    "        experiment_name=f\"{configs['env']['logging']['experiment_name']}-{backbone}\",\n",
    "        tags={**config_metadata, \"job_type\": \"dry_run_sweep\", \"backbone\": backbone},\n",
    "        display_name=f\"{DRY_RUN_JOB_NAME}-{backbone}\",\n",
    "        description=f\"Dry run sweep to validate sweep mechanism for {backbone} before production HPO\",\n",
    "    )\n",
    "    \n",
    "    return sweep_job\n",
    "\n",
    "\n",
    "def submit_and_wait_for_job(ml_client: MLClient, job: Any) -> Job:\n",
    "    \"\"\"\n",
    "    Submit job and wait for completion.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        job: Job definition (command or sweep)\n",
    "        \n",
    "    Returns:\n",
    "        Job: Completed job instance\n",
    "        \n",
    "    Raises:\n",
    "        RuntimeError: If job fails\n",
    "    \"\"\"\n",
    "    submitted_job = ml_client.jobs.create_or_update(job)\n",
    "    ml_client.jobs.stream(submitted_job.name)\n",
    "    \n",
    "    completed_job = ml_client.jobs.get(submitted_job.name)\n",
    "    \n",
    "    if completed_job.status != \"Completed\":\n",
    "        raise RuntimeError(f\"Job {completed_job.name} failed with status: {completed_job.status}\")\n",
    "    \n",
    "    return completed_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quick data access smoke test (optional)\n",
    "# # Run this cell to verify the data asset is readable from the compute before launching sweeps.\n",
    "# from azure.ai.ml import command, Input\n",
    "\n",
    "# data_access_test_input = Input(\n",
    "#     type=\"uri_folder\",\n",
    "#     path=f\"azureml:{data_asset.name}:{data_asset.version}\",\n",
    "#     mode=\"mount\",\n",
    "# )\n",
    "\n",
    "# def run_data_access_smoke_test() -> Job:\n",
    "#     test_job = command(\n",
    "#         code=\"../src\",\n",
    "#         command=\"bash -c 'ls -R ${{inputs.data}} | head -n 200; echo DONE'\",\n",
    "#         inputs={\"data\": data_access_test_input},\n",
    "#         environment=training_environment,\n",
    "#         compute=compute_cluster_name,\n",
    "#         display_name=\"data-ls-test\",\n",
    "#         description=\"Smoke test to verify data asset is accessible from compute\",\n",
    "#     )\n",
    "#     submitted = ml_client.jobs.create_or_update(test_job)\n",
    "#     ml_client.jobs.stream(submitted.name)\n",
    "#     return ml_client.jobs.get(submitted.name)\n",
    "\n",
    "# # Uncomment to run the smoke test before dry run\n",
    "# data_ls_result = run_data_access_smoke_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate definition of create_dry_run_sweep_job_for_backbone removed - see cell with complete definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate definition of create_dry_run_sweep_job_for_backbone removed - see cell with complete definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cluster_name = configs[\"env\"][\"compute\"][\"training_cluster\"]\n",
    "\n",
    "try:\n",
    "    compute_cluster = ml_client.compute.get(compute_cluster_name)\n",
    "    if compute_cluster.provisioning_state != \"Succeeded\":\n",
    "        raise ValueError(f\"Compute cluster not ready: {compute_cluster.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Compute cluster '{compute_cluster_name}' not accessible: {e}\")\n",
    "\n",
    "smoke_hpo_config = load_config_file(SMOKE_HPO_CONFIG_PATH)\n",
    "backbone_values = smoke_hpo_config[\"search_space\"][\"backbone\"][\"values\"]\n",
    "dry_run_sweep_jobs = {}\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    dry_run_sweep_jobs[backbone] = create_dry_run_sweep_job_for_backbone(\n",
    "        ml_client=ml_client,\n",
    "        script_path=TRAINING_SCRIPT_PATH,\n",
    "        data_asset=data_asset,\n",
    "        environment=training_environment,\n",
    "        compute_cluster=compute_cluster_name,\n",
    "        backbone=backbone,\n",
    "        configs=configs,\n",
    "        config_metadata=config_metadata,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your file exceeds 100 MB. If you experience low speeds, latency, or broken connections, we recommend using the AzCopyv10 tool for this file transfer.\n",
      "\n",
      "Example: azcopy copy '/workspaces/resume-ner-azureml' 'https://resumenestoragec054f3d6e.blob.core.windows.net/b64e60f9-615d-4178-8435-31f534cd62a6-b5xtlym3429ijxbdu1o9oqbmf7/resume-ner-azureml' \n",
      "\n",
      "See https://learn.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n",
      "\u001b[32mUploading resume-ner-azureml (266.96 MBs): 100%|██████████| 266964097/266964097 [00:08<00:00, 33219025.66it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: ashy_cart_0dz2fx6mqk\n",
      "Web View: https://ml.azure.com/runs/ashy_cart_0dz2fx6mqk?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "[2025-12-15T23:14:23.1331257Z][GENERATOR][DEBUG]Sampled 2 jobs from search space \n",
      "[2025-12-15T23:14:23.4999614Z][SCHEDULER][INFO]Scheduling job, id='ashy_cart_0dz2fx6mqk_0' \n",
      "[2025-12-15T23:14:23.5580663Z][SCHEDULER][INFO]Scheduling job, id='ashy_cart_0dz2fx6mqk_1' \n",
      "[2025-12-15T23:14:24.5212315Z][SCHEDULER][INFO]Successfully scheduled a job. Id='ashy_cart_0dz2fx6mqk_1' \n",
      "[2025-12-15T23:14:24.5501551Z][SCHEDULER][INFO]Successfully scheduled a job. Id='ashy_cart_0dz2fx6mqk_0' \n",
      "[2025-12-15T23:14:53.7200051Z][GENERATOR][DEBUG]Setting all jobs generated as True, reason : Max number of jobs reached \n",
      "[2025-12-15T23:18:54.0876182Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: ashy_cart_0dz2fx6mqk\n",
      "Web View: https://ml.azure.com/runs/ashy_cart_0dz2fx6mqk?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def validate_dry_run_sweep_job(job: Job, backbone: str) -> None:\n",
    "    \"\"\"\n",
    "    Validate dry run sweep job completed successfully.\n",
    "    Falls back to counting child runs if trial_count is missing/zero.\n",
    "    \n",
    "    Args:\n",
    "        job: Completed sweep job instance\n",
    "        backbone: Backbone model name for error messages\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If validation fails\n",
    "    \"\"\"\n",
    "    if job.status != \"Completed\":\n",
    "        raise ValueError(f\"Dry run sweep job for {backbone} failed with status: {job.status}\")\n",
    "\n",
    "    child_count = None\n",
    "    try:\n",
    "        children = list(ml_client.jobs.list(parent_job_name=job.name))\n",
    "        child_count = len(children)\n",
    "    except Exception:\n",
    "        child_count = None\n",
    "\n",
    "    if hasattr(job, \"trial_count\") and job.trial_count and job.trial_count > 0:\n",
    "        return\n",
    "    if child_count is not None and child_count > 0:\n",
    "        return\n",
    "\n",
    "    raise ValueError(\n",
    "        f\"Dry run sweep job for {backbone} produced no trials (parent run: {job.name}). \"\n",
    "        f\"Check hyperdrive logs and child runs in portal.\"\n",
    "    )\n",
    "\n",
    "\n",
    "dry_run_completed_jobs = {}\n",
    "\n",
    "for backbone, sweep_job in dry_run_sweep_jobs.items():\n",
    "    completed_job = submit_and_wait_for_job(ml_client, sweep_job)\n",
    "    validate_dry_run_sweep_job(completed_job, backbone)\n",
    "    dry_run_completed_jobs[backbone] = completed_job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.5: The Sweep (HPO)\n",
    "\n",
    "Submit a hyperparameter optimization sweep to systematically search for the best model configuration.\n",
    "\n",
    "**Note**: Currently using `smoke.yaml` for demonstration purposes (CPU-only setup). For production with GPU, switch to `prod.yaml` in the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPO_SWEEP_JOB_NAME = \"hpo-sweep\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hpo_sweep_job_for_backbone(\n",
    "    ml_client: MLClient,\n",
    "    script_path: Path,\n",
    "    data_asset: Data,\n",
    "    environment: Environment,\n",
    "    compute_cluster: str,\n",
    "    hpo_config: Dict[str, Any],\n",
    "    backbone: str,\n",
    "    configs: Dict[str, Any],\n",
    "    config_metadata: Dict[str, str],\n",
    ") -> SweepJob:\n",
    "    \"\"\"\n",
    "    Create a production HPO sweep job for a specific backbone model.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        script_path: Path to training script\n",
    "        data_asset: Registered data asset\n",
    "        environment: Training environment\n",
    "        compute_cluster: Compute cluster name\n",
    "        hpo_config: HPO configuration dictionary (from prod.yaml)\n",
    "        backbone: Backbone model name (e.g., \"distilbert\", \"deberta\")\n",
    "        configs: Configuration dictionaries\n",
    "        config_metadata: Configuration metadata for tagging\n",
    "        \n",
    "    Returns:\n",
    "        SweepJob: Azure ML Sweep Job definition\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If training script does not exist\n",
    "    \"\"\"\n",
    "    if not script_path.exists():\n",
    "        raise FileNotFoundError(f\"Training script not found: {script_path}\")\n",
    "    \n",
    "    hpo_config_without_backbone = {\n",
    "        \"search_space\": {\n",
    "            k: v for k, v in hpo_config[\"search_space\"].items() if k != \"backbone\"\n",
    "        }\n",
    "    }\n",
    "    search_space_without_backbone = create_search_space(hpo_config_without_backbone)\n",
    "    \n",
    "    command_args = (\n",
    "        f\"--data-asset ${{{{inputs.data}}}} \"\n",
    "        f\"--config-dir config \"\n",
    "        f\"--backbone {backbone} \"\n",
    "        f\"--learning-rate ${{{{search_space.learning_rate}}}} \"\n",
    "        f\"--batch-size ${{{{search_space.batch_size}}}} \"\n",
    "        f\"--dropout ${{{{search_space.dropout}}}} \"\n",
    "        f\"--weight-decay ${{{{search_space.weight_decay}}}}\"\n",
    "    )\n",
    "    \n",
    "    data_input = Input(\n",
    "        type=\"uri_folder\",\n",
    "        path=f\"azureml:{data_asset.name}:{data_asset.version}\",\n",
    "        mode=\"mount\",\n",
    "    )\n",
    "    \n",
    "    trial_job = command(\n",
    "        code=\"..\",\n",
    "        command=f\"python src/{script_path.name} {command_args}\",\n",
    "        inputs={\n",
    "            \"data\": data_input,\n",
    "        },\n",
    "        environment=environment,\n",
    "        compute=compute_cluster,\n",
    "    )\n",
    "    \n",
    "    objective = Objective(\n",
    "        goal=hpo_config[\"objective\"][\"goal\"],\n",
    "        primary_metric=hpo_config[\"objective\"][\"metric\"],\n",
    "    )\n",
    "    \n",
    "    timeout_seconds = hpo_config[\"sampling\"][\"timeout_minutes\"] * 60\n",
    "    limits = SweepJobLimits(\n",
    "        max_total_trials=hpo_config[\"sampling\"][\"max_trials\"],\n",
    "        timeout=timeout_seconds,\n",
    "    )\n",
    "    \n",
    "    early_termination = None\n",
    "    if \"early_termination\" in hpo_config:\n",
    "        et_config = hpo_config[\"early_termination\"]\n",
    "        if et_config.get(\"policy\") == \"bandit\":\n",
    "            from azure.ai.ml.sweep import BanditPolicy\n",
    "            early_termination = BanditPolicy(\n",
    "                evaluation_interval=et_config[\"evaluation_interval\"],\n",
    "                slack_factor=et_config[\"slack_factor\"],\n",
    "                delay_evaluation=et_config[\"delay_evaluation\"],\n",
    "            )\n",
    "    \n",
    "    sweep_job = SweepJob(\n",
    "        trial=trial_job,\n",
    "        search_space=search_space_without_backbone,\n",
    "        sampling_algorithm=hpo_config[\"sampling\"][\"algorithm\"],\n",
    "        objective=objective,\n",
    "        limits=limits,\n",
    "        early_termination=early_termination,\n",
    "        compute=compute_cluster,\n",
    "        inputs={\n",
    "            \"data\": data_input,\n",
    "        },\n",
    "        experiment_name=f\"{configs['env']['logging']['experiment_name']}-{backbone}\",\n",
    "        tags={**config_metadata, \"job_type\": \"hpo_sweep\", \"backbone\": backbone},\n",
    "        display_name=f\"{HPO_SWEEP_JOB_NAME}-{backbone}\",\n",
    "        description=f\"Production hyperparameter optimization sweep for {backbone}\",\n",
    "    )\n",
    "    \n",
    "    return sweep_job\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cluster_name = configs[\"env\"][\"compute\"][\"training_cluster\"]\n",
    "\n",
    "try:\n",
    "    compute_cluster = ml_client.compute.get(compute_cluster_name)\n",
    "    if compute_cluster.provisioning_state != \"Succeeded\":\n",
    "        raise ValueError(f\"Compute cluster not ready: {compute_cluster.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Compute cluster '{compute_cluster_name}' not accessible: {e}\")\n",
    "\n",
    "backbone_values = configs[\"hpo\"][\"search_space\"][\"backbone\"][\"values\"]\n",
    "hpo_sweep_jobs = {}\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    hpo_sweep_jobs[backbone] = create_hpo_sweep_job_for_backbone(\n",
    "        ml_client=ml_client,\n",
    "        script_path=TRAINING_SCRIPT_PATH,\n",
    "        data_asset=data_asset,\n",
    "        environment=training_environment,\n",
    "        compute_cluster=compute_cluster_name,\n",
    "        hpo_config=configs[\"hpo\"],\n",
    "        backbone=backbone,\n",
    "        configs=configs,\n",
    "        config_metadata=config_metadata,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your file exceeds 100 MB. If you experience low speeds, latency, or broken connections, we recommend using the AzCopyv10 tool for this file transfer.\n",
      "\n",
      "Example: azcopy copy '/workspaces/resume-ner-azureml' 'https://resumenestoragec054f3d6e.blob.core.windows.net/b64e60f9-615d-4178-8435-31f534cd62a6-diwtdop97akzn3qtalkwdzmpmf/resume-ner-azureml' \n",
      "\n",
      "See https://learn.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n",
      "\u001b[32mUploading resume-ner-azureml (266.97 MBs): 100%|██████████| 266974083/266974083 [00:08<00:00, 32727837.68it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: boring_pot_hpwhjfdxb8\n",
      "Web View: https://ml.azure.com/runs/boring_pot_hpwhjfdxb8?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n"
     ]
    }
   ],
   "source": [
    "def validate_hpo_sweep_job(job: Job, backbone: str) -> None:\n",
    "    \"\"\"\n",
    "    Validate HPO sweep job completed successfully with sufficient trials.\n",
    "    \n",
    "    Args:\n",
    "        job: Completed sweep job instance\n",
    "        backbone: Backbone model name for error messages\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If validation fails\n",
    "    \"\"\"\n",
    "    if job.status != \"Completed\":\n",
    "        raise ValueError(f\"HPO sweep job for {backbone} failed with status: {job.status}\")\n",
    "    \n",
    "    if not hasattr(job, \"trial_count\") or job.trial_count == 0:\n",
    "        raise ValueError(f\"HPO sweep job for {backbone} produced no trials\")\n",
    "    \n",
    "    min_expected_trials = 5\n",
    "    if job.trial_count < min_expected_trials:\n",
    "        raise ValueError(\n",
    "            f\"HPO sweep job for {backbone} only produced {job.trial_count} trial(s), \"\n",
    "            f\"expected at least {min_expected_trials}\"\n",
    "        )\n",
    "\n",
    "\n",
    "hpo_completed_jobs = {}\n",
    "\n",
    "for backbone, sweep_job in hpo_sweep_jobs.items():\n",
    "    completed_job = submit_and_wait_for_job(ml_client, sweep_job)\n",
    "    validate_hpo_sweep_job(completed_job, backbone)\n",
    "    hpo_completed_jobs[backbone] = completed_job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.6: Best Configuration Selection (Automated)\n",
    "\n",
    "Programmatically select the best configuration from all HPO sweep runs across all backbone models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "BEST_CONFIG_KEY = \"best_config\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_trial_from_sweep(ml_client: MLClient, sweep_job: Job, objective_metric: str, goal: str) -> Optional[Job]:\n",
    "    \"\"\"\n",
    "    Get the best trial run from a completed sweep job.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        sweep_job: Completed sweep job\n",
    "        objective_metric: Metric name to optimize (e.g., \"macro-f1\")\n",
    "        goal: Optimization goal (\"maximize\" or \"minimize\")\n",
    "        \n",
    "    Returns:\n",
    "        Job: Best trial run, or None if no trials found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        trials = ml_client.jobs.list(parent_job_name=sweep_job.name)\n",
    "        trials_list = list(trials)\n",
    "        \n",
    "        if not trials_list:\n",
    "            return None\n",
    "        \n",
    "        best_trial = None\n",
    "        best_value = None\n",
    "        \n",
    "        for trial in trials_list:\n",
    "            if trial.status != \"Completed\":\n",
    "                continue\n",
    "            \n",
    "            if not hasattr(trial, \"metrics\") or not trial.metrics:\n",
    "                continue\n",
    "            \n",
    "            if objective_metric not in trial.metrics:\n",
    "                continue\n",
    "            \n",
    "            metric_value = trial.metrics[objective_metric]\n",
    "            \n",
    "            if best_value is None:\n",
    "                best_value = metric_value\n",
    "                best_trial = trial\n",
    "            elif goal == \"maximize\" and metric_value > best_value:\n",
    "                best_value = metric_value\n",
    "                best_trial = trial\n",
    "            elif goal == \"minimize\" and metric_value < best_value:\n",
    "                best_value = metric_value\n",
    "                best_trial = trial\n",
    "        \n",
    "        return best_trial\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_trial_configuration(trial: Job) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract configuration from a trial run.\n",
    "    \n",
    "    Args:\n",
    "        trial: Trial job instance\n",
    "        \n",
    "    Returns:\n",
    "        dict: Extracted configuration including hyperparameters and metadata\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"trial_name\": trial.name,\n",
    "        \"trial_id\": trial.id,\n",
    "        \"backbone\": trial.tags.get(\"backbone\", \"unknown\"),\n",
    "        \"hyperparameters\": {},\n",
    "        \"metrics\": {},\n",
    "        \"dataset_version\": trial.tags.get(\"data_version\", configs[\"data\"][\"version\"]),\n",
    "    }\n",
    "    \n",
    "    if hasattr(trial, \"hyperparameters\") and trial.hyperparameters:\n",
    "        config[\"hyperparameters\"] = dict(trial.hyperparameters)\n",
    "    \n",
    "    if hasattr(trial, \"metrics\") and trial.metrics:\n",
    "        config[\"metrics\"] = dict(trial.metrics)\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "def select_best_configuration(\n",
    "    ml_client: MLClient,\n",
    "    hpo_completed_jobs: Dict[str, Job],\n",
    "    hpo_config: Dict[str, Any],\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Select the best configuration across all backbone sweep jobs.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        hpo_completed_jobs: Dictionary of completed sweep jobs by backbone\n",
    "        hpo_config: HPO configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        dict: Best configuration with all extracted information\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If no valid trials found or selection fails\n",
    "    \"\"\"\n",
    "    objective_metric = hpo_config[\"objective\"][\"metric\"]\n",
    "    goal = hpo_config[\"objective\"][\"goal\"]\n",
    "    \n",
    "    best_trial = None\n",
    "    best_value = None\n",
    "    best_backbone = None\n",
    "    \n",
    "    for backbone, sweep_job in hpo_completed_jobs.items():\n",
    "        trial = get_best_trial_from_sweep(ml_client, sweep_job, objective_metric, goal)\n",
    "        \n",
    "        if trial is None:\n",
    "            continue\n",
    "        \n",
    "        if not hasattr(trial, \"metrics\") or objective_metric not in trial.metrics:\n",
    "            continue\n",
    "        \n",
    "        metric_value = trial.metrics[objective_metric]\n",
    "        \n",
    "        if best_value is None:\n",
    "            best_value = metric_value\n",
    "            best_trial = trial\n",
    "            best_backbone = backbone\n",
    "        elif goal == \"maximize\" and metric_value > best_value:\n",
    "            best_value = metric_value\n",
    "            best_trial = trial\n",
    "            best_backbone = backbone\n",
    "        elif goal == \"minimize\" and metric_value < best_value:\n",
    "            best_value = metric_value\n",
    "            best_trial = trial\n",
    "            best_backbone = backbone\n",
    "    \n",
    "    if best_trial is None:\n",
    "        raise ValueError(\"No valid trials found in any sweep job\")\n",
    "    \n",
    "    best_config = extract_trial_configuration(best_trial)\n",
    "    best_config[\"selection_criteria\"] = {\n",
    "        \"metric\": objective_metric,\n",
    "        \"goal\": goal,\n",
    "        \"best_value\": best_value,\n",
    "        \"backbone\": best_backbone,\n",
    "    }\n",
    "    \n",
    "    return best_config\n",
    "\n",
    "\n",
    "best_configuration = select_best_configuration(\n",
    "    ml_client=ml_client,\n",
    "    hpo_completed_jobs=hpo_completed_jobs,\n",
    "    hpo_config=configs[\"hpo\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_best_configuration(best_config: Dict[str, Any]) -> None:    \"\"\"    Log the best configuration selection for reproducibility.        Args:        best_config: Best configuration dictionary    \"\"\"    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.7: Final Training (Post-HPO, Single Run)\n",
    "\n",
    "Train the final production model using the best configuration from HPO with stable, controlled conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_TRAINING_JOB_NAME = \"final-training\"\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_final_training_config(\n",
    "    best_config: Dict[str, Any],\n",
    "    train_config: Dict[str, Any],\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Build final training configuration by merging best HPO config with train.yaml defaults.\n",
    "    \n",
    "    Args:\n",
    "        best_config: Best configuration from HPO selection\n",
    "        train_config: Training defaults from train.yaml\n",
    "        \n",
    "    Returns:\n",
    "        dict: Final training configuration\n",
    "    \"\"\"\n",
    "    hyperparameters = best_config.get(\"hyperparameters\", {})\n",
    "    \n",
    "    final_config = {\n",
    "        \"backbone\": best_config[\"backbone\"],\n",
    "        \"learning_rate\": hyperparameters.get(\"learning_rate\", train_config[\"training\"][\"learning_rate\"]),\n",
    "        \"batch_size\": hyperparameters.get(\"batch_size\", train_config[\"training\"][\"batch_size\"]),\n",
    "        \"dropout\": hyperparameters.get(\"dropout\", train_config[\"training\"].get(\"dropout\", 0.1)),\n",
    "        \"weight_decay\": hyperparameters.get(\"weight_decay\", train_config[\"training\"][\"weight_decay\"]),\n",
    "        \"epochs\": train_config[\"training\"][\"epochs\"],\n",
    "        \"random_seed\": RANDOM_SEED,\n",
    "        \"early_stopping_enabled\": False,\n",
    "        \"use_combined_data\": True,\n",
    "    }\n",
    "    \n",
    "    return final_config\n",
    "\n",
    "\n",
    "final_training_config = build_final_training_config(best_configuration, configs[\"train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_training_job(\n",
    "    ml_client: MLClient,\n",
    "    script_path: Path,\n",
    "    data_asset: Data,\n",
    "    environment: Environment,\n",
    "    compute_cluster: str,\n",
    "    final_config: Dict[str, Any],\n",
    "    configs: Dict[str, Any],\n",
    "    config_metadata: Dict[str, str],\n",
    ") -> command:\n",
    "    \"\"\"\n",
    "    Create final training Azure ML Command Job with best HPO configuration.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        script_path: Path to training script\n",
    "        data_asset: Registered data asset\n",
    "        environment: Training environment\n",
    "        compute_cluster: Compute cluster name\n",
    "        final_config: Final training configuration\n",
    "        configs: Configuration dictionaries\n",
    "        config_metadata: Configuration metadata for tagging\n",
    "        \n",
    "    Returns:\n",
    "        command: Azure ML Command Job definition\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If training script does not exist\n",
    "    \"\"\"\n",
    "    if not script_path.exists():\n",
    "        raise FileNotFoundError(f\"Training script not found: {script_path}\")\n",
    "    \n",
    "    command_args = (\n",
    "        f\"--data-asset ${{{{inputs.data}}}} \"\n",
    "        f\"--config-dir ../config \"\n",
    "        f\"--backbone {final_config['backbone']} \"\n",
    "        f\"--learning-rate {final_config['learning_rate']} \"\n",
    "        f\"--batch-size {final_config['batch_size']} \"\n",
    "        f\"--dropout {final_config['dropout']} \"\n",
    "        f\"--weight-decay {final_config['weight_decay']} \"\n",
    "        f\"--epochs {final_config['epochs']} \"\n",
    "        f\"--random-seed {final_config['random_seed']} \"\n",
    "        f\"--early-stopping-enabled {str(final_config['early_stopping_enabled']).lower()} \"\n",
    "        f\"--use-combined-data {str(final_config['use_combined_data']).lower()}\"\n",
    "    )\n",
    "    \n",
    "    default_datastore = ml_client.datastores.get_default()\n",
    "    if \"/paths/\" in data_asset.path:\n",
    "        relative_path = data_asset.path.split(\"/paths/\", 1)[1].rstrip('/')\n",
    "        data_path = f\"azureml://datastores/{default_datastore.name}/paths/{relative_path}\"\n",
    "    else:\n",
    "        data_path = data_asset.path.rstrip('/')\n",
    "    \n",
    "    data_input = Input(type=\"uri_folder\", path=data_path)\n",
    "    \n",
    "    job = command(\n",
    "        code=\"../src\",\n",
    "        command=f\"python {script_path.name} {command_args}\",\n",
    "        inputs={\n",
    "            \"data\": data_input,\n",
    "        },\n",
    "        environment=environment,\n",
    "        compute=compute_cluster,\n",
    "        experiment_name=configs[\"env\"][\"logging\"][\"experiment_name\"],\n",
    "        tags={\n",
    "            **config_metadata,\n",
    "            \"job_type\": \"final_training\",\n",
    "            \"backbone\": final_config[\"backbone\"],\n",
    "            \"best_trial\": best_configuration[\"trial_name\"],\n",
    "            \"best_metric_value\": str(best_configuration[\"selection_criteria\"][\"best_value\"]),\n",
    "        },\n",
    "        display_name=FINAL_TRAINING_JOB_NAME,\n",
    "        description=\"Final production training with best HPO configuration\",\n",
    "    )\n",
    "    \n",
    "    return job\n",
    "\n",
    "\n",
    "final_training_job = create_final_training_job(\n",
    "    ml_client=ml_client,\n",
    "    script_path=TRAINING_SCRIPT_PATH,\n",
    "    data_asset=data_asset,\n",
    "    environment=training_environment,\n",
    "    compute_cluster=compute_cluster_name,\n",
    "    final_config=final_training_config,\n",
    "    configs=configs,\n",
    "    config_metadata=config_metadata,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_final_training_job(job: Job) -> None:\n",
    "    \"\"\"\n",
    "    Validate final training job completed successfully with required outputs.\n",
    "    \n",
    "    Args:\n",
    "        job: Completed job instance\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If validation fails\n",
    "    \"\"\"\n",
    "    if job.status != \"Completed\":\n",
    "        raise ValueError(f\"Final training job failed with status: {job.status}\")\n",
    "    \n",
    "    if not hasattr(job, \"outputs\") or not job.outputs:\n",
    "        raise ValueError(\"Final training job produced no outputs\")\n",
    "    \n",
    "    required_outputs = [\"checkpoint\"]\n",
    "    for output_name in required_outputs:\n",
    "        if output_name not in job.outputs:\n",
    "            raise ValueError(f\"Final training job missing required output: {output_name}\")\n",
    "\n",
    "\n",
    "final_training_completed_job = submit_and_wait_for_job(ml_client, final_training_job)\n",
    "validate_final_training_job(final_training_completed_job)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-4: Model Conversion & Optimization\n",
    "\n",
    "Convert the final training checkpoint to an optimized ONNX model (int8 quantized) for production inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVERSION_SCRIPT_PATH = Path(\"../src/convert_to_onnx.py\")\n",
    "CONVERSION_JOB_NAME = \"model-conversion\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoint_output_from_training_job(training_job: Job):\n",
    "    \"\"\"\n",
    "    Get checkpoint output object from completed training job.\n",
    "    \n",
    "    Args:\n",
    "        training_job: Completed training job\n",
    "        \n",
    "    Returns:\n",
    "        Checkpoint output object\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If checkpoint not found in job outputs\n",
    "    \"\"\"\n",
    "    if not hasattr(training_job, \"outputs\") or not training_job.outputs:\n",
    "        raise ValueError(\"Training job produced no outputs\")\n",
    "    \n",
    "    if \"checkpoint\" not in training_job.outputs:\n",
    "        raise ValueError(\"Training job missing 'checkpoint' output\")\n",
    "    \n",
    "    return training_job.outputs[\"checkpoint\"]\n",
    "\n",
    "\n",
    "checkpoint_output = get_checkpoint_output_from_training_job(final_training_completed_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversion_job(\n",
    "    ml_client: MLClient,\n",
    "    script_path: Path,\n",
    "    checkpoint_output,\n",
    "    environment: Environment,\n",
    "    compute_cluster: str,\n",
    "    configs: Dict[str, Any],\n",
    "    config_metadata: Dict[str, str],\n",
    "    best_config: Dict[str, Any],\n",
    ") -> command:\n",
    "    \"\"\"\n",
    "    Create Azure ML Command Job for model conversion to ONNX with int8 quantization.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        script_path: Path to conversion script\n",
    "        checkpoint_output: Checkpoint output from training job\n",
    "        environment: Training environment (reused for conversion)\n",
    "        compute_cluster: CPU compute cluster name\n",
    "        configs: Configuration dictionaries\n",
    "        config_metadata: Configuration metadata for tagging\n",
    "        best_config: Best configuration from HPO selection\n",
    "        \n",
    "    Returns:\n",
    "        command: Azure ML Command Job definition\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If conversion script does not exist\n",
    "    \"\"\"\n",
    "    if not script_path.exists():\n",
    "        raise FileNotFoundError(f\"Conversion script not found: {script_path}\")\n",
    "    \n",
    "    command_args = (\n",
    "        f\"--checkpoint-path ${{{{inputs.checkpoint}}}} \"\n",
    "        f\"--config-dir ../config \"\n",
    "        f\"--backbone {best_config['backbone']} \"\n",
    "        f\"--output-dir ${{{{outputs.onnx_model}}}} \"\n",
    "        f\"--quantize-int8 \"\n",
    "        f\"--run-smoke-test\"\n",
    "    )\n",
    "    \n",
    "    job = command(\n",
    "        code=\"../src\",\n",
    "        command=f\"python {script_path.name} {command_args}\",\n",
    "        inputs={\n",
    "            \"checkpoint\": checkpoint_output,\n",
    "        },\n",
    "        outputs={\n",
    "            \"onnx_model\": None,\n",
    "        },\n",
    "        environment=environment,\n",
    "        compute=compute_cluster,\n",
    "        experiment_name=configs[\"env\"][\"logging\"][\"experiment_name\"],\n",
    "        tags={\n",
    "            **config_metadata,\n",
    "            \"job_type\": \"model_conversion\",\n",
    "            \"backbone\": best_config[\"backbone\"],\n",
    "            \"source_training_job\": final_training_completed_job.name,\n",
    "            \"quantization\": \"int8\",\n",
    "        },\n",
    "        display_name=CONVERSION_JOB_NAME,\n",
    "        description=\"Convert PyTorch checkpoint to optimized ONNX model (int8 quantized)\",\n",
    "    )\n",
    "    \n",
    "    return job\n",
    "\n",
    "\n",
    "conversion_cluster_name = configs[\"env\"][\"compute\"][\"conversion_cluster\"]\n",
    "conversion_job = create_conversion_job(\n",
    "    ml_client=ml_client,\n",
    "    script_path=CONVERSION_SCRIPT_PATH,\n",
    "    checkpoint_output=checkpoint_output,\n",
    "    environment=training_environment,\n",
    "    compute_cluster=conversion_cluster_name,\n",
    "    configs=configs,\n",
    "    config_metadata=config_metadata,\n",
    "    best_config=best_configuration,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_conversion_job(job: Job) -> None:\n",
    "    \"\"\"\n",
    "    Validate conversion job completed successfully with required ONNX model output.\n",
    "    \n",
    "    Args:\n",
    "        job: Completed job instance\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If validation fails\n",
    "    \"\"\"\n",
    "    if job.status != \"Completed\":\n",
    "        raise ValueError(f\"Conversion job failed with status: {job.status}\")\n",
    "    \n",
    "    if not hasattr(job, \"outputs\") or not job.outputs:\n",
    "        raise ValueError(\"Conversion job produced no outputs\")\n",
    "    \n",
    "    if \"onnx_model\" not in job.outputs:\n",
    "        raise ValueError(\"Conversion job missing required output: onnx_model\")\n",
    "    \n",
    "    onnx_output = job.outputs[\"onnx_model\"]\n",
    "    if hasattr(onnx_output, \"path\"):\n",
    "        onnx_path = onnx_output.path\n",
    "    elif isinstance(onnx_output, str):\n",
    "        onnx_path = onnx_output\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected ONNX output type: {type(onnx_output)}\")\n",
    "    \n",
    "    if not onnx_path or not onnx_path.endswith(\".onnx\"):\n",
    "        raise ValueError(f\"Invalid ONNX model path: {onnx_path}\")\n",
    "\n",
    "\n",
    "conversion_completed_job = submit_and_wait_for_job(ml_client, conversion_job)\n",
    "validate_conversion_job(conversion_completed_job)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-5: Model Registration (The Handover)\n",
    "\n",
    "Register the optimized ONNX model in Azure ML Model Registry with full metadata for production deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "MODEL_NAME = \"resume-ner-onnx\"\n",
    "PROD_STAGE = \"prod\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onnx_model_path(conversion_job: Job) -> str:\n",
    "    \"\"\"\n",
    "    Get ONNX model path from completed conversion job.\n",
    "    \n",
    "    Args:\n",
    "        conversion_job: Completed conversion job\n",
    "        \n",
    "    Returns:\n",
    "        str: ONNX model path (Azure ML datastore URI)\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If ONNX model not found in job outputs\n",
    "    \"\"\"\n",
    "    if not hasattr(conversion_job, \"outputs\") or not conversion_job.outputs:\n",
    "        raise ValueError(\"Conversion job produced no outputs\")\n",
    "    \n",
    "    if \"onnx_model\" not in conversion_job.outputs:\n",
    "        raise ValueError(\"Conversion job missing 'onnx_model' output\")\n",
    "    \n",
    "    onnx_output = conversion_job.outputs[\"onnx_model\"]\n",
    "    \n",
    "    if hasattr(onnx_output, \"path\"):\n",
    "        return onnx_output.path\n",
    "    elif isinstance(onnx_output, str):\n",
    "        return onnx_output\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected ONNX output type: {type(onnx_output)}\")\n",
    "\n",
    "\n",
    "onnx_model_path = get_onnx_model_path(conversion_completed_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_version(best_config: Dict[str, Any], config_hashes: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Compute deterministic model version from configuration hashes.\n",
    "    \n",
    "    Args:\n",
    "        best_config: Best configuration from HPO selection\n",
    "        config_hashes: Configuration hashes dictionary\n",
    "        \n",
    "    Returns:\n",
    "        str: Model version string\n",
    "    \"\"\"\n",
    "    version_components = [\n",
    "        config_hashes[\"data\"],\n",
    "        config_hashes[\"model\"],\n",
    "        config_hashes[\"train\"],\n",
    "        best_config[\"backbone\"],\n",
    "    ]\n",
    "    version_str = \"_\".join(version_components)\n",
    "    version_hash = hashlib.sha256(version_str.encode()).hexdigest()[:CONFIG_HASH_LENGTH]\n",
    "    return f\"v{version_hash}\"\n",
    "\n",
    "\n",
    "model_version = compute_model_version(best_configuration, config_hashes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_production_model(\n",
    "    ml_client: MLClient,\n",
    "    model_name: str,\n",
    "    model_version: str,\n",
    "    model_path: str,\n",
    "    best_config: Dict[str, Any],\n",
    "    configs: Dict[str, Any],\n",
    "    config_metadata: Dict[str, str],\n",
    ") -> Model:\n",
    "    \"\"\"\n",
    "    Register optimized ONNX model in Azure ML Model Registry.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        model_name: Model name in registry\n",
    "        model_version: Model version\n",
    "        model_path: Path to ONNX model (Azure ML datastore URI)\n",
    "        best_config: Best configuration from HPO selection\n",
    "        configs: Configuration dictionaries\n",
    "        config_metadata: Configuration metadata for tagging\n",
    "        \n",
    "    Returns:\n",
    "        Model: Registered model instance\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If model path is invalid\n",
    "    \"\"\"\n",
    "    if not model_path or not model_path.endswith(\".onnx\"):\n",
    "        raise ValueError(f\"Invalid ONNX model path: {model_path}\")\n",
    "    \n",
    "    selection_criteria = best_config[\"selection_criteria\"]\n",
    "    \n",
    "    model_description = (\n",
    "        f\"Production ONNX model for Resume NER. \"\n",
    "        f\"Backbone: {selection_criteria['backbone']}, \"\n",
    "        f\"Metric: {selection_criteria['metric']}={selection_criteria['best_value']:.4f}\"\n",
    "    )\n",
    "    \n",
    "    model_tags = {\n",
    "        **config_metadata,\n",
    "        \"stage\": PROD_STAGE,\n",
    "        \"backbone\": selection_criteria[\"backbone\"],\n",
    "        \"metric\": selection_criteria[\"metric\"],\n",
    "        \"metric_value\": str(selection_criteria[\"best_value\"]),\n",
    "        \"dataset_version\": best_config[\"dataset_version\"],\n",
    "        \"model_format\": \"onnx\",\n",
    "        \"quantization\": \"int8\",\n",
    "        \"source_training_job\": final_training_completed_job.name,\n",
    "        \"source_conversion_job\": conversion_completed_job.name,\n",
    "    }\n",
    "    \n",
    "    model = Model(\n",
    "        name=model_name,\n",
    "        version=model_version,\n",
    "        description=model_description,\n",
    "        path=model_path,\n",
    "        tags=model_tags,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        existing_model = ml_client.models.get(name=model_name, version=model_version)\n",
    "        return existing_model\n",
    "    except ResourceNotFoundError:\n",
    "        return ml_client.models.create_or_update(model)\n",
    "\n",
    "\n",
    "registered_model = register_production_model(\n",
    "    ml_client=ml_client,\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=model_version,\n",
    "    model_path=onnx_model_path,\n",
    "    best_config=best_configuration,\n",
    "    configs=configs,\n",
    "    config_metadata=config_metadata,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_registered_model(model: Model) -> None:\n",
    "    \"\"\"\n",
    "    Validate registered model has required metadata and tags.\n",
    "    \n",
    "    Args:\n",
    "        model: Registered model instance\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If validation fails\n",
    "    \"\"\"\n",
    "    required_tags = [\"stage\", \"backbone\", \"metric\", \"dataset_version\"]\n",
    "    for tag in required_tags:\n",
    "        if tag not in model.tags:\n",
    "            raise ValueError(f\"Registered model missing required tag: {tag}\")\n",
    "    \n",
    "    if model.tags.get(\"stage\") != PROD_STAGE:\n",
    "        raise ValueError(f\"Model stage must be '{PROD_STAGE}', got: {model.tags.get('stage')}\")\n",
    "    \n",
    "    if not model.path or not model.path.endswith(\".onnx\"):\n",
    "        raise ValueError(f\"Invalid model path: {model.path}\")\n",
    "\n",
    "\n",
    "validate_registered_model(registered_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model registration completed successfully\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
