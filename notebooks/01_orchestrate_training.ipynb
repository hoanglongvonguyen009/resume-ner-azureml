{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Training Orchestration\n",
    "\n",
    "This notebook orchestrates all training activities without performing local computation.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Step 1**: Load Centralized Configs\n",
    "- **Step 2**: Data Ingestion & Versioning (Asset Layer)\n",
    "- **Step 3**: Environment Definition\n",
    "- **Step 4**: The Dry Run\n",
    "- **Step 5**: The Sweep (HPO)\n",
    "- **Step 6**: Best Configuration Selection (Automated)\n",
    "- **Step 7**: Final Training (Post-HPO, Single Run)\n",
    "\n",
    "## Important\n",
    "\n",
    "- This notebook **only submits and monitors Azure ML jobs**\n",
    "- **No training logic** is executed locally\n",
    "- All computation happens remotely on Azure ML compute\n",
    "- The notebook must be **re-runnable end-to-end**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.1: Load Centralized Configs\n",
    "\n",
    "Load and validate all configuration files. Configs are immutable and will be logged with each job for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml-mlflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Ensure we can import the orchestration package from src/\n",
    "import sys\n",
    "sys.path.append(str((Path(\"..\") / \"src\").resolve()))\n",
    "\n",
    "from shared.yaml_utils import load_yaml\n",
    "from orchestration import (\n",
    "    STAGE_SMOKE,\n",
    "    STAGE_HPO,\n",
    "    STAGE_TRAINING,\n",
    "    EXPERIMENT_NAME,\n",
    "    MODEL_NAME,\n",
    "    PROD_STAGE,\n",
    "    CONVERSION_JOB_NAME,\n",
    "    build_aml_experiment_name,\n",
    ")\n",
    "from orchestration.config_loader import (\n",
    "    ExperimentConfig,\n",
    "    create_config_metadata,\n",
    "    load_all_configs,\n",
    "    load_experiment_config,\n",
    "    compute_config_hashes,\n",
    "    snapshot_configs,\n",
    "    validate_config_immutability,\n",
    ")\n",
    "\n",
    "\n",
    "env_path = Path(\"../config.env\")\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DIR = Path(\"../config\")\n",
    "\n",
    "# Experiment selection (switch to try different data/model/HPO/env combos)\n",
    "# The concrete experiment definition lives in config/experiment/<EXPERIMENT_NAME>.yaml\n",
    "\n",
    "# Resolve experiment-level config into concrete file paths\n",
    "experiment_config: ExperimentConfig = load_experiment_config(CONFIG_DIR, EXPERIMENT_NAME)\n",
    "configs = load_all_configs(experiment_config)\n",
    "config_hashes = compute_config_hashes(configs)\n",
    "\n",
    "# Immutable snapshots for runtime mutation checks\n",
    "original_configs = snapshot_configs(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse shared immutability validator from orchestration package\n",
    "validate_config_immutability(configs, original_configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "def get_workspace_name() -> str:\n",
    "    \"\"\"Get workspace name from configuration files.\n",
    "\n",
    "    Order of precedence:\n",
    "    1. ``config/infrastructure.yaml`` (``workspace.name``)\n",
    "    2. ``config/env/azure.yaml`` (``workspace.name`` under ``env`` config)\n",
    "    \"\"\"\n",
    "    infrastructure_config_path = Path(\"../config/infrastructure.yaml\")\n",
    "    if infrastructure_config_path.exists():\n",
    "        infrastructure_config = load_yaml(infrastructure_config_path)\n",
    "        return infrastructure_config[\"workspace\"][\"name\"]\n",
    "\n",
    "    env_workspace = configs[\"env\"].get(\"workspace\", {}).get(\"name\")\n",
    "    if env_workspace:\n",
    "        return env_workspace\n",
    "\n",
    "    raise ValueError(\n",
    "        \"Workspace name must be configured in either \"\n",
    "        \"config/infrastructure.yaml (workspace.name) or config/env/azure.yaml (workspace.name).\"\n",
    "    )\n",
    "\n",
    "\n",
    "subscription_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"AZURE_RESOURCE_GROUP\")\n",
    "\n",
    "if not subscription_id or not resource_group:\n",
    "    raise ValueError(\"AZURE_SUBSCRIPTION_ID and AZURE_RESOURCE_GROUP must be set\")\n",
    "\n",
    "workspace_name = get_workspace_name()\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All configs and their hashes will be attached to each Azure ML job for full reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build config metadata for job tagging using shared helper from\n",
    "# `orchestration.config_loader`.\n",
    "config_metadata = create_config_metadata(configs, config_hashes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.2: Data Ingestion & Versioning (Asset Layer)\n",
    "\n",
    "Upload dataset to Blob Storage and register as an Azure ML Data Asset for versioned, immutable data access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.data_assets import (\n",
    "    resolve_dataset_path,\n",
    "    register_data_asset,\n",
    "    ensure_data_asset_uploaded,\n",
    "    build_data_asset_reference,\n",
    ")\n",
    "\n",
    "# Resolve local dataset path from data config (configs[\"data\"][\"local_path\"])\n",
    "DATASET_LOCAL_PATH = resolve_dataset_path(configs[\"data\"])\n",
    "DATA_ASSET_NAME = configs[\"data\"][\"name\"]\n",
    "DATA_ASSET_VERSION = configs[\"data\"][\"version\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ASSET_OVERRIDE_PATH = None\n",
    "blob_uri = DATA_ASSET_OVERRIDE_PATH or str(DATASET_LOCAL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asset = register_data_asset(\n",
    "    ml_client=ml_client,\n",
    "    name=DATA_ASSET_NAME,\n",
    "    version=DATA_ASSET_VERSION,\n",
    "    uri=blob_uri,\n",
    "    description=configs[\"data\"][\"description\"],\n",
    ")\n",
    "\n",
    "# Best-effort upload of local content to the resolved data asset\n",
    "data_asset = ensure_data_asset_uploaded(\n",
    "    ml_client=ml_client,\n",
    "    data_asset=data_asset,\n",
    "    local_path=DATASET_LOCAL_PATH,\n",
    "    description=configs[\"data\"][\"description\"],\n",
    ")\n",
    "\n",
    "# Build shared references for downstream jobs\n",
    "asset_paths = build_data_asset_reference(ml_client, data_asset)\n",
    "asset_reference = asset_paths[\"asset_uri\"]\n",
    "datastore_path = asset_paths[\"datastore_path\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "\n",
    "If you encounter `ScriptExecution.StreamAccess.NotFound`, verify that:\n",
    "1. Compute cluster has managed identity assigned\n",
    "2. Managed identity has \"Storage Blob Data Reader\" role on storage account\n",
    "3. Storage account firewall allows Azure services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data asset to save\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save data asset info to a JSON file\n",
    "data_asset_cache_file = Path(\"data_asset_cache.json\")\n",
    "\n",
    "if 'data_asset' in globals() and data_asset is not None:\n",
    "    data_asset_info = {\n",
    "        \"name\": data_asset.name,\n",
    "        \"version\": data_asset.version,\n",
    "    }\n",
    "    \n",
    "    # Optionally save asset_paths if they're used directly\n",
    "    if 'asset_paths' in globals():\n",
    "        data_asset_info[\"asset_paths\"] = asset_paths\n",
    "    \n",
    "    with open(data_asset_cache_file, \"w\") as f:\n",
    "        json.dump(data_asset_info, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved data asset: {data_asset_info['name']} v{data_asset_info['version']} to {data_asset_cache_file}\")\n",
    "else:\n",
    "    print(\"No data asset to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data asset: resume-ner-data-tiny-short vv2.1\n",
      "Asset URI: azureml:resume-ner-data-tiny-short:v2.1\n",
      "Skipping data asset registration - using cached asset\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from orchestration.data_assets import build_data_asset_reference\n",
    "\n",
    "# Try to reload from cache\n",
    "data_asset_cache_file = Path(\"data_asset_cache.json\")\n",
    "\n",
    "if data_asset_cache_file.exists():\n",
    "    with open(data_asset_cache_file, \"r\") as f:\n",
    "        data_asset_info = json.load(f)\n",
    "    \n",
    "    try:\n",
    "        # Reload Data asset object from ML client\n",
    "        data_asset = ml_client.data.get(\n",
    "            name=data_asset_info[\"name\"],\n",
    "            version=data_asset_info[\"version\"]\n",
    "        )\n",
    "        \n",
    "        # Rebuild asset_paths if they were saved, otherwise regenerate them\n",
    "        if \"asset_paths\" in data_asset_info:\n",
    "            asset_paths = data_asset_info[\"asset_paths\"]\n",
    "        else:\n",
    "            asset_paths = build_data_asset_reference(ml_client, data_asset)\n",
    "        \n",
    "        asset_reference = asset_paths[\"asset_uri\"]\n",
    "        datastore_path = asset_paths[\"datastore_path\"]\n",
    "        \n",
    "        print(f\"Loaded data asset: {data_asset.name} v{data_asset.version}\")\n",
    "        print(f\"Asset URI: {asset_reference}\")\n",
    "        print(\"Skipping data asset registration - using cached asset\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load data asset {data_asset_info['name']} v{data_asset_info['version']}: {e}\")\n",
    "        print(\"Will need to register data asset again\")\n",
    "        data_asset = None\n",
    "else:\n",
    "    print(f\"Cache file {data_asset_cache_file} not found. Will need to register data asset.\")\n",
    "    data_asset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.3: Environment Definition\n",
    "\n",
    "Define a stable execution environment (Docker image + Conda dependencies) for consistent behavior across all training jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "\u001b[32mUploading src (0.18 MBs): 100%|██████████| 182538/182538 [00:03<00:00, 53188.71it/s]\n",
      "\u001b[39m\n",
      "\n",
      "/usr/local/python/current/lib/python3.12/site-packages/mlflow/__init__.py:41: UserWarning: Versions of mlflow (3.7.0) and child packages mlflow-skinny (3.5.0) are different. This may lead to unexpected behavior. Please install the same version of all MLflow packages.\n",
      "  mlflow.mismatch._check_version_mismatch()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: red_cloud_g6j6jxh3yr\n",
      "Web View: https://ml.azure.com/runs/red_cloud_g6j6jxh3yr?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "======Starting Image Build on Compute======\n",
      "The run ID for the image build on compute is imgbldrun_b64e238\n",
      "Additional logs for the run: https://ml.azure.com/experiments/id/prepare_image/runs/imgbldrun_b64e238?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f\n",
      "2025-12-17T23:43:28: Logging into Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-17T23:43:28: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "\n",
      "2025-12-17T23:43:29: WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "2025-12-17T23:43:29: Configure a credential helper to remove this warning. See\n",
      "2025-12-17T23:43:29: Login Succeeded\n",
      "2025-12-17T23:43:29: https://docs.docker.com/go/credential-store/\n",
      "\n",
      "\n",
      "\n",
      "2025-12-17T23:43:29: Running: ['docker', 'build', '-f', 'azureml-environment-setup/Dockerfile', '.', '-t', 'b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_1e6880c22c772a6f385ad6c518e358dc', '-t', 'b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_1e6880c22c772a6f385ad6c518e358dc:1']\n",
      "2025-12-17T23:43:29: #0 building with \"default\" instance using docker driver\n",
      "\n",
      "2025-12-17T23:43:29: #1 [internal] load .dockerignore\n",
      "2025-12-17T23:43:29: #1 transferring context: 2B done\n",
      "2025-12-17T23:43:29: #1 DONE 0.1s\n",
      "\n",
      "2025-12-17T23:43:29: #2 [internal] load build definition from Dockerfile\n",
      "2025-12-17T23:43:29: #2 transferring dockerfile: 1.68kB done\n",
      "2025-12-17T23:43:29: #2 DONE 0.1s\n",
      "\n",
      "2025-12-17T23:43:29: #3 [internal] load metadata for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33\n",
      "2025-12-17T23:43:29: #3 DONE 0.4s\n",
      "\n",
      "2025-12-17T23:43:29: #4 [internal] load build context\n",
      "2025-12-17T23:43:29: #4 transferring context: 1.80kB done\n",
      "2025-12-17T23:43:29: #4 DONE 0.1s\n",
      "\n",
      "2025-12-17T23:43:29: #5 [ 1/10] FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33\n",
      "2025-12-17T23:43:29: #5 resolve mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33 0.0s done\n",
      "2025-12-17T23:43:30: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 0B / 153.10MB 0.2s\n",
      "2025-12-17T23:43:30: #5 sha256:83631454f85b20f6f2f386c8f58cd8ec885a6b678fcbab1c9a21e1c9ceab4493 9.06kB / 9.06kB done\n",
      "2025-12-17T23:43:30: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 12.58MB / 28.58MB 0.2s\n",
      "2025-12-17T23:43:30: #5 sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33 2.43kB / 2.43kB done\n",
      "2025-12-17T23:43:30: #5 sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572 0B / 641.60kB 0.2s\n",
      "2025-12-17T23:43:30: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 30.41MB / 153.10MB 0.4s\n",
      "2025-12-17T23:43:30: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 28.58MB / 28.58MB 0.4s\n",
      "2025-12-17T23:43:30: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 51.38MB / 153.10MB 0.5s\n",
      "2025-12-17T23:43:30: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 28.58MB / 28.58MB 0.5s done\n",
      "2025-12-17T23:43:30: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 70.25MB / 153.10MB 0.6s\n",
      "2025-12-17T23:43:30: #5 extracting sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 0.1s\n",
      "2025-12-17T23:43:30: #5 sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 0B / 3.61MB 0.6s\n",
      "2025-12-17T23:43:30: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 88.08MB / 153.10MB 0.7s\n",
      "2025-12-17T23:43:30: #5 sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 3.61MB / 3.61MB 0.7s done\n",
      "2025-12-17T23:43:30: #5 sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 0B / 169B 0.7s\n",
      "2025-12-17T23:43:30: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 108.00MB / 153.10MB 0.8s\n",
      "2025-12-17T23:43:30: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 127.93MB / 153.10MB 0.9s\n",
      "2025-12-17T23:43:30: #5 sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572 641.60kB / 641.60kB 0.8s done\n",
      "2025-12-17T23:43:30: #5 sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 169B / 169B 0.8s done\n",
      "2025-12-17T23:43:30: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 0B / 127.20MB 0.9s\n",
      "2025-12-17T23:43:30: #5 sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 0B / 4.17MB 0.9s\n",
      "2025-12-17T23:43:30: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 147.85MB / 153.10MB 1.0s\n",
      "2025-12-17T23:43:30: #5 sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 2.10MB / 4.17MB 1.0s\n",
      "2025-12-17T23:43:31: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 20.97MB / 127.20MB 1.1s\n",
      "2025-12-17T23:43:31: #5 sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 4.17MB / 4.17MB 1.0s done\n",
      "2025-12-17T23:43:31: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 0B / 41.39MB 1.1s\n",
      "2025-12-17T23:43:31: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 37.75MB / 127.20MB 1.2s\n",
      "2025-12-17T23:43:31: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 66.06MB / 127.20MB 1.4s\n",
      "2025-12-17T23:43:31: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 32.51MB / 41.39MB 1.4s\n",
      "2025-12-17T23:43:31: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 85.29MB / 127.20MB 1.5s\n",
      "2025-12-17T23:43:31: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 41.39MB / 41.39MB 1.5s\n",
      "2025-12-17T23:43:31: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 106.13MB / 127.20MB 1.6s\n",
      "2025-12-17T23:43:31: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 124.78MB / 127.20MB 1.7s\n",
      "2025-12-17T23:43:31: #5 extracting sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 1.2s done\n",
      "2025-12-17T23:43:32: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 153.10MB / 153.10MB 2.2s done\n",
      "2025-12-17T23:43:32: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 41.39MB / 41.39MB 2.6s done\n",
      "2025-12-17T23:43:33: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 127.20MB / 127.20MB 3.6s done\n",
      "2025-12-17T23:43:33: #5 sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 0B / 197.03kB 3.7s\n",
      "2025-12-17T23:43:33: #5 sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 0B / 5.71MB 3.7s\n",
      "2025-12-17T23:43:33: #5 sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 197.03kB / 197.03kB 3.8s done\n",
      "2025-12-17T23:43:33: #5 sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 5.71MB / 5.71MB 3.8s done\n",
      "2025-12-17T23:43:33: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040\n",
      "2025-12-17T23:43:38: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 5.1s\n",
      "2025-12-17T23:43:39: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 5.5s done\n",
      "2025-12-17T23:43:42: #5 extracting sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572\n",
      "2025-12-17T23:43:43: #5 extracting sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572 0.0s done\n",
      "2025-12-17T23:43:43: #5 extracting sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94\n",
      "2025-12-17T23:43:43: #5 extracting sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 0.5s done\n",
      "2025-12-17T23:43:43: #5 extracting sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26\n",
      "2025-12-17T23:43:43: #5 extracting sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 done\n",
      "2025-12-17T23:43:43: #5 extracting sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 0.1s\n",
      "2025-12-17T23:43:47: #5 extracting sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 3.8s done\n",
      "2025-12-17T23:43:50: #5 extracting sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725\n",
      "2025-12-17T23:43:50: #5 extracting sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 0.2s done\n",
      "2025-12-17T23:43:50: #5 extracting sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310\n",
      "2025-12-17T23:43:51: #5 extracting sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 0.5s done\n",
      "2025-12-17T23:43:52: #5 extracting sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba\n",
      "2025-12-17T23:43:52: #5 extracting sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 0.0s done\n",
      "2025-12-17T23:43:52: #5 extracting sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3\n",
      "2025-12-17T23:43:52: #5 extracting sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 0.0s done\n",
      "2025-12-17T23:43:52: #5 DONE 22.9s\n",
      "\n",
      "2025-12-17T23:43:52: #6 [ 2/10] RUN mkdir -p $HOME/.cache\n",
      "2025-12-17T23:43:53: #6 DONE 0.3s\n",
      "\n",
      "2025-12-17T23:43:53: #7 [ 3/10] COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      "2025-12-17T23:43:53: #7 DONE 0.1s\n",
      "\n",
      "2025-12-17T23:43:53: #8 [ 4/10] RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      "2025-12-17T23:43:54: #8 DONE 1.8s\n",
      "\n",
      "2025-12-17T23:43:55: #9 [ 5/10] COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      "2025-12-17T23:43:55: #9 DONE 0.1s\n",
      "\n",
      "2025-12-17T23:43:55: #10 [ 6/10] RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_bb93a5711d9b741f8028ca5679c6fc73 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      "2025-12-17T23:43:56: #10 0.641 Retrieving notices: done\n",
      "2025-12-17T23:43:56: #10 1.481 Channels:\n",
      "2025-12-17T23:43:56: #10 1.481  - pytorch\n",
      "2025-12-17T23:43:56: #10 1.481  - conda-forge\n",
      "2025-12-17T23:43:56: #10 1.481  - defaults\n",
      "2025-12-17T23:43:56: #10 1.481 Platform: linux-64\n",
      "2025-12-17T23:44:11: #10 1.481 Collecting package metadata (repodata.json): ...working... done\n",
      "2025-12-17T23:44:16: #10 15.95 Solving environment: ...working... done\n",
      "2025-12-17T23:44:16: #10 21.74 \n",
      "2025-12-17T23:44:16: #10 21.74 \n",
      "2025-12-17T23:44:16: #10 21.74 ==> WARNING: A newer version of conda exists. <==\n",
      "2025-12-17T23:44:16: #10 21.74     current version: 25.1.1\n",
      "2025-12-17T23:44:16: #10 21.74     latest version: 25.11.1\n",
      "2025-12-17T23:44:16: #10 21.74 \n",
      "2025-12-17T23:44:16: #10 21.74 Please update conda by running\n",
      "2025-12-17T23:44:16: #10 21.74 \n",
      "2025-12-17T23:44:16: #10 21.74     $ conda update -n base -c conda-forge conda\n",
      "2025-12-17T23:44:16: #10 21.74 \n",
      "2025-12-17T23:44:16: #10 21.74 \n",
      "2025-12-17T23:44:16: #10 21.84 \n",
      "2025-12-17T23:44:17: mkl-2025.3.0         | 119.4 MB  |            |   0% \n",
      "2025-12-17T23:44:17: libtorch-2.9.1       | 57.9 MB   |            |   0% \u001b[A\n",
      "2025-12-17T23:44:17: #10 21.84 \n",
      "2025-12-17T23:44:17: python-3.10.19       | 24.1 MB   |            |   0% \u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.84 \n",
      "2025-12-17T23:44:17: #10 21.84 \n",
      "2025-12-17T23:44:17: pytorch-2.9.1        | 20.4 MB   |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.84 \n",
      "2025-12-17T23:44:17: #10 21.84 \n",
      "2025-12-17T23:44:17: #10 21.84 \n",
      "2025-12-17T23:44:17: numpy-2.2.6          | 7.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: llvm-openmp-21.1.8   | 5.8 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: libstdcxx-15.2.0     | 5.6 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: libprotobuf-6.31.1   | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: sympy-1.14.0         | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: tk-8.6.13            | 3.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: openssl-3.6.0        | 3.0 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: libhwloc-2.12.1      | 2.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: sleef-3.9.0          | 1.9 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: libabseil-20250512.1 | 1.2 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: networkx-3.4.2       | 1.2 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: pip-25.3             | 1.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: libgcc-15.2.0        | 1018 KB   |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: #10 21.85 \n",
      "2025-12-17T23:44:17: libsqlite-3.51.1     | 917 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: libuv-1.51.0         | 874 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: #10 21.86 \n",
      "2025-12-17T23:44:17: mkl-2025.3.0         | 119.4 MB  |            |   0% \n",
      "2025-12-17T23:44:17: libtorch-2.9.1       | 57.9 MB   | 2          |   2% \u001b[A\n",
      "2025-12-17T23:44:17: #10 21.94 \n",
      "2025-12-17T23:44:17: #10 21.94 \n",
      "2025-12-17T23:44:17: pytorch-2.9.1        | 20.4 MB   |            |   1% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.95 \n",
      "2025-12-17T23:44:17: #10 21.95 \n",
      "2025-12-17T23:44:17: #10 21.95 \n",
      "2025-12-17T23:44:17: numpy-2.2.6          | 7.5 MB    | #2         |  12% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 21.97 \n",
      "2025-12-17T23:44:17: mkl-2025.3.0         | 119.4 MB  | 3          |   3% \n",
      "2025-12-17T23:44:17: libtorch-2.9.1       | 57.9 MB   | 7          |   7% \u001b[A\n",
      "2025-12-17T23:44:17: #10 22.04 \n",
      "2025-12-17T23:44:17: #10 22.04 \n",
      "2025-12-17T23:44:17: pytorch-2.9.1        | 20.4 MB   | #5         |  15% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.05 \n",
      "2025-12-17T23:44:17: #10 22.05 \n",
      "2025-12-17T23:44:17: #10 22.05 \n",
      "2025-12-17T23:44:17: numpy-2.2.6          | 7.5 MB    | #####6     |  56% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.07 \n",
      "2025-12-17T23:44:17: mkl-2025.3.0         | 119.4 MB  | 5          |   6% \n",
      "2025-12-17T23:44:17: libtorch-2.9.1       | 57.9 MB   | #2         |  13% \u001b[A\n",
      "2025-12-17T23:44:17: #10 22.14 \n",
      "2025-12-17T23:44:17: #10 22.14 \n",
      "2025-12-17T23:44:17: pytorch-2.9.1        | 20.4 MB   | ###        |  30% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.15 \n",
      "2025-12-17T23:44:17: #10 22.15 \n",
      "2025-12-17T23:44:17: #10 22.15 \n",
      "2025-12-17T23:44:17: numpy-2.2.6          | 7.5 MB    | #########7 |  97% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.17 \n",
      "2025-12-17T23:44:17: mkl-2025.3.0         | 119.4 MB  | 8          |   8% \n",
      "2025-12-17T23:44:17: libtorch-2.9.1       | 57.9 MB   | #8         |  18% \u001b[A\n",
      "2025-12-17T23:44:17: #10 22.25 \n",
      "2025-12-17T23:44:17: #10 22.25 \n",
      "2025-12-17T23:44:17: pytorch-2.9.1        | 20.4 MB   | ####7      |  48% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.27 \n",
      "2025-12-17T23:44:17: mkl-2025.3.0         | 119.4 MB  | #1         |  11% \n",
      "2025-12-17T23:44:17: libtorch-2.9.1       | 57.9 MB   | ##4        |  24% \u001b[A\n",
      "2025-12-17T23:44:17: #10 22.35 \n",
      "2025-12-17T23:44:17: #10 22.35 \n",
      "2025-12-17T23:44:17: pytorch-2.9.1        | 20.4 MB   | ######4    |  64% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.35 \n",
      "2025-12-17T23:44:17: #10 22.35 \n",
      "2025-12-17T23:44:17: #10 22.35 \n",
      "2025-12-17T23:44:17: numpy-2.2.6          | 7.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.37 \n",
      "2025-12-17T23:44:17: python-3.10.19       | 24.1 MB   | #####1     |  51% \u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.39 \n",
      "2025-12-17T23:44:17: #10 22.39 \n",
      "2025-12-17T23:44:17: #10 22.39 \n",
      "2025-12-17T23:44:17: #10 22.39 \n",
      "2025-12-17T23:44:17: mkl-2025.3.0         | 119.4 MB  | #3         |  14% \n",
      "2025-12-17T23:44:17: libtorch-2.9.1       | 57.9 MB   | ##9        |  30% \u001b[A\n",
      "2025-12-17T23:44:17: #10 22.46 \n",
      "2025-12-17T23:44:17: #10 22.46 \n",
      "2025-12-17T23:44:17: pytorch-2.9.1        | 20.4 MB   | #######8   |  79% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.47 \n",
      "2025-12-17T23:44:17: python-3.10.19       | 24.1 MB   | ######3    |  63% \u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.49 \n",
      "2025-12-17T23:44:17: #10 22.49 \n",
      "2025-12-17T23:44:17: #10 22.49 \n",
      "2025-12-17T23:44:17: #10 22.49 \n",
      "2025-12-17T23:44:17: mkl-2025.3.0         | 119.4 MB  | #6         |  16% \n",
      "2025-12-17T23:44:17: libtorch-2.9.1       | 57.9 MB   | ###4       |  35% \u001b[A\n",
      "2025-12-17T23:44:17: #10 22.57 \n",
      "2025-12-17T23:44:17: #10 22.57 \n",
      "2025-12-17T23:44:17: pytorch-2.9.1        | 20.4 MB   | #########3 |  93% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.58 \n",
      "2025-12-17T23:44:17: python-3.10.19       | 24.1 MB   | #######5   |  75% \u001b[A\u001b[A\n",
      "2025-12-17T23:44:17: #10 22.59 \n",
      "2025-12-17T23:44:17: #10 22.59 \n",
      "2025-12-17T23:44:17: #10 22.59 \n",
      "2025-12-17T23:44:17: #10 22.59 \n",
      "2025-12-17T23:44:17: mkl-2025.3.0         | 119.4 MB  | #8         |  19% \n",
      "2025-12-17T23:44:17: libtorch-2.9.1       | 57.9 MB   | ####       |  40% \u001b[A\n",
      "2025-12-17T23:44:17: #10 22.68 \n",
      "2025-12-17T23:44:18: mkl-2025.3.0         | 119.4 MB  | ##1        |  21% \n",
      "2025-12-17T23:44:18: libtorch-2.9.1       | 57.9 MB   | ####6      |  46% \u001b[A\n",
      "2025-12-17T23:44:18: #10 22.78 \n",
      "2025-12-17T23:44:18: #10 22.78 \n",
      "2025-12-17T23:44:18: #10 22.78 \n",
      "2025-12-17T23:44:18: #10 22.78 \n",
      "2025-12-17T23:44:18: llvm-openmp-21.1.8   | 5.8 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 22.83 \n",
      "2025-12-17T23:44:18: #10 22.83 \n",
      "2025-12-17T23:44:18: #10 22.83 \n",
      "2025-12-17T23:44:18: #10 22.83 \n",
      "2025-12-17T23:44:18: #10 22.83 \n",
      "2025-12-17T23:44:18: mkl-2025.3.0         | 119.4 MB  | ##4        |  24% \n",
      "2025-12-17T23:44:18: libtorch-2.9.1       | 57.9 MB   | #####1     |  52% \u001b[A\n",
      "2025-12-17T23:44:18: #10 22.93 \n",
      "2025-12-17T23:44:18: #10 22.93 \n",
      "2025-12-17T23:44:18: #10 22.93 \n",
      "2025-12-17T23:44:18: #10 22.93 \n",
      "2025-12-17T23:44:18: #10 22.93 \n",
      "2025-12-17T23:44:18: mkl-2025.3.0         | 119.4 MB  | ##6        |  27% \n",
      "2025-12-17T23:44:18: mkl-2025.3.0         | 119.4 MB  | ##9        |  29% \n",
      "2025-12-17T23:44:18: mkl-2025.3.0         | 119.4 MB  | ###2       |  32% \n",
      "2025-12-17T23:44:18: libtorch-2.9.1       | 57.9 MB   | ######8    |  69% \u001b[A\n",
      "2025-12-17T23:44:18: #10 23.18 \n",
      "2025-12-17T23:44:18: #10 23.18 \n",
      "2025-12-17T23:44:18: #10 23.18 \n",
      "2025-12-17T23:44:18: #10 23.18 \n",
      "2025-12-17T23:44:18: #10 23.18 \n",
      "2025-12-17T23:44:18: libstdcxx-15.2.0     | 5.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.18 \n",
      "2025-12-17T23:44:18: #10 23.18 \n",
      "2025-12-17T23:44:18: #10 23.18 \n",
      "2025-12-17T23:44:18: #10 23.18 \n",
      "2025-12-17T23:44:18: #10 23.18 \n",
      "2025-12-17T23:44:18: libstdcxx-15.2.0     | 5.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.23 \n",
      "2025-12-17T23:44:18: #10 23.23 \n",
      "2025-12-17T23:44:18: #10 23.23 \n",
      "2025-12-17T23:44:18: #10 23.23 \n",
      "2025-12-17T23:44:18: #10 23.23 \n",
      "2025-12-17T23:44:18: #10 23.23 \n",
      "2025-12-17T23:44:18: mkl-2025.3.0         | 119.4 MB  | ###5       |  35% \n",
      "2025-12-17T23:44:18: #10 23.28 \n",
      "2025-12-17T23:44:18: #10 23.28 \n",
      "2025-12-17T23:44:18: pytorch-2.9.1        | 20.4 MB   | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: libtorch-2.9.1       | 57.9 MB   | #######4   |  74% \u001b[A\n",
      "2025-12-17T23:44:18: #10 23.33 \n",
      "2025-12-17T23:44:18: #10 23.33 \n",
      "2025-12-17T23:44:18: #10 23.33 \n",
      "2025-12-17T23:44:18: #10 23.33 \n",
      "2025-12-17T23:44:18: #10 23.33 \n",
      "2025-12-17T23:44:18: #10 23.33 \n",
      "2025-12-17T23:44:18: libprotobuf-6.31.1   | 4.4 MB    | #####3     |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.35 \n",
      "2025-12-17T23:44:18: #10 23.35 \n",
      "2025-12-17T23:44:18: #10 23.35 \n",
      "2025-12-17T23:44:18: #10 23.35 \n",
      "2025-12-17T23:44:18: #10 23.35 \n",
      "2025-12-17T23:44:18: #10 23.35 \n",
      "2025-12-17T23:44:18: #10 23.35 \n",
      "2025-12-17T23:44:18: mkl-2025.3.0         | 119.4 MB  | ###7       |  38% \n",
      "2025-12-17T23:44:18: libtorch-2.9.1       | 57.9 MB   | #######9   |  80% \u001b[A\n",
      "2025-12-17T23:44:18: #10 23.45 \n",
      "2025-12-17T23:44:18: #10 23.45 \n",
      "2025-12-17T23:44:18: #10 23.45 \n",
      "2025-12-17T23:44:18: #10 23.45 \n",
      "2025-12-17T23:44:18: #10 23.45 \n",
      "2025-12-17T23:44:18: #10 23.45 \n",
      "2025-12-17T23:44:18: #10 23.45 \n",
      "2025-12-17T23:44:18: mkl-2025.3.0         | 119.4 MB  | ####       |  40% \n",
      "2025-12-17T23:44:18: libtorch-2.9.1       | 57.9 MB   | ########4  |  85% \u001b[A\n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: libprotobuf-6.31.1   | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: #10 23.57 \n",
      "2025-12-17T23:44:18: libprotobuf-6.31.1   | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.59 \n",
      "2025-12-17T23:44:18: #10 23.59 \n",
      "2025-12-17T23:44:18: #10 23.59 \n",
      "2025-12-17T23:44:18: #10 23.59 \n",
      "2025-12-17T23:44:18: llvm-openmp-21.1.8   | 5.8 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.60 \n",
      "2025-12-17T23:44:18: #10 23.60 \n",
      "2025-12-17T23:44:18: #10 23.60 \n",
      "2025-12-17T23:44:18: #10 23.60 \n",
      "2025-12-17T23:44:18: #10 23.60 \n",
      "2025-12-17T23:44:18: #10 23.60 \n",
      "2025-12-17T23:44:18: #10 23.60 \n",
      "2025-12-17T23:44:18: #10 23.60 \n",
      "2025-12-17T23:44:18: tk-8.6.13            | 3.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.60 \n",
      "2025-12-17T23:44:18: python-3.10.19       | 24.1 MB   | ########## | 100% \u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.60 \n",
      "2025-12-17T23:44:18: mkl-2025.3.0         | 119.4 MB  | ####2      |  43% \n",
      "2025-12-17T23:44:18: libtorch-2.9.1       | 57.9 MB   | ########9  |  90% \u001b[A\n",
      "2025-12-17T23:44:18: #10 23.65 \n",
      "2025-12-17T23:44:18: #10 23.65 \n",
      "2025-12-17T23:44:18: #10 23.65 \n",
      "2025-12-17T23:44:18: #10 23.65 \n",
      "2025-12-17T23:44:18: #10 23.65 \n",
      "2025-12-17T23:44:18: #10 23.65 \n",
      "2025-12-17T23:44:18: #10 23.65 \n",
      "2025-12-17T23:44:18: #10 23.65 \n",
      "2025-12-17T23:44:18: #10 23.65 \n",
      "2025-12-17T23:44:18: openssl-3.6.0        | 3.0 MB    |            |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: #10 23.68 \n",
      "2025-12-17T23:44:18: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.70 \n",
      "2025-12-17T23:44:18: #10 23.70 \n",
      "2025-12-17T23:44:18: #10 23.70 \n",
      "2025-12-17T23:44:18: #10 23.70 \n",
      "2025-12-17T23:44:18: #10 23.70 \n",
      "2025-12-17T23:44:18: #10 23.70 \n",
      "2025-12-17T23:44:18: #10 23.70 \n",
      "2025-12-17T23:44:18: #10 23.70 \n",
      "2025-12-17T23:44:18: mkl-2025.3.0         | 119.4 MB  | ####4      |  45% \n",
      "2025-12-17T23:44:18: libtorch-2.9.1       | 57.9 MB   | #########4 |  95% \u001b[A\n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: openssl-3.6.0        | 3.0 MB    | ########1  |  82% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: #10 23.75 \n",
      "2025-12-17T23:44:18: mkl-2025.3.0         | 119.4 MB  | ####7      |  47% \n",
      "2025-12-17T23:44:19: libtorch-2.9.1       | 57.9 MB   | #########9 | 100% \u001b[A\n",
      "2025-12-17T23:44:19: #10 23.85 \n",
      "2025-12-17T23:44:19: #10 23.85 \n",
      "2025-12-17T23:44:19: #10 23.85 \n",
      "2025-12-17T23:44:19: #10 23.85 \n",
      "2025-12-17T23:44:19: #10 23.85 \n",
      "2025-12-17T23:44:19: #10 23.85 \n",
      "2025-12-17T23:44:19: #10 23.85 \n",
      "2025-12-17T23:44:19: #10 23.85 \n",
      "2025-12-17T23:44:19: tk-8.6.13            | 3.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 23.89 \n",
      "2025-12-17T23:44:19: #10 23.89 \n",
      "2025-12-17T23:44:19: #10 23.89 \n",
      "2025-12-17T23:44:19: #10 23.89 \n",
      "2025-12-17T23:44:19: #10 23.89 \n",
      "2025-12-17T23:44:19: #10 23.89 \n",
      "2025-12-17T23:44:19: #10 23.89 \n",
      "2025-12-17T23:44:19: #10 23.89 \n",
      "2025-12-17T23:44:19: #10 23.89 \n",
      "2025-12-17T23:44:19: openssl-3.6.0        | 3.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: #10 23.92 \n",
      "2025-12-17T23:44:19: mkl-2025.3.0         | 119.4 MB  | ####9      |  50% \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: #10 23.93 \n",
      "2025-12-17T23:44:19: libabseil-20250512.1 | 1.2 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: #10 23.97 \n",
      "2025-12-17T23:44:19: networkx-3.4.2       | 1.2 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: #10 24.02 \n",
      "2025-12-17T23:44:19: mkl-2025.3.0         | 119.4 MB  | #####2     |  52% \n",
      "2025-12-17T23:44:19: #10 24.04 \n",
      "2025-12-17T23:44:19: #10 24.04 \n",
      "2025-12-17T23:44:19: #10 24.04 \n",
      "2025-12-17T23:44:19: #10 24.04 \n",
      "2025-12-17T23:44:19: #10 24.04 \n",
      "2025-12-17T23:44:19: libstdcxx-15.2.0     | 5.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: #10 24.06 \n",
      "2025-12-17T23:44:19: networkx-3.4.2       | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: #10 24.07 \n",
      "2025-12-17T23:44:19: pip-25.3             | 1.1 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: libsqlite-3.51.1     | 917 KB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: #10 24.11 \n",
      "2025-12-17T23:44:19: mkl-2025.3.0         | 119.4 MB  | #####4     |  55% \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: #10 24.15 \n",
      "2025-12-17T23:44:19: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: libsqlite-3.51.1     | 917 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: #10 24.18 \n",
      "2025-12-17T23:44:19: libgcc-15.2.0        | 1018 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: #10 24.19 \n",
      "2025-12-17T23:44:19: libuv-1.51.0         | 874 KB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: #10 24.22 \n",
      "2025-12-17T23:44:19: mkl-2025.3.0         | 119.4 MB  | #####7     |  57% \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: #10 24.25 \n",
      "2025-12-17T23:44:19: libuv-1.51.0         | 874 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:19: #10 24.29 \n",
      "2025-12-17T23:44:20: mkl-2025.3.0         | 119.4 MB  | #########  |  91% \n",
      "2025-12-17T23:44:20: #10 25.37 \n",
      "2025-12-17T23:44:20: #10 25.37 \n",
      "2025-12-17T23:44:20: #10 25.37 \n",
      "2025-12-17T23:44:20: #10 25.37 \n",
      "2025-12-17T23:44:20: #10 25.37 \n",
      "2025-12-17T23:44:20: #10 25.37 \n",
      "2025-12-17T23:44:20: mkl-2025.3.0         | 119.4 MB  | #########7 |  97% \n",
      "2025-12-17T23:44:21: libtorch-2.9.1       | 57.9 MB   | ########## | 100% \u001b[A\n",
      "2025-12-17T23:44:21: #10 26.61 \n",
      "2025-12-17T23:44:21: #10 26.61 \n",
      "2025-12-17T23:44:21: #10 26.61 \n",
      "2025-12-17T23:44:24: mkl-2025.3.0         | 119.4 MB  | ########## | 100% \n",
      "2025-12-17T23:44:24: #10 29.27 \n",
      "2025-12-17T23:44:24: #10 29.27 \n",
      "2025-12-17T23:44:24: #10 29.27 \n",
      "2025-12-17T23:44:24: #10 29.27 \n",
      "2025-12-17T23:44:24: #10 29.27 \n",
      "2025-12-17T23:44:24: #10 29.27 \n",
      "2025-12-17T23:44:24: #10 29.27 \n",
      "2025-12-17T23:44:24: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:24: #10 29.68 \n",
      "2025-12-17T23:44:25: python-3.10.19       | 24.1 MB   | ########## | 100% \u001b[A\u001b[A\n",
      "2025-12-17T23:44:25: #10 29.88 \n",
      "2025-12-17T23:44:25: #10 29.88 \n",
      "2025-12-17T23:44:25: #10 29.88 \n",
      "2025-12-17T23:44:25: #10 29.88 \n",
      "2025-12-17T23:44:25: #10 29.88 \n",
      "2025-12-17T23:44:25: #10 29.88 \n",
      "2025-12-17T23:44:25: #10 29.88 \n",
      "2025-12-17T23:44:25: #10 29.88 \n",
      "2025-12-17T23:44:25: tk-8.6.13            | 3.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:25: #10 30.03 \n",
      "2025-12-17T23:44:25: #10 30.03 \n",
      "2025-12-17T23:44:25: #10 30.03 \n",
      "2025-12-17T23:44:25: #10 30.03 \n",
      "2025-12-17T23:44:25: #10 30.03 \n",
      "2025-12-17T23:44:25: #10 30.03 \n",
      "2025-12-17T23:44:25: #10 30.03 \n",
      "2025-12-17T23:44:25: #10 30.03 \n",
      "2025-12-17T23:44:25: #10 30.03 \n",
      "2025-12-17T23:44:25: openssl-3.6.0        | 3.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:25: #10 30.48 \n",
      "2025-12-17T23:44:25: #10 30.48 \n",
      "2025-12-17T23:44:25: #10 30.48 \n",
      "2025-12-17T23:44:25: #10 30.48 \n",
      "2025-12-17T23:44:25: #10 30.48 \n",
      "2025-12-17T23:44:25: #10 30.48 \n",
      "2025-12-17T23:44:25: #10 30.48 \n",
      "2025-12-17T23:44:25: #10 30.48 \n",
      "2025-12-17T23:44:25: #10 30.48 \n",
      "2025-12-17T23:44:25: #10 30.48 \n",
      "2025-12-17T23:44:25: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:25: #10 30.60 \n",
      "2025-12-17T23:44:25: #10 30.60 \n",
      "2025-12-17T23:44:25: #10 30.60 \n",
      "2025-12-17T23:44:25: #10 30.60 \n",
      "2025-12-17T23:44:25: #10 30.60 \n",
      "2025-12-17T23:44:25: #10 30.60 \n",
      "2025-12-17T23:44:25: #10 30.60 \n",
      "2025-12-17T23:44:25: #10 30.60 \n",
      "2025-12-17T23:44:25: #10 30.60 \n",
      "2025-12-17T23:44:25: #10 30.60 \n",
      "2025-12-17T23:44:25: #10 30.60 \n",
      "2025-12-17T23:44:25: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:25: #10 30.83 \n",
      "2025-12-17T23:44:26: libabseil-20250512.1 | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: #10 30.83 \n",
      "2025-12-17T23:44:26: libabseil-20250512.1 | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: networkx-3.4.2       | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: #10 31.23 \n",
      "2025-12-17T23:44:26: networkx-3.4.2       | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: libsqlite-3.51.1     | 917 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: #10 31.30 \n",
      "2025-12-17T23:44:26: libsqlite-3.51.1     | 917 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: #10 31.38 \n",
      "2025-12-17T23:44:26: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: libuv-1.51.0         | 874 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: #10 31.43 \n",
      "2025-12-17T23:44:26: libuv-1.51.0         | 874 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: libgcc-15.2.0        | 1018 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:26: #10 31.45 \n",
      "2025-12-17T23:44:27: libgcc-15.2.0        | 1018 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:27: #10 32.24 \n",
      "2025-12-17T23:44:27: #10 32.24 \n",
      "2025-12-17T23:44:29: pytorch-2.9.1        | 20.4 MB   | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29:  ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:29: #10 34.01 \n",
      "2025-12-17T23:44:33: mkl-2025.3.0         | 119.4 MB  | ########## | 100% \n",
      "2025-12-17T23:44:33: libtorch-2.9.1       | 57.9 MB   | ########## | 100% \u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: \u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: \u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: \u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: #10 38.38 \n",
      "2025-12-17T23:44:33: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A done\n",
      "2025-12-17T23:44:34: #10 38.38 Preparing transaction: done\n",
      "2025-12-17T23:44:37: #10 39.25 Verifying transaction: done\n",
      "2025-12-17T23:44:47: #10 42.04 Executing transaction: done\n",
      "2025-12-17T23:46:51: #10 51.90 Installing pip dependencies: / Ran pip subprocess with arguments:\n",
      "2025-12-17T23:46:51: #10 176.0 ['/azureml-envs/azureml_bb93a5711d9b741f8028ca5679c6fc73/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt', '--exists-action=b']\n",
      "2025-12-17T23:46:51: #10 176.0 Pip subprocess output:\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azureml-defaults (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azureml_defaults-1.61.0-py3-none-any.whl.metadata (914 bytes)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting transformers<5.0.0,>=4.35.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting safetensors>=0.4.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 3))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting datasets>=2.12.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting numpy<2.0,>=1.24.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 5))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pandas>=2.0.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 6))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting scikit-learn>=1.3.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 7))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-ai-ml>=1.0.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_ai_ml-1.30.0-py3-none-any.whl.metadata (40 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-identity>=1.12.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 9))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_identity-1.25.1-py3-none-any.whl.metadata (88 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-storage-blob>=12.17.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 10))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_blob-12.27.1-py3-none-any.whl.metadata (26 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pyyaml>=6.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 11))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting tqdm>=4.65.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 12))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting seqeval>=1.2.2 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 13))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Installing build dependencies: started\n",
      "2025-12-17T23:46:51: #10 176.0   Installing build dependencies: finished with status 'done'\n",
      "2025-12-17T23:46:51: #10 176.0   Getting requirements to build wheel: started\n",
      "2025-12-17T23:46:51: #10 176.0   Getting requirements to build wheel: finished with status 'done'\n",
      "2025-12-17T23:46:51: #10 176.0   Installing backend dependencies: started\n",
      "2025-12-17T23:46:51: #10 176.0   Installing backend dependencies: finished with status 'done'\n",
      "2025-12-17T23:46:51: #10 176.0   Preparing metadata (pyproject.toml): started\n",
      "2025-12-17T23:46:51: #10 176.0   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting sentencepiece>=0.1.99 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 14))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting mlflow (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading mlflow-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azureml-mlflow (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 16))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azureml_mlflow-1.61.0.post1-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting onnxruntime (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 17))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading onnxruntime-1.23.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting onnx>=1.16.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 18))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading onnx-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting onnxscript>=0.1.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 19))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Requirement already satisfied: filelock in /azureml-envs/azureml_bb93a5711d9b741f8028ca5679c6fc73/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2)) (3.20.1)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting huggingface-hub<1.0,>=0.34.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting packaging>=20.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2))\n",
      "2025-12-17T23:46:51: #10 176.0   Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting requests (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Requirement already satisfied: fsspec>=2023.5.0 in /azureml-envs/azureml_bb93a5711d9b741f8028ca5679c6fc73/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2)) (2025.12.0)\n",
      "2025-12-17T23:46:51: #10 176.0 Requirement already satisfied: typing-extensions>=3.7.4.3 in /azureml-envs/azureml_bb93a5711d9b741f8028ca5679c6fc73/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2)) (4.15.0)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azureml-inference-server-http~=1.4 (from azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azureml_inference_server_http-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azureml-core~=1.61.0 (from azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azureml_core-1.61.0.post1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azureml-dataset-runtime~=1.61.0 (from azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azureml_dataset_runtime-1.61.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pytz (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting backports.tempfile (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading backports.tempfile-1.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pathspec<1.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting msal<2.0.0,>=1.15.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting msal-extensions<=2.0.0,>=0.3.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting knack<0.13.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading knack-0.12.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-core<2.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_core-1.37.0-py3-none-any.whl.metadata (47 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pkginfo (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pkginfo-1.12.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting argcomplete<4 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading argcomplete-3.6.3-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting humanfriendly<11.0,>=4.7 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting paramiko<4.0.0,>=2.0.8 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-mgmt-resource<=24.0.0,>=15.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_mgmt_resource-24.0.0-py3-none-any.whl.metadata (43 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-mgmt-containerregistry<15,>=8.2.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_mgmt_containerregistry-14.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-mgmt-storage<=24.0.0,>=16.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_mgmt_storage-24.0.0-py3-none-any.whl.metadata (36 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-mgmt-keyvault<12.0.0,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_mgmt_keyvault-11.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-mgmt-authorization<5,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-mgmt-network<=30.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_mgmt_network-30.0.0-py3-none-any.whl.metadata (94 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-graphrbac<1.0.0,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_graphrbac-0.61.2-py2.py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-common<2.0.0,>=1.1.12 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting msrest<=0.7.1,>=0.5.1 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting msrestazure<=0.7,>=0.4.33 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting urllib3<3.0.0,>1.26.17 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting python-dateutil<3.0.0,>=2.7.3 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting ndg-httpsclient<=0.5.1 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading ndg_httpsclient-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting SecretStorage<4.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading secretstorage-3.5.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting jsonpickle<5.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading jsonpickle-4.1.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting contextlib2<22.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting docker<8.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting PyJWT<3.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting adal<=1.2.7,>=1.2.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading adal-1.2.7-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pyopenssl<26.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting jmespath<2.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting cryptography>=1.1.0 (from adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting isodate<1.0.0,>=0.6.1 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-mgmt-core<2.0.0,>=1.3.2 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_mgmt_core-1.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azureml-dataprep<5.5.0a,>=5.1.0a (from azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azureml_dataprep-5.4.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pyarrow<21.0.0,>=0.17.0 (from azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azureml-dataprep-native<43.0.0,>=42.0.0 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azureml_dataprep_native-42.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azureml-dataprep-rslex~=2.25.1 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azureml_dataprep_rslex-2.25.2-cp310-cp310-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting cloudpickle<3.0.0,>=1.1.0 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-identity>=1.12.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 9))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_identity-1.17.0-py3-none-any.whl.metadata (79 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting jsonschema (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Requirement already satisfied: pip>=25.3 in /azureml-envs/azureml_bb93a5711d9b741f8028ca5679c6fc73/lib/python3.10/site-packages (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1)) (25.3)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting fusepy<4.0.0,>=3.0.1 (from azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Installing build dependencies: started\n",
      "2025-12-17T23:46:51: #10 176.0   Installing build dependencies: finished with status 'done'\n",
      "2025-12-17T23:46:51: #10 176.0   Getting requirements to build wheel: started\n",
      "2025-12-17T23:46:51: #10 176.0   Getting requirements to build wheel: finished with status 'done'\n",
      "2025-12-17T23:46:51: #10 176.0   Preparing metadata (pyproject.toml): started\n",
      "2025-12-17T23:46:51: #10 176.0   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting flask~=3.1.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting flask-cors~=6.0.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting gunicorn>=23.0.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting inference-schema~=1.8.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading inference_schema-1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-sdk==1.33.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-api==1.33.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_api-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-semantic-conventions (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry_exporter-1.0.0b46-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pydantic~=2.11.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pydantic-settings (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting werkzeug>=3.0.3 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting certifi>=2024.7.4 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting deprecated>=1.2.6 (from opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-semantic-conventions (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting blinker>=1.9.0 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting click>=8.1.3 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting itsdangerous>=2.2.0 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Requirement already satisfied: jinja2>=3.1.2 in /azureml-envs/azureml_bb93a5711d9b741f8028ca5679c6fc73/lib/python3.10/site-packages (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1)) (3.1.6)\n",
      "2025-12-17T23:46:51: #10 176.0 Requirement already satisfied: markupsafe>=2.1.1 in /azureml-envs/azureml_bb93a5711d9b741f8028ca5679c6fc73/lib/python3.10/site-packages (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1)) (3.0.3)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting wrapt<=1.16.0,>=1.14.0 (from inference-schema~=1.8.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pygments (from knack<0.13.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting tabulate (from knack<0.13.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting cffi>=2.0.0 (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting requests-oauthlib>=0.5.0 (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting six (from msrestazure<=0.7,>=0.4.33->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pyasn1>=0.1.1 (from ndg-httpsclient<=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting bcrypt>=3.2 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pynacl>=1.5 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pynacl-1.6.1-cp38-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting annotated-types>=0.6.0 (from pydantic~=2.11.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pydantic-core==2.33.2 (from pydantic~=2.11.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting typing-inspection>=0.4.0 (from pydantic~=2.11.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting charset_normalizer<4,>=2 (from requests->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting idna<4,>=2.5 (from requests->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting jeepney>=0.6 (from SecretStorage<4.0.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading jeepney-0.9.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting datasets>=2.12.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading datasets-4.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading datasets-4.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting xxhash (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting multiprocess<0.70.17 (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 2))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting tzdata>=2022.7 (from pandas>=2.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 6))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting scipy>=1.8.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 7))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting joblib>=1.2.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 7))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 7))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting marshmallow<4.0.0,>=3.5 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting strictyaml<2.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting colorama<1.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-storage-file-share (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_file_share-12.23.1-py3-none-any.whl.metadata (52 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_file_datalake-12.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pydash<9.0.0,>=6.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pydash-8.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.8.3-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting attrs>=22.2.0 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting referencing>=0.28.4 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting rpds-py>=0.7.1 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting mlflow-skinny==3.7.0 (from mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading mlflow_skinny-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting mlflow-tracing==3.7.0 (from mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading mlflow_tracing-3.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting alembic!=1.10.0,<2 (from mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting graphene<4 (from mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting huey<3,>=2.5.0 (from mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading huey-2.5.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting matplotlib<4 (from mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting sqlalchemy<3,>=1.4.0 (from mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading sqlalchemy-2.0.45-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading cachetools-6.2.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading databricks_sdk-0.76.0-py3-none-any.whl.metadata (40 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting fastapi<1 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading fastapi-0.125.0-py3-none-any.whl.metadata (30 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading sqlparse-0.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting uvicorn<1 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting Mako (from alembic!=1.10.0,<2->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting tomli (from alembic!=1.10.0,<2->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Using cached tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading google_auth-2.45.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting starlette<0.51.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting cycler>=0.10 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting fonttools>=4.22.0 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting kiwisolver>=1.3.1 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pillow>=8 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pyparsing>=3 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading greenlet-3.3.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting anyio<5,>=3.6.2 (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 15))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of azureml-mlflow to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azureml-mlflow (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 16))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azureml_mlflow-1.61.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azureml_mlflow-1.60.0.post1-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azureml_mlflow-1.60.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-storage-blob>=12.17.0 (from -r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 10))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting coloredlogs (from onnxruntime->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 17))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting flatbuffers (from onnxruntime->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 17))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "2025-12-17T23:46:51: #10 176.0 Requirement already satisfied: sympy in /azureml-envs/azureml_bb93a5711d9b741f8028ca5679c6fc73/lib/python3.10/site-packages (from onnxruntime->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 17)) (1.14.0)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting ml_dtypes>=0.5.0 (from onnx>=1.16.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 18))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading ml_dtypes-0.5.4-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting onnx_ir<2,>=0.1.12 (from onnxscript>=0.1.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 19))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading onnx_ir-0.1.13-py3-none-any.whl.metadata (3.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 4))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of azure-storage-file-datalake to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_file_datalake-12.21.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_file_datalake-12.19.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_file_datalake-12.18.1-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_file_datalake-12.18.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_file_datalake-12.17.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_file_datalake-12.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is still looking at multiple versions of azure-storage-file-datalake to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_file_datalake-12.15.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_storage_file_datalake-12.14.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting pycparser (from cffi>=2.0.0->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-core-tracing-opentelemetry~=1.0.0b11 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of azure-monitor-opentelemetry to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.8.2-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.8.1-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.8.0-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-django~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_django-0.60b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-fastapi~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_fastapi-0.60b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-flask~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_flask-0.60b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-psycopg2~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_psycopg2-0.60b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-requests~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_requests-0.60b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-urllib~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib-0.60b1-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-urllib3~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib3-0.60b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-resource-detector-azure~=0.1.5 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl.metadata (5.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.6.13-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.6.12-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-django<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_django-0.52b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-flask<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_flask-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-psycopg2<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_psycopg2-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-requests<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_requests-0.52b1-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-urllib<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib-0.52b1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-urllib3<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib3-0.52b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.6.11-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is still looking at multiple versions of azure-monitor-opentelemetry to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.6.10-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.6.9-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.6.8-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry-1.6.7-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of azure-monitor-opentelemetry-exporter to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry_exporter-1.0.0b45-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry_exporter-1.0.0b44-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry_exporter-1.0.0b43-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry_exporter-1.0.0b42-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry_exporter-1.0.0b41-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading azure_monitor_opentelemetry_exporter-1.0.0b40-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting psutil<8,>=5.9 (from azure-monitor-opentelemetry-exporter->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-wsgi==0.60b1 (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_wsgi-0.60b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation==0.60b1 (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation-0.60b1-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-django to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_django-0.60b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-wsgi==0.60b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_wsgi-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation==0.60b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation-0.60b0-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_django-0.59b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-wsgi==0.59b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_wsgi-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_django-0.58b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-wsgi==0.58b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_wsgi-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation==0.58b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_django-0.57b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-wsgi==0.57b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_wsgi-0.57b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation==0.57b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_django-0.56b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-wsgi==0.56b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_wsgi-0.56b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation==0.56b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation-0.56b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_django-0.55b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-wsgi==0.55b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_wsgi-0.55b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_django-0.55b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-wsgi==0.55b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_wsgi-0.55b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation==0.55b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation-0.55b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-django to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_django-0.54b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-wsgi==0.54b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_wsgi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_django-0.54b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-wsgi==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_wsgi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-util-http==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-asgi==0.60b1 (from opentelemetry-instrumentation-fastapi~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_asgi-0.60b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_fastapi-0.60b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-asgi==0.60b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_asgi-0.60b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_fastapi-0.59b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-asgi==0.59b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_asgi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_fastapi-0.58b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-asgi==0.58b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_asgi-0.58b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_fastapi-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-asgi==0.57b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_asgi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_fastapi-0.56b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-asgi==0.56b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_asgi-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_fastapi-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-asgi==0.55b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_asgi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-asgi==0.54b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b0->opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading asgiref-3.11.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-flask to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-flask~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_flask-0.60b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_flask-0.59b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_flask-0.58b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_flask-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_flask-0.56b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_flask-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_flask-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-flask to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_flask-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_flask-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-dbapi==0.60b1 (from opentelemetry-instrumentation-psycopg2~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_dbapi-0.60b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-psycopg2 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_psycopg2-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-dbapi==0.60b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_dbapi-0.60b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_psycopg2-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-dbapi==0.59b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_dbapi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_psycopg2-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-dbapi==0.58b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_dbapi-0.58b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_psycopg2-0.57b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-dbapi==0.57b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_dbapi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_psycopg2-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-dbapi==0.56b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_dbapi-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_psycopg2-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-dbapi==0.55b1 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_dbapi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_psycopg2-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-dbapi==0.55b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_dbapi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-psycopg2 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_psycopg2-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-dbapi==0.54b1 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_dbapi-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_psycopg2-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-dbapi==0.54b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_dbapi-0.54b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-requests to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-requests~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_requests-0.60b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_requests-0.59b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_requests-0.58b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_requests-0.57b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_requests-0.56b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_requests-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_requests-0.55b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-requests to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_requests-0.54b1-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_requests-0.54b0-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-urllib to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-urllib~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib-0.60b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib-0.59b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib-0.58b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib-0.57b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib-0.56b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib-0.55b1-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib-0.55b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-urllib to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib-0.54b1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib-0.54b0-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting opentelemetry-instrumentation-urllib3~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 8))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib3-0.60b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib3-0.59b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib3-0.58b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib3-0.57b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib3-0.56b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib3-0.55b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib3-0.55b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib3-0.54b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading opentelemetry_instrumentation_urllib3-0.54b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Collecting backports.weakref (from backports.tempfile->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 1))\n",
      "2025-12-17T23:46:51: #10 176.0   Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Requirement already satisfied: mpmath<1.4,>=1.1.0 in /azureml-envs/azureml_bb93a5711d9b741f8028ca5679c6fc73/lib/python3.10/site-packages (from sympy->onnxruntime->-r /azureml-environment-setup/condaenv.i5o3_ts5.requirements.txt (line 17)) (1.3.0)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 109.9 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 81.1 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 566.1/566.1 kB 16.9 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 28.5 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 97.7 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azureml_defaults-1.61.0-py3-none-any.whl (2.1 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azureml_core-1.61.0.post1-py3-none-any.whl (3.3 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 74.5 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading argcomplete-3.6.3-py3-none-any.whl (43 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_core-1.37.0-py3-none-any.whl (214 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_graphrbac-0.61.2-py2.py3-none-any.whl (142 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl (1.1 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 22.1 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_mgmt_containerregistry-14.0.0-py3-none-any.whl (1.7 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 61.0 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_mgmt_core-1.6.0-py3-none-any.whl (29 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_mgmt_keyvault-11.0.0-py3-none-any.whl (308 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_mgmt_network-30.0.0-py3-none-any.whl (614 kB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 614.0/614.0 kB 25.2 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_mgmt_resource-24.0.0-py3-none-any.whl (3.6 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 76.9 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_mgmt_storage-24.0.0-py3-none-any.whl (290 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azureml_dataset_runtime-1.61.0-py3-none-any.whl (2.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azureml_dataprep-5.4.2-py3-none-any.whl (253 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_identity-1.17.0-py3-none-any.whl (173 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 770.3/770.3 kB 24.0 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azureml_dataprep_native-42.1.0-cp310-cp310-manylinux1_x86_64.whl (187 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azureml_dataprep_rslex-2.25.2-cp310-cp310-manylinux1_x86_64.whl (26.1 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.1/26.1 MB 75.9 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azureml_inference_server_http-1.5.0-py3-none-any.whl (42 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_api-1.33.0-py3-none-any.whl (65 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl (118 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl (194 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading inference_schema-1.8-py3-none-any.whl (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading jsonpickle-4.1.1-py3-none-any.whl (47 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading knack-0.12.0-py3-none-any.whl (60 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading msal-1.34.0-py3-none-any.whl (116 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 111.1 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl (40 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading paramiko-3.5.1-py3-none-any.whl (227 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.3/42.3 MB 49.5 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 49.6 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pyopenssl-25.3.0-py3-none-any.whl (57 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading secretstorage-3.5.0-py3-none-any.whl (15 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 91.5 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.7/9.7 MB 4.4 MB/s  0:00:02\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_ai_ml-1.30.0-py3-none-any.whl (13.3 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.3/13.3 MB 44.9 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 45.9 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading mlflow-3.7.0-py3-none-any.whl (8.9 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.9/8.9 MB 83.9 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading mlflow_skinny-3.7.0-py3-none-any.whl (2.4 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 60.8 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading mlflow_tracing-3.7.0-py3-none-any.whl (1.3 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 28.4 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading alembic-1.17.2-py3-none-any.whl (248 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading cachetools-6.2.4-py3-none-any.whl (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading databricks_sdk-0.76.0-py3-none-any.whl (774 kB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 774.7/774.7 kB 33.7 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading fastapi-0.125.0-py3-none-any.whl (112 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading google_auth-2.45.0-py2.py3-none-any.whl (233 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading huey-2.5.5-py3-none-any.whl (76 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.7/8.7 MB 117.1 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 37.7/37.7 MB 75.9 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading sqlalchemy-2.0.45-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 91.4 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading sqlparse-0.5.4-py3-none-any.whl (45 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azureml_mlflow-1.60.0-py3-none-any.whl (1.0 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 32.0 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading onnxruntime-1.23.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.4/17.4 MB 88.5 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading onnx-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.1/18.1 MB 75.1 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 693.4/693.4 kB 18.8 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading onnx_ir-0.1.13-py3-none-any.whl (133 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 43.9 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_storage_file_datalake-12.14.0-py3-none-any.whl (251 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 114.7 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading greenlet-3.3.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (586 kB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 586.9/586.9 kB 22.0 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading jeepney-0.9.0-py3-none-any.whl (49 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 66.1 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading ml_dtypes-0.5.4-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.0/5.0 MB 98.8 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 135.7 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pynacl-1.6.1-cp38-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 25.7 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 791.7/791.7 kB 23.0 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_monitor_opentelemetry-1.6.7-py3-none-any.whl (23 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl (11 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_monitor_opentelemetry_exporter-1.0.0b40-py2.py3-none-any.whl (159 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_instrumentation_django-0.54b0-py3-none-any.whl (19 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl (31 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_instrumentation_wsgi-0.54b0-py3-none-any.whl (14 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl (7.3 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl (16 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading asgiref-3.11.0-py3-none-any.whl (24 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_instrumentation_flask-0.54b0-py3-none-any.whl (14 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_instrumentation_psycopg2-0.54b0-py3-none-any.whl (10 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_instrumentation_dbapi-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_instrumentation_requests-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_instrumentation_urllib-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_instrumentation_urllib3-0.54b0-py3-none-any.whl (13 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl (14 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading azure_storage_file_share-12.23.1-py3-none-any.whl (307 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pkginfo-1.12.1.2-py3-none-any.whl (32 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "2025-12-17T23:46:51: #10 176.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 36.5 MB/s  0:00:00\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Using cached tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "2025-12-17T23:46:51: #10 176.0 Building wheels for collected packages: fusepy, seqeval\n",
      "2025-12-17T23:46:51: #10 176.0   Building wheel for fusepy (pyproject.toml): started\n",
      "2025-12-17T23:46:51: #10 176.0   Building wheel for fusepy (pyproject.toml): finished with status 'done'\n",
      "2025-12-17T23:46:51: #10 176.0   Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10537 sha256=add6310e52acc27a7fe014ca151d3e0e21f92793a1bd6a5fa0b3d665fd1647fc\n",
      "2025-12-17T23:46:51: #10 176.0   Stored in directory: /root/.cache/pip/wheels/c0/18/f6/f0d6be9d0435e2677ce5cc758e91da50053dce456a346f08c5\n",
      "2025-12-17T23:46:51: #10 176.0   Building wheel for seqeval (pyproject.toml): started\n",
      "2025-12-17T23:46:51: #10 176.0   Building wheel for seqeval (pyproject.toml): finished with status 'done'\n",
      "2025-12-17T23:46:51: #10 176.0   Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16250 sha256=fef678a8569bf558b867c07cca309cd85a78ffd4ec6bc91f34691c8c5547605f\n",
      "2025-12-17T23:46:51: #10 176.0   Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "2025-12-17T23:46:51: #10 176.0 Successfully built fusepy seqeval\n",
      "2025-12-17T23:46:51: #10 176.0 Installing collected packages: pytz, huey, fusepy, flatbuffers, fixedint, backports.weakref, azureml-dataprep-rslex, azure-common, zipp, xxhash, wrapt, werkzeug, urllib3, tzdata, typing-inspection, tqdm, tomli, threadpoolctl, tabulate, sqlparse, smmap, six, sentencepiece, safetensors, rpds-py, regex, pyyaml, python-dotenv, PySocks, pyparsing, PyJWT, pygments, pydash, pydantic-core, pycparser, pyasn1, pyarrow, psutil, protobuf, propcache, pkginfo, pillow, pathspec, packaging, opentelemetry-util-http, oauthlib, numpy, multidict, Mako, kiwisolver, jsonpickle, joblib, jmespath, jeepney, itsdangerous, isodate, idna, humanfriendly, hf-xet, h11, greenlet, graphql-core, fsspec, frozenlist, fonttools, exceptiongroup, dill, cycler, contextlib2, colorama, cloudpickle, click, charset_normalizer, certifi, cachetools, blinker, bcrypt, backports.tempfile, azureml-dataprep-native, attrs, async-timeout, asgiref, argcomplete, annotated-types, annotated-doc, aiohappyeyeballs, yarl, uvicorn, sqlalchemy, scipy, rsa, requests, referencing, python-dateutil, pydantic, pyasn1-modules, opentelemetry-proto, multiprocess, ml_dtypes, marshmallow, knack, importlib-metadata, gunicorn, graphql-relay, gitdb, flask, deprecated, contourpy, coloredlogs, cffi, anyio, aiosignal, strictyaml, starlette, scikit-learn, requests-oauthlib, pynacl, pydantic-settings, pandas, opentelemetry-api, onnxruntime, onnx, matplotlib, jsonschema-specifications, inference-schema, huggingface-hub, graphene, google-auth, gitpython, flask-cors, docker, cryptography, azure-core, alembic, aiohttp, tokenizers, seqeval, SecretStorage, pyopenssl, paramiko, opentelemetry-semantic-conventions, onnx_ir, msrest, jsonschema, fastapi, databricks-sdk, azure-storage-file-share, azure-storage-blob, azure-mgmt-core, azure-core-tracing-opentelemetry, adal, transformers, opentelemetry-sdk, opentelemetry-instrumentation, onnxscript, ndg-httpsclient, msrestazure, msal, datasets, azure-storage-file-datalake, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-network, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, opentelemetry-resource-detector-azure, opentelemetry-instrumentation-wsgi, opentelemetry-instrumentation-urllib3, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-dbapi, opentelemetry-instrumentation-asgi, msal-extensions, mlflow-tracing, mlflow-skinny, azure-graphrbac, opentelemetry-instrumentation-psycopg2, opentelemetry-instrumentation-flask, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-django, mlflow, azureml-core, azure-identity, azureml-mlflow, azureml-dataprep, azure-monitor-opentelemetry-exporter, azureml-inference-server-http, azureml-dataset-runtime, azure-monitor-opentelemetry, azure-ai-ml, azureml-defaults\n",
      "2025-12-17T23:46:51: #10 176.0   Attempting uninstall: numpy\n",
      "2025-12-17T23:46:51: #10 176.0     Found existing installation: numpy 2.2.6\n",
      "2025-12-17T23:46:51: #10 176.0     Uninstalling numpy-2.2.6:\n",
      "2025-12-17T23:46:51: #10 176.0       Successfully uninstalled numpy-2.2.6\n",
      "2025-12-17T23:46:51: #10 176.0   Attempting uninstall: fsspec\n",
      "2025-12-17T23:46:51: #10 176.0     Found existing installation: fsspec 2025.12.0\n",
      "2025-12-17T23:46:51: #10 176.0     Uninstalling fsspec-2025.12.0:\n",
      "2025-12-17T23:46:51: #10 176.0       Successfully uninstalled fsspec-2025.12.0\n",
      "2025-12-17T23:46:51: #10 176.0 \n",
      "2025-12-17T23:46:51: #10 176.0 Successfully installed Mako-1.3.10 PyJWT-2.10.1 PySocks-1.7.1 SecretStorage-3.5.0 adal-1.2.7 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 alembic-1.17.2 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.12.0 argcomplete-3.6.3 asgiref-3.11.0 async-timeout-5.0.1 attrs-25.4.0 azure-ai-ml-1.30.0 azure-common-1.1.28 azure-core-1.37.0 azure-core-tracing-opentelemetry-1.0.0b12 azure-graphrbac-0.61.2 azure-identity-1.17.0 azure-mgmt-authorization-4.0.0 azure-mgmt-containerregistry-14.0.0 azure-mgmt-core-1.6.0 azure-mgmt-keyvault-11.0.0 azure-mgmt-network-30.0.0 azure-mgmt-resource-24.0.0 azure-mgmt-storage-24.0.0 azure-monitor-opentelemetry-1.6.7 azure-monitor-opentelemetry-exporter-1.0.0b40 azure-storage-blob-12.19.0 azure-storage-file-datalake-12.14.0 azure-storage-file-share-12.23.1 azureml-core-1.61.0.post1 azureml-dataprep-5.4.2 azureml-dataprep-native-42.1.0 azureml-dataprep-rslex-2.25.2 azureml-dataset-runtime-1.61.0 azureml-defaults-1.61.0 azureml-inference-server-http-1.5.0 azureml-mlflow-1.60.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-5.0.0 blinker-1.9.0 cachetools-6.2.4 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 cloudpickle-2.2.1 colorama-0.4.6 coloredlogs-15.0.1 contextlib2-21.6.0 contourpy-1.3.2 cryptography-46.0.3 cycler-0.12.1 databricks-sdk-0.76.0 datasets-4.0.0 deprecated-1.3.1 dill-0.3.8 docker-7.1.0 exceptiongroup-1.3.1 fastapi-0.125.0 fixedint-0.1.6 flask-3.1.2 flask-cors-6.0.2 flatbuffers-25.9.23 fonttools-4.61.1 frozenlist-1.8.0 fsspec-2025.3.0 fusepy-3.0.1 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.45.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 greenlet-3.3.0 gunicorn-23.0.0 h11-0.16.0 hf-xet-1.2.0 huey-2.5.5 huggingface-hub-0.36.0 humanfriendly-10.0 idna-3.11 importlib-metadata-8.6.1 inference-schema-1.8 isodate-0.7.2 itsdangerous-2.2.0 jeepney-0.9.0 jmespath-1.0.1 joblib-1.5.3 jsonpickle-4.1.1 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kiwisolver-1.4.9 knack-0.12.0 marshmallow-3.26.1 matplotlib-3.10.8 ml_dtypes-0.5.4 mlflow-3.7.0 mlflow-skinny-3.7.0 mlflow-tracing-3.7.0 msal-1.34.0 msal-extensions-1.3.1 msrest-0.7.1 msrestazure-0.6.4.post1 multidict-6.7.0 multiprocess-0.70.16 ndg-httpsclient-0.5.1 numpy-1.26.4 oauthlib-3.3.1 onnx-1.20.0 onnx_ir-0.1.13 onnxruntime-1.23.2 onnxscript-0.5.7 opentelemetry-api-1.33.0 opentelemetry-instrumentation-0.54b0 opentelemetry-instrumentation-asgi-0.54b0 opentelemetry-instrumentation-dbapi-0.54b0 opentelemetry-instrumentation-django-0.54b0 opentelemetry-instrumentation-fastapi-0.54b0 opentelemetry-instrumentation-flask-0.54b0 opentelemetry-instrumentation-psycopg2-0.54b0 opentelemetry-instrumentation-requests-0.54b0 opentelemetry-instrumentation-urllib-0.54b0 opentelemetry-instrumentation-urllib3-0.54b0 opentelemetry-instrumentation-wsgi-0.54b0 opentelemetry-proto-1.39.1 opentelemetry-resource-detector-azure-0.1.5 opentelemetry-sdk-1.33.0 opentelemetry-semantic-conventions-0.54b0 opentelemetry-util-http-0.54b0 packaging-25.0 pandas-2.3.3 paramiko-3.5.1 pathspec-0.12.1 pillow-12.0.0 pkginfo-1.12.1.2 propcache-0.4.1 protobuf-6.33.2 psutil-7.1.3 pyarrow-20.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.23 pydantic-2.11.10 pydantic-core-2.33.2 pydantic-settings-2.12.0 pydash-8.0.5 pygments-2.19.2 pynacl-1.6.1 pyopenssl-25.3.0 pyparsing-3.2.5 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 pytz-2025.2 pyyaml-6.0.3 referencing-0.37.0 regex-2025.11.3 requests-2.32.5 requests-oauthlib-2.0.0 rpds-py-0.30.0 rsa-4.9.1 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 sentencepiece-0.2.1 seqeval-1.2.2 six-1.17.0 smmap-5.0.2 sqlalchemy-2.0.45 sqlparse-0.5.4 starlette-0.50.0 strictyaml-1.7.3 tabulate-0.9.0 threadpoolctl-3.6.0 tokenizers-0.22.1 tomli-2.3.0 tqdm-4.67.1 transformers-4.57.3 typing-inspection-0.4.2 tzdata-2025.3 urllib3-2.6.2 uvicorn-0.38.0 werkzeug-3.1.4 wrapt-1.16.0 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0\n",
      "2025-12-17T23:46:51: #10 176.1 \n",
      "2025-12-17T23:46:51: #10 176.done\n",
      "2025-12-17T23:46:51: #10 176.1 #\n",
      "2025-12-17T23:46:51: #10 176.1 # To activate this environment, use\n",
      "2025-12-17T23:46:51: #10 176.1 #\n",
      "2025-12-17T23:46:51: #10 176.1 #     $ conda activate /azureml-envs/azureml_bb93a5711d9b741f8028ca5679c6fc73\n",
      "2025-12-17T23:46:51: #10 176.1 #\n",
      "2025-12-17T23:46:51: #10 176.1 # To deactivate an active environment, use\n",
      "2025-12-17T23:46:51: #10 176.1 #\n",
      "2025-12-17T23:46:51: #10 176.1 #     $ conda deactivate\n",
      "2025-12-17T23:46:51: #10 176.1 \n",
      "2025-12-17T23:46:57: #10 DONE 182.0s\n",
      "\n",
      "2025-12-17T23:46:57: #11 [ 7/10] COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      "2025-12-17T23:46:57: #11 DONE 0.2s\n",
      "\n",
      "2025-12-17T23:46:57: #12 [ 8/10] RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      "2025-12-17T23:46:57: #12 DONE 0.3s\n",
      "\n",
      "2025-12-17T23:46:57: #13 [ 9/10] RUN rm -rf azureml-environment-setup\n",
      "2025-12-17T23:46:58: #13 DONE 0.4s\n",
      "\n",
      "2025-12-17T23:46:58: #14 exporting to image\n",
      "2025-12-17T23:46:58: #14 exporting layers\n",
      "2025-12-17T23:47:22: #14 exporting layers 23.9s done\n",
      "2025-12-17T23:47:22: #14 writing image sha256:420fe4426341fe88301db39e8740be945c1b07bc715e4acf65b00e54173653a4 done\n",
      "2025-12-17T23:47:22: #14 naming to b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_1e6880c22c772a6f385ad6c518e358dc 0.0s done\n",
      "2025-12-17T23:47:22: #14 naming to b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_1e6880c22c772a6f385ad6c518e358dc:1 0.0s done\n",
      "2025-12-17T23:47:22: #14 DONE 23.9s\n",
      "\n",
      "\n",
      "2025-12-17T23:47:22: Logging into Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-17T23:47:22: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "2025-12-17T23:47:22: Login Succeeded\n",
      "\n",
      "\n",
      "2025-12-17T23:47:22: Using default tag: latest\n",
      "2025-12-17T23:47:22: The push refers to repository [b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_1e6880c22c772a6f385ad6c518e358dc]\n",
      "2025-12-17T23:47:22: eb1d452e667f: Preparing\n",
      "2025-12-17T23:47:22: 5f70bf18a086: Preparing\n",
      "2025-12-17T23:47:22: 270764410f49: Preparing\n",
      "2025-12-17T23:47:22: 81d6a1ed78b5: Preparing\n",
      "2025-12-17T23:47:22: 040d38a128d1: Preparing\n",
      "2025-12-17T23:47:22: 870cb98de5bf: Preparing\n",
      "2025-12-17T23:47:22: 275e2fcef9c7: Preparing\n",
      "2025-12-17T23:47:22: 5f70bf18a086: Preparing\n",
      "2025-12-17T23:47:22: 6b0c1cfc8f15: Preparing\n",
      "2025-12-17T23:47:22: d0b10cfca986: Preparing\n",
      "2025-12-17T23:47:22: 2baf6d5fcdda: Preparing\n",
      "2025-12-17T23:47:22: 947277ce5638: Preparing\n",
      "2025-12-17T23:47:22: 2ea0beed9e18: Preparing\n",
      "2025-12-17T23:47:22: 7d3ba5b124ef: Preparing\n",
      "2025-12-17T23:47:22: cd1cc5cf0a38: Preparing\n",
      "2025-12-17T23:47:22: fa26ceb8799b: Preparing\n",
      "2025-12-17T23:47:22: 44bfba9b2552: Preparing\n",
      "2025-12-17T23:47:22: fffe76c64ef2: Preparing\n",
      "2025-12-17T23:47:22: 947277ce5638: Waiting\n",
      "2025-12-17T23:47:22: 2ea0beed9e18: Waiting\n",
      "2025-12-17T23:47:22: 7d3ba5b124ef: Waiting\n",
      "2025-12-17T23:47:22: cd1cc5cf0a38: Waiting\n",
      "2025-12-17T23:47:22: fa26ceb8799b: Waiting\n",
      "2025-12-17T23:47:22: 44bfba9b2552: Waiting\n",
      "2025-12-17T23:47:22: fffe76c64ef2: Waiting\n",
      "2025-12-17T23:47:22: 275e2fcef9c7: Waiting\n",
      "2025-12-17T23:47:22: 870cb98de5bf: Waiting\n",
      "2025-12-17T23:47:22: 6b0c1cfc8f15: Waiting\n",
      "2025-12-17T23:47:22: d0b10cfca986: Waiting\n",
      "2025-12-17T23:47:22: 2baf6d5fcdda: Waiting\n",
      "2025-12-17T23:47:22: 5f70bf18a086: Pushed\n",
      "2025-12-17T23:47:22: 040d38a128d1: Pushed\n",
      "2025-12-17T23:47:22: eb1d452e667f: Pushed\n",
      "2025-12-17T23:47:22: 270764410f49: Pushed\n",
      "2025-12-17T23:47:23: 6b0c1cfc8f15: Pushed\n",
      "2025-12-17T23:47:23: 275e2fcef9c7: Pushed\n",
      "2025-12-17T23:47:23: d0b10cfca986: Pushed\n",
      "2025-12-17T23:47:23: 870cb98de5bf: Pushed\n",
      "2025-12-17T23:47:23: 7d3ba5b124ef: Pushed\n",
      "2025-12-17T23:47:24: 947277ce5638: Pushed\n",
      "2025-12-17T23:47:25: cd1cc5cf0a38: Pushed\n",
      "2025-12-17T23:47:25: fa26ceb8799b: Pushed\n",
      "2025-12-17T23:47:27: 2baf6d5fcdda: Pushed\n",
      "2025-12-17T23:47:30: fffe76c64ef2: Pushed\n",
      "2025-12-17T23:47:40: 2ea0beed9e18: Pushed\n",
      "2025-12-17T23:47:48: 44bfba9b2552: Pushed\n",
      "2025-12-17T23:49:14: 81d6a1ed78b5: Pushed\n",
      "2025-12-17T23:49:15: latest: digest: sha256:7844b1c397ad0957aa41f8d9621c86a45c2a6ef0a9e753e146c1cd2ccbb9187f size: 4092\n",
      "\n",
      "\n",
      "2025-12-17T23:49:15: The push refers to repository [b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_1e6880c22c772a6f385ad6c518e358dc]\n",
      "2025-12-17T23:49:15: eb1d452e667f: Preparing\n",
      "2025-12-17T23:49:15: 5f70bf18a086: Preparing\n",
      "2025-12-17T23:49:15: 270764410f49: Preparing\n",
      "2025-12-17T23:49:15: 81d6a1ed78b5: Preparing\n",
      "2025-12-17T23:49:15: 040d38a128d1: Preparing\n",
      "2025-12-17T23:49:15: 870cb98de5bf: Preparing\n",
      "2025-12-17T23:49:15: 275e2fcef9c7: Preparing\n",
      "2025-12-17T23:49:15: 5f70bf18a086: Preparing\n",
      "2025-12-17T23:49:15: 6b0c1cfc8f15: Preparing\n",
      "2025-12-17T23:49:15: d0b10cfca986: Preparing\n",
      "2025-12-17T23:49:15: 2baf6d5fcdda: Preparing\n",
      "2025-12-17T23:49:15: 947277ce5638: Preparing\n",
      "2025-12-17T23:49:15: 2ea0beed9e18: Preparing\n",
      "2025-12-17T23:49:15: 7d3ba5b124ef: Preparing\n",
      "2025-12-17T23:49:15: cd1cc5cf0a38: Preparing\n",
      "2025-12-17T23:49:15: fa26ceb8799b: Preparing\n",
      "2025-12-17T23:49:15: 44bfba9b2552: Preparing\n",
      "2025-12-17T23:49:15: fffe76c64ef2: Preparing\n",
      "2025-12-17T23:49:15: 870cb98de5bf: Waiting\n",
      "2025-12-17T23:49:15: 275e2fcef9c7: Waiting\n",
      "2025-12-17T23:49:15: 6b0c1cfc8f15: Waiting\n",
      "2025-12-17T23:49:15: d0b10cfca986: Waiting\n",
      "2025-12-17T23:49:15: 2baf6d5fcdda: Waiting\n",
      "2025-12-17T23:49:15: 2ea0beed9e18: Waiting\n",
      "2025-12-17T23:49:15: 947277ce5638: Waiting\n",
      "2025-12-17T23:49:15: 44bfba9b2552: Waiting\n",
      "2025-12-17T23:49:15: fffe76c64ef2: Waiting\n",
      "2025-12-17T23:49:15: 7d3ba5b124ef: Waiting\n",
      "2025-12-17T23:49:15: cd1cc5cf0a38: Waiting\n",
      "2025-12-17T23:49:15: fa26ceb8799b: Waiting\n",
      "2025-12-17T23:49:15: eb1d452e667f: Layer already exists\n",
      "2025-12-17T23:49:15: 040d38a128d1: Layer already exists\n",
      "2025-12-17T23:49:15: 81d6a1ed78b5: Layer already exists\n",
      "2025-12-17T23:49:15: 5f70bf18a086: Layer already exists\n",
      "2025-12-17T23:49:15: 270764410f49: Layer already exists\n",
      "2025-12-17T23:49:15: 870cb98de5bf: Layer already exists\n",
      "2025-12-17T23:49:15: 275e2fcef9c7: Layer already exists\n",
      "2025-12-17T23:49:15: d0b10cfca986: Layer already exists\n",
      "2025-12-17T23:49:15: 2baf6d5fcdda: Layer already exists\n",
      "2025-12-17T23:49:15: 6b0c1cfc8f15: Layer already exists\n",
      "2025-12-17T23:49:15: 947277ce5638: Layer already exists\n",
      "2025-12-17T23:49:15: 2ea0beed9e18: Layer already exists\n",
      "2025-12-17T23:49:15: 7d3ba5b124ef: Layer already exists\n",
      "2025-12-17T23:49:15: cd1cc5cf0a38: Layer already exists\n",
      "2025-12-17T23:49:15: fa26ceb8799b: Layer already exists\n",
      "2025-12-17T23:49:15: fffe76c64ef2: Layer already exists\n",
      "2025-12-17T23:49:15: 44bfba9b2552: Layer already exists\n",
      "2025-12-17T23:49:16: 1: digest: sha256:7844b1c397ad0957aa41f8d9621c86a45c2a6ef0a9e753e146c1cd2ccbb9187f size: 4092\n",
      "\n",
      "\n",
      "2025-12-17T23:49:16: #### Image for post-processing commands: b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_1e6880c22c772a6f385ad6c518e358dc:latest\n",
      "2025-12-17T23:49:16: #### Image digest: sha256:7844b1c397ad0957aa41f8d9621c86a45c2a6ef0a9e753e146c1cd2ccbb9187f\n",
      "2025-12-17T23:49:16: \n",
      "\n",
      "#### Found send_dependencies.py at: /tmp/tmpb5sj3cbn/azureml-environment-setup/send_dependencies.py\n",
      "2025-12-17T23:49:16: #### Attempting to run dependencies script\n",
      "\n",
      "\n",
      "2025-12-17T23:49:21: Report materialized dependencies for the environment\n",
      "2025-12-17T23:49:21: Reading environment context\n",
      "2025-12-17T23:49:21: Exporting conda environment\n",
      "2025-12-17T23:49:21: Sending request with materialized conda environment details\n",
      "2025-12-17T23:49:21: Successfully sent materialized environment dependencies\n",
      "\n",
      "\n",
      "2025-12-17T23:49:21: fe7003ff76e289928f27844dd39f309826fcf7ca83352bb6ff2fdd41ee9634bf\n",
      "\n",
      "\n",
      "2025-12-17T23:49:21: #### Cleaning up local image cache\n",
      "2025-12-17T23:49:21: Deleting b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_1e6880c22c772a6f385ad6c518e358dc from local machine\n",
      "2025-12-17T23:49:22: Error response from daemon: page not found\n",
      "\n",
      "\n",
      "2025-12-17T23:49:22: Logging out of Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-17T23:49:22: Removing login credentials for https://index.docker.io/v1/\n",
      "\n",
      "\n",
      "2025-12-17T23:49:22: Logging out of Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-17T23:49:22: Removing login credentials for https://index.docker.io/v1/\n",
      "\n",
      "\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: red_cloud_g6j6jxh3yr\n",
      "Web View: https://ml.azure.com/runs/red_cloud_g6j6jxh3yr?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from orchestration.environment import (\n",
    "    build_environment_config,\n",
    "    create_training_environment,\n",
    "    prepare_environment_image,\n",
    ")\n",
    "\n",
    "# Build environment configuration from env.yaml (with sensible defaults)\n",
    "env_config = build_environment_config(CONFIG_DIR, configs[\"env\"])\n",
    "\n",
    "# Materialize or fetch the Azure ML Environment\n",
    "training_environment = create_training_environment(ml_client, env_config)\n",
    "\n",
    "# Trigger a small warm-up job so the image is built/cached before real work\n",
    "prepare_environment_image(\n",
    "    ml_client=ml_client,\n",
    "    environment=training_environment,\n",
    "    compute_cluster=configs[\"env\"][\"compute\"][\"training_cluster\"],\n",
    "    env_config=env_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training environment: resume-ner-training vv8dba3aeec663aed1 to training_environment_cache.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save environment info to a JSON file\n",
    "env_cache_file = Path(\"training_environment_cache.json\")\n",
    "\n",
    "if 'training_environment' in globals() and training_environment is not None:\n",
    "    env_data = {\n",
    "        \"name\": training_environment.name,\n",
    "        \"version\": training_environment.version,\n",
    "    }\n",
    "    \n",
    "    with open(env_cache_file, \"w\") as f:\n",
    "        json.dump(env_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved training environment: {env_data['name']} v{env_data['version']} to {env_cache_file}\")\n",
    "else:\n",
    "    print(\"No training environment to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training environment: resume-ner-training vv8dba3aeec663aed1\n",
      "Skipping environment setup - using cached environment\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to reload from cache\n",
    "env_cache_file = Path(\"training_environment_cache.json\")\n",
    "\n",
    "if env_cache_file.exists():\n",
    "    with open(env_cache_file, \"r\") as f:\n",
    "        env_data = json.load(f)\n",
    "    \n",
    "    try:\n",
    "        # Reload Environment object from ML client\n",
    "        training_environment = ml_client.environments.get(\n",
    "            name=env_data[\"name\"],\n",
    "            version=env_data[\"version\"]\n",
    "        )\n",
    "        print(f\"Loaded training environment: {training_environment.name} v{training_environment.version}\")\n",
    "        print(\"Skipping environment setup - using cached environment\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load environment {env_data['name']} v{env_data['version']}: {e}\")\n",
    "        print(\"Will need to create environment again\")\n",
    "        training_environment = None\n",
    "else:\n",
    "    print(f\"Cache file {env_cache_file} not found. Will need to create environment.\")\n",
    "    training_environment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.4: The Dry Run\n",
    "\n",
    "Submit a minimal sweep job using `smoke.yaml` to validate the sweep mechanism and pipeline integrity before launching the production HPO sweep.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/current/lib/python3.12/site-packages/mlflow/__init__.py:41: UserWarning: Versions of mlflow (3.7.0) and child packages mlflow-skinny (3.5.0) are different. This may lead to unexpected behavior. Please install the same version of all MLflow packages.\n",
      "  mlflow.mismatch._check_version_mismatch()\n"
     ]
    }
   ],
   "source": [
    "from orchestration.jobs import (\n",
    "    create_dry_run_sweep_job_for_backbone,\n",
    "    submit_and_wait_for_job,\n",
    "    validate_sweep_job,\n",
    ")\n",
    "\n",
    "TRAINING_SCRIPT_PATH = Path(\"../src/train.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cluster_name = configs[\"env\"][\"compute\"][\"training_cluster\"]\n",
    "\n",
    "try:\n",
    "    compute_cluster = ml_client.compute.get(compute_cluster_name)\n",
    "    if compute_cluster.provisioning_state != \"Succeeded\":\n",
    "        raise ValueError(f\"Compute cluster not ready: {compute_cluster.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Compute cluster '{compute_cluster_name}' not accessible: {e}\")\n",
    "\n",
    "stage_name = STAGE_SMOKE\n",
    "smoke_hpo_config = configs[\"hpo\"]\n",
    "\n",
    "# Backbones are controlled by the HPO config file (single source of truth)\n",
    "backbone_values = smoke_hpo_config[\"search_space\"][\"backbone\"][\"values\"]\n",
    "\n",
    "dry_run_sweep_jobs = {}\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    aml_experiment_name = build_aml_experiment_name(\n",
    "        experiment_config,\n",
    "        configs[\"env\"],\n",
    "        stage_name,\n",
    "        backbone,\n",
    "    )\n",
    "    dry_run_sweep_jobs[backbone] = create_dry_run_sweep_job_for_backbone(\n",
    "        script_path=TRAINING_SCRIPT_PATH,\n",
    "        data_asset=data_asset,\n",
    "        environment=training_environment,\n",
    "        compute_cluster=compute_cluster_name,\n",
    "        backbone=backbone,\n",
    "        smoke_hpo_config=smoke_hpo_config,\n",
    "        configs=configs,\n",
    "        config_metadata=config_metadata,\n",
    "        aml_experiment_name=aml_experiment_name,\n",
    "        stage=stage_name,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading resume-ner-azureml (0.17 MBs): 100%|██████████| 165299/165299 [00:03<00:00, 41641.68it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: silver_pasta_yqzs0g82xm\n",
      "Web View: https://ml.azure.com/runs/silver_pasta_yqzs0g82xm?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "[2025-12-17T22:49:50.7407231Z][GENERATOR][DEBUG]Sampled 2 jobs from search space \n",
      "[2025-12-17T22:49:51.1172505Z][SCHEDULER][INFO]Scheduling job, id='silver_pasta_yqzs0g82xm_0' \n",
      "[2025-12-17T22:49:51.1541293Z][SCHEDULER][INFO]Scheduling job, id='silver_pasta_yqzs0g82xm_1' \n",
      "[2025-12-17T22:49:51.9137620Z][SCHEDULER][INFO]Successfully scheduled a job. Id='silver_pasta_yqzs0g82xm_1' \n",
      "[2025-12-17T22:49:52.0647700Z][SCHEDULER][INFO]Successfully scheduled a job. Id='silver_pasta_yqzs0g82xm_0' \n",
      "[2025-12-17T22:50:21.3548591Z][GENERATOR][DEBUG]Setting all jobs generated as True, reason : Max number of jobs reached \n",
      "[2025-12-17T22:59:24.5812109Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: silver_pasta_yqzs0g82xm\n",
      "Web View: https://ml.azure.com/runs/silver_pasta_yqzs0g82xm?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for backbone, sweep_job in dry_run_sweep_jobs.items():\n",
    "    completed_job = submit_and_wait_for_job(ml_client, sweep_job)\n",
    "    validate_sweep_job(\n",
    "        job=completed_job,\n",
    "        backbone=backbone,\n",
    "        job_type=\"Dry run sweep\",\n",
    "        ml_client=ml_client,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.5: The Sweep (HPO)\n",
    "\n",
    "Submit a hyperparameter optimization sweep to systematically search for the best model configuration.\n",
    "\n",
    "**Note**: Currently using `smoke.yaml` for demonstration purposes (CPU-only setup). For production with GPU, switch to `prod.yaml` in the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs import (\n",
    "    create_hpo_sweep_job_for_backbone,\n",
    "    submit_and_wait_for_job,\n",
    "    validate_sweep_job,\n",
    ")\n",
    "\n",
    "TRAINING_SCRIPT_PATH = Path(\"../src/train.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cluster_name = configs[\"env\"][\"compute\"][\"training_cluster\"]\n",
    "\n",
    "try:\n",
    "    compute_cluster = ml_client.compute.get(compute_cluster_name)\n",
    "    if compute_cluster.provisioning_state != \"Succeeded\":\n",
    "        raise ValueError(f\"Compute cluster not ready: {compute_cluster.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Compute cluster '{compute_cluster_name}' not accessible: {e}\")\n",
    "\n",
    "stage_name = STAGE_HPO\n",
    "hpo_config = configs[\"hpo\"]\n",
    "backbone_values = configs[\"hpo\"][\"search_space\"][\"backbone\"][\"values\"]\n",
    "hpo_sweep_jobs = {}\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    aml_experiment_name = build_aml_experiment_name(\n",
    "        experiment_config,\n",
    "        configs[\"env\"],\n",
    "        stage_name,\n",
    "        backbone,\n",
    "    )\n",
    "    hpo_sweep_jobs[backbone] = create_hpo_sweep_job_for_backbone(\n",
    "        script_path=TRAINING_SCRIPT_PATH,\n",
    "        data_asset=data_asset,\n",
    "        environment=training_environment,\n",
    "        compute_cluster=compute_cluster_name,\n",
    "        hpo_config=hpo_config,\n",
    "        backbone=backbone,\n",
    "        configs=configs,\n",
    "        config_metadata=config_metadata,\n",
    "        aml_experiment_name=aml_experiment_name,\n",
    "        stage=stage_name,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: sincere_onion_jxjs9zm1pr\n",
      "Web View: https://ml.azure.com/runs/sincere_onion_jxjs9zm1pr?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "[2025-12-17T23:02:24.2657702Z][GENERATOR][DEBUG]Sampled 2 jobs from search space \n",
      "[2025-12-17T23:02:24.5435094Z][SCHEDULER][INFO]Scheduling job, id='sincere_onion_jxjs9zm1pr_0' \n",
      "[2025-12-17T23:02:24.5807937Z][SCHEDULER][INFO]Scheduling job, id='sincere_onion_jxjs9zm1pr_1' \n",
      "[2025-12-17T23:02:25.3311199Z][SCHEDULER][INFO]Successfully scheduled a job. Id='sincere_onion_jxjs9zm1pr_0' \n",
      "[2025-12-17T23:02:25.4121992Z][SCHEDULER][INFO]Successfully scheduled a job. Id='sincere_onion_jxjs9zm1pr_1' \n",
      "[2025-12-17T23:02:54.7192606Z][GENERATOR][DEBUG]Setting all jobs generated as True, reason : Max number of jobs reached \n",
      "[2025-12-17T23:05:25.2067315Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: sincere_onion_jxjs9zm1pr\n",
      "Web View: https://ml.azure.com/runs/sincere_onion_jxjs9zm1pr?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hpo_completed_jobs = {}\n",
    "\n",
    "for backbone, sweep_job in hpo_sweep_jobs.items():\n",
    "    completed_job = submit_and_wait_for_job(ml_client, sweep_job)\n",
    "    validate_sweep_job(\n",
    "        job=completed_job,\n",
    "        backbone=backbone,\n",
    "        job_type=\"HPO sweep\",\n",
    "        min_expected_trials=2,\n",
    "        ml_client=ml_client,\n",
    "    )\n",
    "    hpo_completed_jobs[backbone] = completed_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 HPO job references to hpo_completed_jobs_cache.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save job names to a JSON file\n",
    "hpo_jobs_cache_file = Path(\"hpo_completed_jobs_cache.json\")\n",
    "\n",
    "if hpo_completed_jobs:\n",
    "    # Extract job names (which are strings and easily serializable)\n",
    "    hpo_jobs_data = {\n",
    "        backbone: {\n",
    "            \"job_name\": job.name,\n",
    "            \"job_id\": job.id,\n",
    "        }\n",
    "        for backbone, job in hpo_completed_jobs.items()\n",
    "    }\n",
    "    \n",
    "    with open(hpo_jobs_cache_file, \"w\") as f:\n",
    "        json.dump(hpo_jobs_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved {len(hpo_jobs_data)} HPO job references to {hpo_jobs_cache_file}\")\n",
    "else:\n",
    "    print(\"No HPO completed jobs to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HPO job for deberta: sincere_onion_jxjs9zm1pr (status: Completed)\n",
      "\n",
      "Successfully reloaded 1 HPO completed jobs from cache\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to reload from cache\n",
    "hpo_jobs_cache_file = Path(\"hpo_completed_jobs_cache.json\")\n",
    "\n",
    "if hpo_jobs_cache_file.exists():\n",
    "    with open(hpo_jobs_cache_file, \"r\") as f:\n",
    "        hpo_jobs_data = json.load(f)\n",
    "    \n",
    "    # Reload Job objects from ML client\n",
    "    hpo_completed_jobs = {}\n",
    "    for backbone, job_info in hpo_jobs_data.items():\n",
    "        try:\n",
    "            job = ml_client.jobs.get(job_info[\"job_name\"])\n",
    "            hpo_completed_jobs[backbone] = job\n",
    "            print(f\"Loaded HPO job for {backbone}: {job.name} (status: {job.status})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load job {job_info['job_name']} for {backbone}: {e}\")\n",
    "    \n",
    "    if hpo_completed_jobs:\n",
    "        print(f\"\\nSuccessfully reloaded {len(hpo_completed_jobs)} HPO completed jobs from cache\")\n",
    "    else:\n",
    "        print(\"No valid jobs found in cache, will need to run HPO again\")\n",
    "        hpo_completed_jobs = {}\n",
    "else:\n",
    "    print(f\"Cache file {hpo_jobs_cache_file} not found. Will need to run HPO.\")\n",
    "    hpo_completed_jobs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.6: Best Configuration Selection (Automated)\n",
    "\n",
    "Programmatically select the best configuration from all HPO sweep runs across all backbone models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs import select_best_configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best configuration from all HPO sweep runs\n",
    "best_configuration = select_best_configuration(\n",
    "    ml_client=ml_client,\n",
    "    hpo_completed_jobs=hpo_completed_jobs,\n",
    "    hpo_config=configs[\"hpo\"],\n",
    "    dataset_version=configs[\"data\"][\"version\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trial_name': 'sincere_onion_jxjs9zm1pr_0',\n",
       " 'trial_id': '/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/jobs/sincere_onion_jxjs9zm1pr_0',\n",
       " 'backbone': 'deberta',\n",
       " 'hyperparameters': {'learning_rate': '1.0000268243753498',\n",
       "  'batch_size': '4',\n",
       "  'dropout': '0.14430746590491816',\n",
       "  'weight_decay': '1.0846340242099708',\n",
       "  'epochs': '2',\n",
       "  'backbone': 'microsoft/deberta-v3-base'},\n",
       " 'metrics': {'macro-f1': 0.056306306306306314,\n",
       "  'macro-f1-span': 0.30959752321981426,\n",
       "  'loss': 135.18899536132812},\n",
       " 'dataset_version': 'v2.1',\n",
       " 'selection_criteria': {'metric': 'macro-f1',\n",
       "  'goal': 'maximize',\n",
       "  'best_value': 0.056306306306306314,\n",
       "  'backbone': 'deberta'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best configuration to best_configuration_cache.json\n",
      "  Backbone: deberta\n",
      "  Best metric value: 0.056306306306306314\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save best configuration to a JSON file\n",
    "best_config_cache_file = Path(\"best_configuration_cache.json\")\n",
    "\n",
    "if \"best_configuration\" in globals() and best_configuration is not None:\n",
    "    # best_configuration contains trial_name, trial_id, backbone, hyperparameters, metrics, etc.\n",
    "    # All of these are JSON-serializable\n",
    "    with open(best_config_cache_file, \"w\") as f:\n",
    "        json.dump(best_configuration, f, indent=2)\n",
    "    print(f\"Saved best configuration to {best_config_cache_file}\")\n",
    "    print(f\"  Backbone: {best_configuration.get('backbone')}\")\n",
    "    print(f\"  Best metric value: {best_configuration.get('selection_criteria', {}).get('best_value')}\")\n",
    "else:\n",
    "    print(\"No best configuration to save\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best configuration from cache:\n",
      "  Backbone: deberta\n",
      "  Trial: sincere_onion_jxjs9zm1pr_0\n",
      "  Best metric value: 0.056306306306306314\n",
      "  Dataset version: v2.1\n",
      "\n",
      "Skipping best configuration selection - using cached result\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to reload from cache\n",
    "best_config_cache_file = Path(\"best_configuration_cache.json\")\n",
    "\n",
    "if best_config_cache_file.exists():\n",
    "    with open(best_config_cache_file, \"r\") as f:\n",
    "        best_configuration = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded best configuration from cache:\")\n",
    "    print(f\"  Backbone: {best_configuration.get('backbone')}\")\n",
    "    print(f\"  Trial: {best_configuration.get('trial_name')}\")\n",
    "    print(f\"  Best metric value: {best_configuration.get('selection_criteria', {}).get('best_value')}\")\n",
    "    print(f\"  Dataset version: {best_configuration.get('dataset_version')}\")\n",
    "    print(f\"\\nSkipping best configuration selection - using cached result\")\n",
    "else:\n",
    "    print(f\"Cache file {best_config_cache_file} not found. Will need to run Step P1-3.6.\")\n",
    "    best_configuration = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.7: Final Training (Post-HPO, Single Run)\n",
    "\n",
    "Train the final production model using the best configuration from HPO with stable, controlled conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs import (\n",
    "    build_final_training_config,\n",
    "    create_final_training_job,\n",
    "    validate_final_training_job,\n",
    "    submit_and_wait_for_job\n",
    ")\n",
    "\n",
    "TRAINING_SCRIPT_PATH = Path(\"../src/train.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final training config from best HPO result + train.yaml defaults\n",
    "final_training_config = build_final_training_config(best_configuration, configs[\"train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone': 'deberta',\n",
       " 'learning_rate': '1.0000268243753498',\n",
       " 'dropout': '0.14430746590491816',\n",
       " 'weight_decay': '1.0846340242099708',\n",
       " 'batch_size': 4,\n",
       " 'epochs': 2,\n",
       " 'random_seed': 42,\n",
       " 'early_stopping_enabled': False,\n",
       " 'use_combined_data': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cluster_name = configs[\"env\"][\"compute\"][\"training_cluster\"]\n",
    "\n",
    "try:\n",
    "    compute_cluster = ml_client.compute.get(compute_cluster_name)\n",
    "    if compute_cluster.provisioning_state != \"Succeeded\":\n",
    "        raise ValueError(f\"Compute cluster not ready: {compute_cluster.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Compute cluster '{compute_cluster_name}' not accessible: {e}\")\n",
    "    \n",
    "# Create and submit final training job\n",
    "stage_name = STAGE_TRAINING\n",
    "aml_experiment_name = build_aml_experiment_name(\n",
    "    experiment_config,\n",
    "    configs[\"env\"],\n",
    "    stage_name,\n",
    "    final_training_config[\"backbone\"],\n",
    ")\n",
    "\n",
    "final_training_job = create_final_training_job(\n",
    "    script_path=TRAINING_SCRIPT_PATH,\n",
    "    data_asset_datastore_path=datastore_path,\n",
    "    environment=training_environment,\n",
    "    compute_cluster=compute_cluster_name,\n",
    "    final_config=final_training_config,\n",
    "    configs=configs,\n",
    "    config_metadata=config_metadata,\n",
    "    best_trial_name=best_configuration[\"trial_name\"],\n",
    "    best_value=best_configuration[\"selection_criteria\"][\"best_value\"],\n",
    "    aml_experiment_name=aml_experiment_name,\n",
    "    stage=stage_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: plucky_pumpkin_kd897lscw8\n",
      "Web View: https://ml.azure.com/runs/plucky_pumpkin_kd897lscw8?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: plucky_pumpkin_kd897lscw8\n",
      "Web View: https://ml.azure.com/runs/plucky_pumpkin_kd897lscw8?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Submit and validate final training job\n",
    "final_training_completed_job = submit_and_wait_for_job(ml_client, final_training_job)\n",
    "validate_final_training_job(final_training_completed_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final training job reference to final_training_job_cache.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "final_training_cache_file = Path(\"final_training_job_cache.json\")\n",
    "\n",
    "if \"final_training_completed_job\" in globals() and final_training_completed_job is not None:\n",
    "    data = {\n",
    "        \"job_name\": final_training_completed_job.name,\n",
    "        \"job_id\": final_training_completed_job.id,\n",
    "    }\n",
    "    with open(final_training_cache_file, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"Saved final training job reference to {final_training_cache_file}\")\n",
    "else:\n",
    "    print(\"No final training job to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded final training job: plucky_pumpkin_kd897lscw8 (status: Completed)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "final_training_cache_file = Path(\"final_training_job_cache.json\")\n",
    "\n",
    "if final_training_cache_file.exists():\n",
    "    with open(final_training_cache_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    try:\n",
    "        final_training_completed_job = ml_client.jobs.get(data[\"job_name\"])\n",
    "        print(f\"Loaded final training job: {final_training_completed_job.name} (status: {final_training_completed_job.status})\")\n",
    "        \n",
    "        # Validate that the job has a checkpoint output\n",
    "        if not hasattr(final_training_completed_job, \"outputs\") or \"checkpoint\" not in final_training_completed_job.outputs:\n",
    "            print(f\"\\n⚠️  WARNING: Training job {final_training_completed_job.name} does not have a 'checkpoint' output.\")\n",
    "            print(\"   This job cannot be used for model conversion.\")\n",
    "            print(\"   Please re-run Step P1-3.7: Final Training to generate a new job with checkpoint output.\")\n",
    "            final_training_completed_job = None\n",
    "        else:\n",
    "            print(f\"✓ Training job has checkpoint output\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not reload final training job {data['job_name']}: {e}\")\n",
    "        final_training_completed_job = None\n",
    "else:\n",
    "    print(f\"No cache file {final_training_cache_file} found; you need to rerun Step 3.7.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-4: Model Conversion & Optimization\n",
    "\n",
    "Convert the final training checkpoint to an optimized ONNX model (int8 quantized) for production inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>resume-ner-train-deberta</td><td>plucky_pumpkin_kd897lscw8</td><td>command</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/plucky_pumpkin_kd897lscw8?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&amp;tid=e7572e92-7aee-4713-a3c4-ba64888ad45f\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {'learning_rate': '1.0000268243753498', 'batch_size': '4', 'dropout': '0.14430746590491816', 'weight_decay': '1.0846340242099708', 'epochs': '2', 'backbone': 'microsoft/deberta-v3-base'}, 'init': False, 'name': 'plucky_pumpkin_kd897lscw8', 'type': 'command', 'status': 'Completed', 'log_files': None, 'description': 'Final production training with best HPO configuration', 'tags': {'data_config_hash': '2f21eff8258574d6', 'model_config_hash': '5f90a66353401b44', 'train_config_hash': 'f0c2caf728759868', 'hpo_config_hash': 'b28114c649d43a67', 'env_config_hash': '3e54b931c7640cf2', 'data_version': 'v2.1', 'model_backbone': 'distilbert-base-uncased', 'job_type': 'final_training', 'backbone': 'deberta', 'best_trial': 'sincere_onion_jxjs9zm1pr_0', 'best_metric_value': '0.056306306306306314', 'stage': 'training', '_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":0,\"CurrentNodeCount\":2}'}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/longdang193/resume-ner-azureml', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '911df2cae6b4e15a4276a5789eeeb72e48605202', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'cpu-cluster', 'ContentSnapshotId': '5d171656-c15c-4a5e-8b3c-4b5847211df7', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'StartTimeUtc': '2025-12-17 23:11:02', 'EndTimeUtc': '2025-12-17 23:12:35'}, 'print_as_yaml': False, 'id': '/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/jobs/plucky_pumpkin_kd897lscw8', 'Resource__source_path': '', 'base_path': '/workspaces/resume-ner-azureml/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fcd0486a5d0>, 'serialize': <msrest.serialization.Serializer object at 0x7fcd04716a80>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'final-training', 'experiment_name': 'resume-ner-train-deberta', 'compute': 'cpu-cluster', 'services': {'Tracking': {'endpoint': 'azureml://japanwest.api.azureml.ms/mlflow/v1.0/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/plucky_pumpkin_kd897lscw8?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/3232563f3982da9961ea618d65a32a106230b55248141ce91a9158d93c07e092/dataset_tiny', 'mode': 'ro_mount'}}, 'job_outputs': {'checkpoint': {'type': 'uri_folder', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.plucky_pumpkin_kd897lscw8', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fcd04715e50>}, 'outputs': {'checkpoint': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fcd047305f0>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fcd04730ce0>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'plucky_pumpkin_kd897lscw8', 'description': 'Final production training with best HPO configuration', 'tags': {'data_config_hash': '2f21eff8258574d6', 'model_config_hash': '5f90a66353401b44', 'train_config_hash': 'f0c2caf728759868', 'hpo_config_hash': 'b28114c649d43a67', 'env_config_hash': '3e54b931c7640cf2', 'data_version': 'v2.1', 'model_backbone': 'distilbert-base-uncased', 'job_type': 'final_training', 'backbone': 'deberta', 'best_trial': 'sincere_onion_jxjs9zm1pr_0', 'best_metric_value': '0.056306306306306314', 'stage': 'training', '_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":0,\"CurrentNodeCount\":2}'}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/workspaces/resume-ner-azureml/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fcd0486a5d0>, 'serialize': <msrest.serialization.Serializer object at 0x7fcd0486b200>, 'command': 'python src/train.py --data-asset ${{inputs.data}} --config-dir config --backbone deberta --learning-rate 1.0000268243753498 --batch-size 4 --dropout 0.14430746590491816 --weight-decay 1.0846340242099708 --epochs 2 --random-seed 42 --early-stopping-enabled false --use-combined-data true', 'code': '/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/codes/5b8eae97-a068-4bcd-bbbb-4d40f79325ee/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/environments/resume-ner-training/versions/v0656c70c562dd554', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'final-training', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/3232563f3982da9961ea618d65a32a106230b55248141ce91a9158d93c07e092/dataset_tiny', 'mode': 'ro_mount'}}, 'outputs': {'checkpoint': {'type': 'uri_folder', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.plucky_pumpkin_kd897lscw8', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Completed', 'parameters': {'learning_rate': '1.0000268243753498', 'batch_size': '4', 'dropout': '0.14430746590491816', 'weight_decay': '1.0846340242099708', 'epochs': '2', 'backbone': 'microsoft/deberta-v3-base'}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://japanwest.api.azureml.ms/mlflow/v1.0/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/plucky_pumpkin_kd897lscw8?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f', 'type': 'Studio'}}, 'status': 'Completed', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fcd0486a5d0>}, 'instance_id': '3e79cf5d-718d-41b4-923d-558d9b14b53c', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'resume-ner-training:v0656c70c562dd554', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': {'job_tier': 'null'}, 'parent_job_name': None, 'swept': False})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_training_completed_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/current/lib/python3.12/site-packages/mlflow/__init__.py:41: UserWarning: Versions of mlflow (3.7.0) and child packages mlflow-skinny (3.5.0) are different. This may lead to unexpected behavior. Please install the same version of all MLflow packages.\n",
      "  mlflow.mismatch._check_version_mismatch()\n"
     ]
    }
   ],
   "source": [
    "from orchestration.jobs import (\n",
    "    get_checkpoint_output_from_training_job,\n",
    "    create_conversion_job,\n",
    "    validate_conversion_job,\n",
    "    submit_and_wait_for_job,\n",
    ")\n",
    "\n",
    "CONVERSION_SCRIPT_PATH = Path(\"../src/convert_to_onnx.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/resume-ner-azureml/src/orchestration/jobs/conversion.py:75: UserWarning: ml_client not provided for training job 'plucky_pumpkin_kd897lscw8'. Constructing data asset reference directly. For best results, provide ml_client.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Guard: ensure final_training_completed_job is set and has checkpoint output\n",
    "if \"final_training_completed_job\" not in globals() or final_training_completed_job is None:\n",
    "    raise ValueError(\n",
    "        \"final_training_completed_job is not set. \"\n",
    "        \"Please run Step P1-3.7: Final Training first, or ensure the cached job has a checkpoint output.\"\n",
    "    )\n",
    "\n",
    "# Guard: ensure ml_client is defined (required for fetching checkpoint data asset)\n",
    "if \"ml_client\" not in globals() or ml_client is None:\n",
    "    raise ValueError(\n",
    "        \"ml_client is not defined. \"\n",
    "        \"Please run the cells that set up ml_client (Step P1-3.1) before running this cell.\"\n",
    "    )\n",
    "\n",
    "checkpoint_output = get_checkpoint_output_from_training_job(final_training_completed_job, ml_client=ml_client)\n",
    "print(f\"✓ Retrieved checkpoint output: {checkpoint_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_cluster_name = configs[\"env\"][\"compute\"][\"conversion_cluster\"]\n",
    "conversion_job = create_conversion_job(\n",
    "    script_path=CONVERSION_SCRIPT_PATH,\n",
    "    checkpoint_output=checkpoint_output,\n",
    "    environment=training_environment,\n",
    "    compute_cluster=conversion_cluster_name,\n",
    "    configs=configs,\n",
    "    config_metadata=config_metadata,\n",
    "    best_config=best_configuration,\n",
    "    final_training_job=final_training_completed_job,\n",
    "    ml_client=ml_client,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "\u001b[32mUploading resume-ner-azureml (0.17 MBs): 100%|██████████| 165372/165372 [00:04<00:00, 35479.14it/s]\n",
      "\u001b[39m\n",
      "\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: purple_wall_rgn3r3jgg2\n",
      "Web View: https://ml.azure.com/runs/purple_wall_rgn3r3jgg2?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n"
     ]
    }
   ],
   "source": [
    "conversion_completed_job = submit_and_wait_for_job(ml_client, conversion_job)\n",
    "validate_conversion_job(conversion_completed_job, ml_client=ml_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-5: Model Registration (The Handover)\n",
    "\n",
    "Register the optimized ONNX model in Azure ML Model Registry with full metadata for production deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.core.exceptions import ResourceNotFoundError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onnx_model_path(conversion_job: Job) -> str:\n",
    "    \"\"\"\n",
    "    Get ONNX model path from completed conversion job.\n",
    "    \n",
    "    Args:\n",
    "        conversion_job: Completed conversion job\n",
    "        \n",
    "    Returns:\n",
    "        str: ONNX model path (Azure ML datastore URI)\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If ONNX model not found in job outputs\n",
    "    \"\"\"\n",
    "    if not hasattr(conversion_job, \"outputs\") or not conversion_job.outputs:\n",
    "        raise ValueError(\"Conversion job produced no outputs\")\n",
    "    \n",
    "    if \"onnx_model\" not in conversion_job.outputs:\n",
    "        raise ValueError(\"Conversion job missing 'onnx_model' output\")\n",
    "    \n",
    "    onnx_output = conversion_job.outputs[\"onnx_model\"]\n",
    "    \n",
    "    if hasattr(onnx_output, \"path\"):\n",
    "        return onnx_output.path\n",
    "    elif isinstance(onnx_output, str):\n",
    "        return onnx_output\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected ONNX output type: {type(onnx_output)}\")\n",
    "\n",
    "\n",
    "onnx_model_path = get_onnx_model_path(conversion_completed_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_version(best_config: Dict[str, Any], config_hashes: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Compute deterministic model version from configuration hashes.\n",
    "    \n",
    "    Args:\n",
    "        best_config: Best configuration from HPO selection\n",
    "        config_hashes: Configuration hashes dictionary\n",
    "        \n",
    "    Returns:\n",
    "        str: Model version string\n",
    "    \"\"\"\n",
    "    version_components = [\n",
    "        config_hashes[\"data\"],\n",
    "        config_hashes[\"model\"],\n",
    "        config_hashes[\"train\"],\n",
    "        best_config[\"backbone\"],\n",
    "    ]\n",
    "    version_str = \"_\".join(version_components)\n",
    "    version_hash = hashlib.sha256(version_str.encode()).hexdigest()[:CONFIG_HASH_LENGTH]\n",
    "    return f\"v{version_hash}\"\n",
    "\n",
    "\n",
    "model_version = compute_model_version(best_configuration, config_hashes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_production_model(\n",
    "    ml_client: MLClient,\n",
    "    model_name: str,\n",
    "    model_version: str,\n",
    "    model_path: str,\n",
    "    best_config: Dict[str, Any],\n",
    "    configs: Dict[str, Any],\n",
    "    config_metadata: Dict[str, str],\n",
    ") -> Model:\n",
    "    \"\"\"\n",
    "    Register optimized ONNX model in Azure ML Model Registry.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        model_name: Model name in registry\n",
    "        model_version: Model version\n",
    "        model_path: Path to ONNX model (Azure ML datastore URI)\n",
    "        best_config: Best configuration from HPO selection\n",
    "        configs: Configuration dictionaries\n",
    "        config_metadata: Configuration metadata for tagging\n",
    "        \n",
    "    Returns:\n",
    "        Model: Registered model instance\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If model path is invalid\n",
    "    \"\"\"\n",
    "    if not model_path or not model_path.endswith(\".onnx\"):\n",
    "        raise ValueError(f\"Invalid ONNX model path: {model_path}\")\n",
    "    \n",
    "    selection_criteria = best_config[\"selection_criteria\"]\n",
    "    \n",
    "    model_description = (\n",
    "        f\"Production ONNX model for Resume NER. \"\n",
    "        f\"Backbone: {selection_criteria['backbone']}, \"\n",
    "        f\"Metric: {selection_criteria['metric']}={selection_criteria['best_value']:.4f}\"\n",
    "    )\n",
    "    \n",
    "    model_tags = {\n",
    "        **config_metadata,\n",
    "        \"stage\": PROD_STAGE,\n",
    "        \"backbone\": selection_criteria[\"backbone\"],\n",
    "        \"metric\": selection_criteria[\"metric\"],\n",
    "        \"metric_value\": str(selection_criteria[\"best_value\"]),\n",
    "        \"dataset_version\": best_config[\"dataset_version\"],\n",
    "        \"model_format\": \"onnx\",\n",
    "        \"quantization\": \"int8\",\n",
    "        \"source_training_job\": final_training_completed_job.name,\n",
    "        \"source_conversion_job\": conversion_completed_job.name,\n",
    "    }\n",
    "    \n",
    "    model = Model(\n",
    "        name=model_name,\n",
    "        version=model_version,\n",
    "        description=model_description,\n",
    "        path=model_path,\n",
    "        tags=model_tags,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        existing_model = ml_client.models.get(name=model_name, version=model_version)\n",
    "        return existing_model\n",
    "    except ResourceNotFoundError:\n",
    "        return ml_client.models.create_or_update(model)\n",
    "\n",
    "\n",
    "registered_model = register_production_model(\n",
    "    ml_client=ml_client,\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=model_version,\n",
    "    model_path=onnx_model_path,\n",
    "    best_config=best_configuration,\n",
    "    configs=configs,\n",
    "    config_metadata=config_metadata,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_registered_model(model: Model) -> None:\n",
    "    \"\"\"\n",
    "    Validate registered model has required metadata and tags.\n",
    "    \n",
    "    Args:\n",
    "        model: Registered model instance\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If validation fails\n",
    "    \"\"\"\n",
    "    required_tags = [\"stage\", \"backbone\", \"metric\", \"dataset_version\"]\n",
    "    for tag in required_tags:\n",
    "        if tag not in model.tags:\n",
    "            raise ValueError(f\"Registered model missing required tag: {tag}\")\n",
    "    \n",
    "    if model.tags.get(\"stage\") != PROD_STAGE:\n",
    "        raise ValueError(f\"Model stage must be '{PROD_STAGE}', got: {model.tags.get('stage')}\")\n",
    "    \n",
    "    if not model.path or not model.path.endswith(\".onnx\"):\n",
    "        raise ValueError(f\"Invalid model path: {model.path}\")\n",
    "\n",
    "\n",
    "validate_registered_model(registered_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
