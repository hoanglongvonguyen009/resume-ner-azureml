{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Training Orchestration\n",
    "\n",
    "This notebook orchestrates all training activities without performing local computation.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Step 1**: Load Centralized Configs\n",
    "- **Step 2**: Data Ingestion & Versioning (Asset Layer)\n",
    "- **Step 3**: Environment Definition\n",
    "- **Step 4**: The Dry Run\n",
    "- **Step 5**: The Sweep (HPO)\n",
    "- **Step 6**: Best Configuration Selection (Automated)\n",
    "- **Step 7**: Final Training (Post-HPO, Single Run)\n",
    "\n",
    "## Important\n",
    "\n",
    "- This notebook **only submits and monitors Azure ML jobs**\n",
    "- **No training logic** is executed locally\n",
    "- All computation happens remotely on Azure ML compute\n",
    "- The notebook must be **re-runnable end-to-end**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.1: Load Centralized Configs\n",
    "\n",
    "Load and validate all configuration files. Configs are immutable and will be logged with each job for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml-mlflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Ensure we can import the orchestration package from src/\n",
    "import sys\n",
    "sys.path.append(str((Path(\"..\") / \"src\").resolve()))\n",
    "\n",
    "from shared.yaml_utils import load_yaml\n",
    "from orchestration import (\n",
    "    STAGE_SMOKE,\n",
    "    STAGE_HPO,\n",
    "    STAGE_TRAINING,\n",
    "    EXPERIMENT_NAME,\n",
    "    MODEL_NAME,\n",
    "    PROD_STAGE,\n",
    "    CONVERSION_JOB_NAME,\n",
    "    build_aml_experiment_name,\n",
    ")\n",
    "from orchestration.config_loader import (\n",
    "    ExperimentConfig,\n",
    "    create_config_metadata,\n",
    "    load_all_configs,\n",
    "    load_experiment_config,\n",
    "    compute_config_hashes,\n",
    "    snapshot_configs,\n",
    "    validate_config_immutability,\n",
    ")\n",
    "\n",
    "\n",
    "env_path = Path(\"../config.env\")\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DIR = Path(\"../config\")\n",
    "\n",
    "# Experiment selection (switch to try different data/model/HPO/env combos)\n",
    "# The concrete experiment definition lives in config/experiment/<EXPERIMENT_NAME>.yaml\n",
    "\n",
    "# Resolve experiment-level config into concrete file paths\n",
    "experiment_config: ExperimentConfig = load_experiment_config(CONFIG_DIR, EXPERIMENT_NAME)\n",
    "configs = load_all_configs(experiment_config)\n",
    "config_hashes = compute_config_hashes(configs)\n",
    "\n",
    "# Immutable snapshots for runtime mutation checks\n",
    "original_configs = snapshot_configs(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse shared immutability validator from orchestration package\n",
    "validate_config_immutability(configs, original_configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "def get_workspace_name() -> str:\n",
    "    \"\"\"Get workspace name from configuration files.\n",
    "\n",
    "    Order of precedence:\n",
    "    1. ``config/infrastructure.yaml`` (``workspace.name``)\n",
    "    2. ``config/env/azure.yaml`` (``workspace.name`` under ``env`` config)\n",
    "    \"\"\"\n",
    "    infrastructure_config_path = Path(\"../config/infrastructure.yaml\")\n",
    "    if infrastructure_config_path.exists():\n",
    "        infrastructure_config = load_yaml(infrastructure_config_path)\n",
    "        return infrastructure_config[\"workspace\"][\"name\"]\n",
    "\n",
    "    env_workspace = configs[\"env\"].get(\"workspace\", {}).get(\"name\")\n",
    "    if env_workspace:\n",
    "        return env_workspace\n",
    "\n",
    "    raise ValueError(\n",
    "        \"Workspace name must be configured in either \"\n",
    "        \"config/infrastructure.yaml (workspace.name) or config/env/azure.yaml (workspace.name).\"\n",
    "    )\n",
    "\n",
    "\n",
    "subscription_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"AZURE_RESOURCE_GROUP\")\n",
    "\n",
    "if not subscription_id or not resource_group:\n",
    "    raise ValueError(\"AZURE_SUBSCRIPTION_ID and AZURE_RESOURCE_GROUP must be set\")\n",
    "\n",
    "workspace_name = get_workspace_name()\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All configs and their hashes will be attached to each Azure ML job for full reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build config metadata for job tagging using shared helper from\n",
    "# `orchestration.config_loader`.\n",
    "config_metadata = create_config_metadata(configs, config_hashes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.2: Data Ingestion & Versioning (Asset Layer)\n",
    "\n",
    "Upload dataset to Blob Storage and register as an Azure ML Data Asset for versioned, immutable data access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.data_assets import (\n",
    "    resolve_dataset_path,\n",
    "    register_data_asset,\n",
    "    ensure_data_asset_uploaded,\n",
    "    build_data_asset_reference,\n",
    ")\n",
    "\n",
    "# Resolve local dataset path from data config (configs[\"data\"][\"local_path\"])\n",
    "DATASET_LOCAL_PATH = resolve_dataset_path(configs[\"data\"])\n",
    "DATA_ASSET_NAME = configs[\"data\"][\"name\"]\n",
    "DATA_ASSET_VERSION = configs[\"data\"][\"version\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ASSET_OVERRIDE_PATH = None\n",
    "blob_uri = DATA_ASSET_OVERRIDE_PATH or str(DATASET_LOCAL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asset = register_data_asset(\n",
    "    ml_client=ml_client,\n",
    "    name=DATA_ASSET_NAME,\n",
    "    version=DATA_ASSET_VERSION,\n",
    "    uri=blob_uri,\n",
    "    description=configs[\"data\"][\"description\"],\n",
    ")\n",
    "\n",
    "# Best-effort upload of local content to the resolved data asset\n",
    "data_asset = ensure_data_asset_uploaded(\n",
    "    ml_client=ml_client,\n",
    "    data_asset=data_asset,\n",
    "    local_path=DATASET_LOCAL_PATH,\n",
    "    description=configs[\"data\"][\"description\"],\n",
    ")\n",
    "\n",
    "# Build shared references for downstream jobs\n",
    "asset_paths = build_data_asset_reference(ml_client, data_asset)\n",
    "asset_reference = asset_paths[\"asset_uri\"]\n",
    "datastore_path = asset_paths[\"datastore_path\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "\n",
    "If you encounter `ScriptExecution.StreamAccess.NotFound`, verify that:\n",
    "1. Compute cluster has managed identity assigned\n",
    "2. Managed identity has \"Storage Blob Data Reader\" role on storage account\n",
    "3. Storage account firewall allows Azure services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data asset to save\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save data asset info to a JSON file\n",
    "data_asset_cache_file = Path(\"data_asset_cache.json\")\n",
    "\n",
    "if 'data_asset' in globals() and data_asset is not None:\n",
    "    data_asset_info = {\n",
    "        \"name\": data_asset.name,\n",
    "        \"version\": data_asset.version,\n",
    "    }\n",
    "    \n",
    "    # Optionally save asset_paths if they're used directly\n",
    "    if 'asset_paths' in globals():\n",
    "        data_asset_info[\"asset_paths\"] = asset_paths\n",
    "    \n",
    "    with open(data_asset_cache_file, \"w\") as f:\n",
    "        json.dump(data_asset_info, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved data asset: {data_asset_info['name']} v{data_asset_info['version']} to {data_asset_cache_file}\")\n",
    "else:\n",
    "    print(\"No data asset to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data asset: resume-ner-data-tiny-short vv2.1\n",
      "Asset URI: azureml:resume-ner-data-tiny-short:v2.1\n",
      "Skipping data asset registration - using cached asset\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from orchestration.data_assets import build_data_asset_reference\n",
    "\n",
    "# Try to reload from cache\n",
    "data_asset_cache_file = Path(\"data_asset_cache.json\")\n",
    "\n",
    "if data_asset_cache_file.exists():\n",
    "    with open(data_asset_cache_file, \"r\") as f:\n",
    "        data_asset_info = json.load(f)\n",
    "    \n",
    "    try:\n",
    "        # Reload Data asset object from ML client\n",
    "        data_asset = ml_client.data.get(\n",
    "            name=data_asset_info[\"name\"],\n",
    "            version=data_asset_info[\"version\"]\n",
    "        )\n",
    "        \n",
    "        # Rebuild asset_paths if they were saved, otherwise regenerate them\n",
    "        if \"asset_paths\" in data_asset_info:\n",
    "            asset_paths = data_asset_info[\"asset_paths\"]\n",
    "        else:\n",
    "            asset_paths = build_data_asset_reference(ml_client, data_asset)\n",
    "        \n",
    "        asset_reference = asset_paths[\"asset_uri\"]\n",
    "        datastore_path = asset_paths[\"datastore_path\"]\n",
    "        \n",
    "        print(f\"Loaded data asset: {data_asset.name} v{data_asset.version}\")\n",
    "        print(f\"Asset URI: {asset_reference}\")\n",
    "        print(\"Skipping data asset registration - using cached asset\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load data asset {data_asset_info['name']} v{data_asset_info['version']}: {e}\")\n",
    "        print(\"Will need to register data asset again\")\n",
    "        data_asset = None\n",
    "else:\n",
    "    print(f\"Cache file {data_asset_cache_file} not found. Will need to register data asset.\")\n",
    "    data_asset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.3: Environment Definition\n",
    "\n",
    "Define a stable execution environment (Docker image + Conda dependencies) for consistent behavior across all training jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "\u001b[32mUploading src (0.18 MBs): 100%|██████████| 180303/180303 [00:03<00:00, 50526.37it/s]\n",
      "\u001b[39m\n",
      "\n",
      "/usr/local/python/current/lib/python3.12/site-packages/mlflow/__init__.py:41: UserWarning: Versions of mlflow (3.7.0) and child packages mlflow-skinny (3.5.0) are different. This may lead to unexpected behavior. Please install the same version of all MLflow packages.\n",
      "  mlflow.mismatch._check_version_mismatch()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: amiable_bell_4ml6bncptc\n",
      "Web View: https://ml.azure.com/runs/amiable_bell_4ml6bncptc?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "======Starting Image Build on Compute======\n",
      "The run ID for the image build on compute is imgbldrun_2f8c468\n",
      "Additional logs for the run: https://ml.azure.com/experiments/id/prepare_image/runs/imgbldrun_2f8c468?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f\n",
      "2025-12-17T22:04:35: Logging into Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-17T22:04:35: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "\n",
      "2025-12-17T22:04:35: Login Succeeded\n",
      "2025-12-17T22:04:35: WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "2025-12-17T22:04:35: Configure a credential helper to remove this warning. See\n",
      "2025-12-17T22:04:35: https://docs.docker.com/go/credential-store/\n",
      "\n",
      "\n",
      "\n",
      "2025-12-17T22:04:35: Running: ['docker', 'build', '-f', 'azureml-environment-setup/Dockerfile', '.', '-t', 'b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_ce68dc37400cee2fcde731c88b0a5cef', '-t', 'b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_ce68dc37400cee2fcde731c88b0a5cef:1']\n",
      "2025-12-17T22:04:35: #0 building with \"default\" instance using docker driver\n",
      "\n",
      "2025-12-17T22:04:35: #1 [internal] load build definition from Dockerfile\n",
      "2025-12-17T22:04:35: #1 transferring dockerfile: 1.68kB done\n",
      "2025-12-17T22:04:35: #1 DONE 0.1s\n",
      "\n",
      "2025-12-17T22:04:35: #2 [internal] load .dockerignore\n",
      "2025-12-17T22:04:35: #2 transferring context: 2B done\n",
      "2025-12-17T22:04:35: #2 DONE 0.1s\n",
      "\n",
      "2025-12-17T22:04:35: #3 [internal] load metadata for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33\n",
      "2025-12-17T22:04:35: #3 DONE 0.4s\n",
      "\n",
      "2025-12-17T22:04:36: #4 [internal] load build context\n",
      "2025-12-17T22:04:36: #4 transferring context: 1.77kB done\n",
      "2025-12-17T22:04:36: #4 DONE 0.1s\n",
      "\n",
      "2025-12-17T22:04:36: #5 [ 1/10] FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33\n",
      "2025-12-17T22:04:36: #5 resolve mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest@sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33 0.0s done\n",
      "2025-12-17T22:04:36: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 4.19MB / 28.58MB 0.2s\n",
      "2025-12-17T22:04:36: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 0B / 153.10MB 0.2s\n",
      "2025-12-17T22:04:36: #5 sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572 641.60kB / 641.60kB 0.1s done\n",
      "2025-12-17T22:04:36: #5 sha256:74a79815972fc52df633e894463c51ba80b178d039a7fc50c2072930b298fc33 2.43kB / 2.43kB done\n",
      "2025-12-17T22:04:36: #5 sha256:83631454f85b20f6f2f386c8f58cd8ec885a6b678fcbab1c9a21e1c9ceab4493 9.06kB / 9.06kB done\n",
      "2025-12-17T22:04:36: #5 sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 0B / 3.61MB 0.2s\n",
      "2025-12-17T22:04:36: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 16.78MB / 28.58MB 0.4s\n",
      "2025-12-17T22:04:36: #5 sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 3.61MB / 3.61MB 0.3s done\n",
      "2025-12-17T22:04:36: #5 sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 0B / 169B 0.4s\n",
      "2025-12-17T22:04:36: #5 sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 169B / 169B 0.7s done\n",
      "2025-12-17T22:04:36: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 0B / 127.20MB 0.8s\n",
      "2025-12-17T22:04:37: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 8.39MB / 127.20MB 1.0s\n",
      "2025-12-17T22:04:37: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 20.97MB / 28.58MB 1.4s\n",
      "2025-12-17T22:04:37: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 44.38MB / 153.10MB 1.4s\n",
      "2025-12-17T22:04:37: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 28.58MB / 28.58MB 1.6s\n",
      "2025-12-17T22:04:37: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 83.77MB / 153.10MB 1.6s\n",
      "2025-12-17T22:04:37: #5 sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 28.58MB / 28.58MB 1.7s done\n",
      "2025-12-17T22:04:37: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 123.73MB / 153.10MB 1.8s\n",
      "2025-12-17T22:04:37: #5 sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 0B / 4.17MB 1.8s\n",
      "2025-12-17T22:04:37: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 139.46MB / 153.10MB 1.9s\n",
      "2025-12-17T22:04:37: #5 extracting sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1\n",
      "2025-12-17T22:04:38: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 153.10MB / 153.10MB 2.0s\n",
      "2025-12-17T22:04:38: #5 sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 4.17MB / 4.17MB 1.9s done\n",
      "2025-12-17T22:04:38: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 0B / 41.39MB 2.0s\n",
      "2025-12-17T22:04:38: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 17.41MB / 41.39MB 2.2s\n",
      "2025-12-17T22:04:38: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 28.31MB / 127.20MB 2.3s\n",
      "2025-12-17T22:04:38: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 34.60MB / 41.39MB 2.3s\n",
      "2025-12-17T22:04:38: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 44.04MB / 127.20MB 2.4s\n",
      "2025-12-17T22:04:38: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 41.39MB / 41.39MB 2.4s\n",
      "2025-12-17T22:04:38: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 58.72MB / 127.20MB 2.5s\n",
      "2025-12-17T22:04:39: #5 extracting sha256:86e5016c269355b382c9cabab4f6646d56d75914f20d545289970436dae431b1 1.2s done\n",
      "2025-12-17T22:04:39: #5 sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 153.10MB / 153.10MB 3.1s done\n",
      "2025-12-17T22:04:39: #5 sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 41.39MB / 41.39MB 3.5s done\n",
      "2025-12-17T22:04:39: #5 sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 0B / 197.03kB 3.6s\n",
      "2025-12-17T22:04:39: #5 sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 0B / 5.71MB 3.6s\n",
      "2025-12-17T22:04:39: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 68.16MB / 127.20MB 3.7s\n",
      "2025-12-17T22:04:39: #5 sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 197.03kB / 197.03kB 3.7s done\n",
      "2025-12-17T22:04:39: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040\n",
      "2025-12-17T22:04:39: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 75.50MB / 127.20MB 3.8s\n",
      "2025-12-17T22:04:39: #5 sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 5.71MB / 5.71MB 3.7s done\n",
      "2025-12-17T22:04:41: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 83.89MB / 127.20MB 5.0s\n",
      "2025-12-17T22:04:42: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 91.23MB / 127.20MB 6.2s\n",
      "2025-12-17T22:04:42: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 118.49MB / 127.20MB 6.4s\n",
      "2025-12-17T22:04:42: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 127.20MB / 127.20MB 6.5s\n",
      "2025-12-17T22:04:43: #5 sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 127.20MB / 127.20MB 7.4s done\n",
      "2025-12-17T22:04:44: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 5.2s\n",
      "2025-12-17T22:04:45: #5 extracting sha256:99c5fd780954ce0866e78df451610f0560c1cdd29a31bec3a08a582f04ec1040 5.6s done\n",
      "2025-12-17T22:04:49: #5 extracting sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572\n",
      "2025-12-17T22:04:49: #5 extracting sha256:d50911151bde613fb7f76aa73ef46474769b058516a0896c8852650d84bc7572 0.0s done\n",
      "2025-12-17T22:04:49: #5 extracting sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 0.1s\n",
      "2025-12-17T22:04:49: #5 extracting sha256:05ced3eb3eecdac63a4d976b17bfd190945ab4b0740d5fe291f3c32d66d70b94 0.5s done\n",
      "2025-12-17T22:04:49: #5 extracting sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26\n",
      "2025-12-17T22:04:50: #5 extracting sha256:c67ddbb880dbb982213e1351b9422b59c183c944ee6c67fd9bc08205a6213a26 done\n",
      "2025-12-17T22:04:50: #5 extracting sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 0.1s\n",
      "2025-12-17T22:04:53: #5 extracting sha256:af53440902ce4cda9e38b513196b6c9ad47b18a94a8e0bc2e2bb8856bf6c4ad9 3.8s done\n",
      "2025-12-17T22:04:56: #5 extracting sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725\n",
      "2025-12-17T22:04:56: #5 extracting sha256:552662b21dba1dad9f4d88b4569d25dc7b542d674bde34cfcdda4a8c8cf01725 0.2s done\n",
      "2025-12-17T22:04:56: #5 extracting sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310\n",
      "2025-12-17T22:04:57: #5 extracting sha256:094e2aa4a333d5520507638d0c526be17800af5c2b015b8d0979cb976afa8310 0.5s done\n",
      "2025-12-17T22:04:58: #5 extracting sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba\n",
      "2025-12-17T22:04:58: #5 extracting sha256:9de5bb6930297a574d053f55b1081b4115c0f7cb9d246b3fa9dbef7cc2a5afba 0.0s done\n",
      "2025-12-17T22:04:58: #5 extracting sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3\n",
      "2025-12-17T22:04:58: #5 extracting sha256:695bd62f9bb8076efb8271acdcc66ecdb542475c0147c6adef4d240ccc644af3 0.0s done\n",
      "2025-12-17T22:04:58: #5 DONE 22.6s\n",
      "\n",
      "2025-12-17T22:04:58: #6 [ 2/10] RUN mkdir -p $HOME/.cache\n",
      "2025-12-17T22:04:58: #6 DONE 0.2s\n",
      "\n",
      "2025-12-17T22:04:58: #7 [ 3/10] COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      "2025-12-17T22:04:58: #7 DONE 0.1s\n",
      "\n",
      "2025-12-17T22:04:59: #8 [ 4/10] RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      "2025-12-17T22:05:00: #8 DONE 1.8s\n",
      "\n",
      "2025-12-17T22:05:00: #9 [ 5/10] COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      "2025-12-17T22:05:00: #9 DONE 0.1s\n",
      "\n",
      "2025-12-17T22:05:00: #10 [ 6/10] RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_f71dcdfa6b5c19f689c94e1aa90f3685 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      "2025-12-17T22:05:02: #10 0.597 Retrieving notices: done\n",
      "2025-12-17T22:05:02: #10 1.825 Channels:\n",
      "2025-12-17T22:05:02: #10 1.825  - pytorch\n",
      "2025-12-17T22:05:02: #10 1.825  - conda-forge\n",
      "2025-12-17T22:05:02: #10 1.825  - defaults\n",
      "2025-12-17T22:05:02: #10 1.825 Platform: linux-64\n",
      "2025-12-17T22:05:17: #10 1.825 Collecting package metadata (repodata.json): ...working... done\n",
      "2025-12-17T22:05:23: #10 16.50 Solving environment: ...working... done\n",
      "2025-12-17T22:05:23: #10 22.32 \n",
      "2025-12-17T22:05:23: #10 22.32 \n",
      "2025-12-17T22:05:23: #10 22.32 ==> WARNING: A newer version of conda exists. <==\n",
      "2025-12-17T22:05:23: #10 22.32     current version: 25.1.1\n",
      "2025-12-17T22:05:23: #10 22.32     latest version: 25.11.1\n",
      "2025-12-17T22:05:23: #10 22.32 \n",
      "2025-12-17T22:05:23: #10 22.32 Please update conda by running\n",
      "2025-12-17T22:05:23: #10 22.32 \n",
      "2025-12-17T22:05:23: #10 22.32     $ conda update -n base -c conda-forge conda\n",
      "2025-12-17T22:05:23: #10 22.32 \n",
      "2025-12-17T22:05:23: #10 22.32 \n",
      "2025-12-17T22:05:23: #10 22.41 \n",
      "2025-12-17T22:05:23: mkl-2025.3.0         | 119.4 MB  |            |   0% \n",
      "2025-12-17T22:05:23: libtorch-2.9.1       | 57.9 MB   |            |   0% \u001b[A\n",
      "2025-12-17T22:05:23: #10 22.41 \n",
      "2025-12-17T22:05:23: python-3.10.19       | 24.1 MB   |            |   0% \u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: pytorch-2.9.1        | 20.4 MB   |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: numpy-2.2.6          | 7.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: llvm-openmp-21.1.8   | 5.8 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: libstdcxx-15.2.0     | 5.6 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: libprotobuf-6.31.1   | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: sympy-1.14.0         | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: #10 22.42 \n",
      "2025-12-17T22:05:23: tk-8.6.13            | 3.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: openssl-3.6.0        | 3.0 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: libhwloc-2.12.1      | 2.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: sleef-3.9.0          | 1.9 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: libabseil-20250512.1 | 1.2 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: networkx-3.4.2       | 1.2 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: pip-25.3             | 1.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: libgcc-15.2.0        | 1018 KB   |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: libsqlite-3.51.1     | 917 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: libuv-1.51.0         | 874 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23: #10 22.43 \n",
      "2025-12-17T22:05:23:  ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: mkl-2025.3.0         | 119.4 MB  |            |   0% \n",
      "2025-12-17T22:05:23: #10 22.52 \n",
      "2025-12-17T22:05:23: #10 22.52 \n",
      "2025-12-17T22:05:23: pytorch-2.9.1        | 20.4 MB   | 3          |   4% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.52 \n",
      "2025-12-17T22:05:23: python-3.10.19       | 24.1 MB   | 6          |   7% \u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.52 \n",
      "2025-12-17T22:05:23: #10 22.52 \n",
      "2025-12-17T22:05:23: #10 22.52 \n",
      "2025-12-17T22:05:23: numpy-2.2.6          | 7.5 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: mkl-2025.3.0         | 119.4 MB  | 2          |   2% \n",
      "2025-12-17T22:05:23: #10 22.62 \n",
      "2025-12-17T22:05:23: #10 22.62 \n",
      "2025-12-17T22:05:23: pytorch-2.9.1        | 20.4 MB   | #9         |  19% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.62 \n",
      "2025-12-17T22:05:23: python-3.10.19       | 24.1 MB   | #9         |  20% \u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.62 \n",
      "2025-12-17T22:05:23: #10 22.62 \n",
      "2025-12-17T22:05:23: #10 22.62 \n",
      "2025-12-17T22:05:23: numpy-2.2.6          | 7.5 MB    | ####       |  41% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: mkl-2025.3.0         | 119.4 MB  | 5          |   5% \n",
      "2025-12-17T22:05:23: #10 22.72 \n",
      "2025-12-17T22:05:23: #10 22.72 \n",
      "2025-12-17T22:05:23: pytorch-2.9.1        | 20.4 MB   | ###4       |  35% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.72 \n",
      "2025-12-17T22:05:23: python-3.10.19       | 24.1 MB   | ###2       |  32% \u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.72 \n",
      "2025-12-17T22:05:23: #10 22.72 \n",
      "2025-12-17T22:05:23: #10 22.72 \n",
      "2025-12-17T22:05:23: numpy-2.2.6          | 7.5 MB    | #######9   |  80% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: mkl-2025.3.0         | 119.4 MB  | 7          |   8% \n",
      "2025-12-17T22:05:23: #10 22.82 \n",
      "2025-12-17T22:05:23: #10 22.82 \n",
      "2025-12-17T22:05:23: pytorch-2.9.1        | 20.4 MB   | #####1     |  52% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.82 \n",
      "2025-12-17T22:05:23: python-3.10.19       | 24.1 MB   | ####5      |  46% \u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: mkl-2025.3.0         | 119.4 MB  | #          |  11% \n",
      "2025-12-17T22:05:23: #10 22.92 \n",
      "2025-12-17T22:05:23: #10 22.92 \n",
      "2025-12-17T22:05:23: pytorch-2.9.1        | 20.4 MB   | ######9    |  70% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.92 \n",
      "2025-12-17T22:05:23: python-3.10.19       | 24.1 MB   | ######     |  60% \u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 22.96 \n",
      "2025-12-17T22:05:23: #10 22.96 \n",
      "2025-12-17T22:05:23: #10 22.96 \n",
      "2025-12-17T22:05:23: numpy-2.2.6          | 7.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 23.00 \n",
      "2025-12-17T22:05:23: #10 23.00 \n",
      "2025-12-17T22:05:23: #10 23.00 \n",
      "2025-12-17T22:05:23: #10 23.00 \n",
      "2025-12-17T22:05:23: llvm-openmp-21.1.8   | 5.8 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: #10 23.02 \n",
      "2025-12-17T22:05:23: mkl-2025.3.0         | 119.4 MB  | #3         |  13% \n",
      "2025-12-17T22:05:23: #10 23.03 \n",
      "2025-12-17T22:05:23: #10 23.03 \n",
      "2025-12-17T22:05:23: pytorch-2.9.1        | 20.4 MB   | ########5  |  86% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:23: libtorch-2.9.1       | 57.9 MB   | ###2       |  32% \u001b[A\n",
      "2025-12-17T22:05:23: #10 23.10 \n",
      "2025-12-17T22:05:23: #10 23.10 \n",
      "2025-12-17T22:05:23: #10 23.10 \n",
      "2025-12-17T22:05:23: #10 23.10 \n",
      "2025-12-17T22:05:24: mkl-2025.3.0         | 119.4 MB  | #5         |  16% \n",
      "2025-12-17T22:05:24: #10 23.14 \n",
      "2025-12-17T22:05:24: python-3.10.19       | 24.1 MB   | ########6  |  86% \u001b[A\u001b[A\n",
      "2025-12-17T22:05:24: libtorch-2.9.1       | 57.9 MB   | ###7       |  37% \u001b[A\n",
      "2025-12-17T22:05:24: #10 23.20 \n",
      "2025-12-17T22:05:24: #10 23.20 \n",
      "2025-12-17T22:05:24: #10 23.20 \n",
      "2025-12-17T22:05:24: #10 23.20 \n",
      "2025-12-17T22:05:24: mkl-2025.3.0         | 119.4 MB  | #8         |  19% \n",
      "2025-12-17T22:05:24: #10 23.24 \n",
      "2025-12-17T22:05:24: python-3.10.19       | 24.1 MB   | #########8 |  98% \u001b[A\u001b[A\n",
      "2025-12-17T22:05:24: mkl-2025.3.0         | 119.4 MB  | ##1        |  22% \n",
      "2025-12-17T22:05:24: libtorch-2.9.1       | 57.9 MB   | ####9      |  50% \u001b[A\n",
      "2025-12-17T22:05:24: #10 23.37 \n",
      "2025-12-17T22:05:24: #10 23.37 \n",
      "2025-12-17T22:05:24: #10 23.37 \n",
      "2025-12-17T22:05:24: #10 23.37 \n",
      "2025-12-17T22:05:24: llvm-openmp-21.1.8   | 5.8 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:24: #10 23.41 \n",
      "2025-12-17T22:05:24: #10 23.41 \n",
      "2025-12-17T22:05:24: #10 23.41 \n",
      "2025-12-17T22:05:24: #10 23.41 \n",
      "2025-12-17T22:05:24: #10 23.41 \n",
      "2025-12-17T22:05:24: mkl-2025.3.0         | 119.4 MB  | ##4        |  24% \n",
      "2025-12-17T22:05:24: libtorch-2.9.1       | 57.9 MB   | #####5     |  55% \u001b[A\n",
      "2025-12-17T22:05:24: #10 23.51 \n",
      "2025-12-17T22:05:24: #10 23.51 \n",
      "2025-12-17T22:05:24: #10 23.51 \n",
      "2025-12-17T22:05:24: #10 23.51 \n",
      "2025-12-17T22:05:24: #10 23.51 \n",
      "2025-12-17T22:05:24: mkl-2025.3.0         | 119.4 MB  | ##7        |  27% \n",
      "2025-12-17T22:05:24: mkl-2025.3.0         | 119.4 MB  | ###        |  30% \n",
      "2025-12-17T22:05:24: mkl-2025.3.0         | 119.4 MB  | ###2       |  33% \n",
      "2025-12-17T22:05:24: #10 23.76 \n",
      "2025-12-17T22:05:24: #10 23.76 \n",
      "2025-12-17T22:05:24: #10 23.76 \n",
      "2025-12-17T22:05:24: #10 23.76 \n",
      "2025-12-17T22:05:24: #10 23.76 \n",
      "2025-12-17T22:05:24: libstdcxx-15.2.0     | 5.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:24: #10 23.76 \n",
      "2025-12-17T22:05:24: #10 23.76 \n",
      "2025-12-17T22:05:24: #10 23.76 \n",
      "2025-12-17T22:05:24: #10 23.76 \n",
      "2025-12-17T22:05:24: #10 23.76 \n",
      "2025-12-17T22:05:24: libstdcxx-15.2.0     | 5.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:24: libtorch-2.9.1       | 57.9 MB   | #######2   |  73% \u001b[A\n",
      "2025-12-17T22:05:24: #10 23.78 \n",
      "2025-12-17T22:05:24: #10 23.78 \n",
      "2025-12-17T22:05:24: pytorch-2.9.1        | 20.4 MB   | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:24: #10 23.79 \n",
      "2025-12-17T22:05:24: #10 23.79 \n",
      "2025-12-17T22:05:24: #10 23.79 \n",
      "2025-12-17T22:05:24: #10 23.79 \n",
      "2025-12-17T22:05:24: #10 23.79 \n",
      "2025-12-17T22:05:24: #10 23.79 \n",
      "2025-12-17T22:05:24: libprotobuf-6.31.1   | 4.4 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:24: #10 23.82 \n",
      "2025-12-17T22:05:24: #10 23.82 \n",
      "2025-12-17T22:05:24: #10 23.82 \n",
      "2025-12-17T22:05:24: #10 23.82 \n",
      "2025-12-17T22:05:24: #10 23.82 \n",
      "2025-12-17T22:05:24: #10 23.82 \n",
      "2025-12-17T22:05:24: #10 23.82 \n",
      "2025-12-17T22:05:24: mkl-2025.3.0         | 119.4 MB  | ###5       |  36% \n",
      "2025-12-17T22:05:24: libtorch-2.9.1       | 57.9 MB   | #######8   |  78% \u001b[A\n",
      "2025-12-17T22:05:24: #10 23.89 \n",
      "2025-12-17T22:05:24: #10 23.89 \n",
      "2025-12-17T22:05:24: #10 23.89 \n",
      "2025-12-17T22:05:24: #10 23.89 \n",
      "2025-12-17T22:05:24: #10 23.89 \n",
      "2025-12-17T22:05:24: #10 23.89 \n",
      "2025-12-17T22:05:24: libprotobuf-6.31.1   | 4.4 MB    | ######8    |  68% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:24: #10 23.92 \n",
      "2025-12-17T22:05:24: #10 23.92 \n",
      "2025-12-17T22:05:24: #10 23.92 \n",
      "2025-12-17T22:05:24: #10 23.92 \n",
      "2025-12-17T22:05:24: #10 23.92 \n",
      "2025-12-17T22:05:24: #10 23.92 \n",
      "2025-12-17T22:05:24: #10 23.92 \n",
      "2025-12-17T22:05:24: mkl-2025.3.0         | 119.4 MB  | ###8       |  38% \n",
      "2025-12-17T22:05:24: libtorch-2.9.1       | 57.9 MB   | ########3  |  84% \u001b[A\n",
      "2025-12-17T22:05:24: #10 24.07 \n",
      "2025-12-17T22:05:25: mkl-2025.3.0         | 119.4 MB  | ####       |  41% \n",
      "2025-12-17T22:05:25: #10 24.10 \n",
      "2025-12-17T22:05:25: #10 24.10 \n",
      "2025-12-17T22:05:25: #10 24.10 \n",
      "2025-12-17T22:05:25: #10 24.10 \n",
      "2025-12-17T22:05:25: #10 24.10 \n",
      "2025-12-17T22:05:25: #10 24.10 \n",
      "2025-12-17T22:05:25: #10 24.10 \n",
      "2025-12-17T22:05:25: #10 24.10 \n",
      "2025-12-17T22:05:25: tk-8.6.13            | 3.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: libtorch-2.9.1       | 57.9 MB   | ########8  |  89% \u001b[A\n",
      "2025-12-17T22:05:25: #10 24.12 \n",
      "2025-12-17T22:05:25: #10 24.12 \n",
      "2025-12-17T22:05:25: #10 24.12 \n",
      "2025-12-17T22:05:25: #10 24.12 \n",
      "2025-12-17T22:05:25: #10 24.12 \n",
      "2025-12-17T22:05:25: #10 24.12 \n",
      "2025-12-17T22:05:25: libprotobuf-6.31.1   | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.15 \n",
      "2025-12-17T22:05:25: #10 24.15 \n",
      "2025-12-17T22:05:25: #10 24.15 \n",
      "2025-12-17T22:05:25: #10 24.15 \n",
      "2025-12-17T22:05:25: llvm-openmp-21.1.8   | 5.8 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: #10 24.16 \n",
      "2025-12-17T22:05:25: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.17 \n",
      "2025-12-17T22:05:25: #10 24.17 \n",
      "2025-12-17T22:05:25: #10 24.17 \n",
      "2025-12-17T22:05:25: #10 24.17 \n",
      "2025-12-17T22:05:25: #10 24.17 \n",
      "2025-12-17T22:05:25: #10 24.17 \n",
      "2025-12-17T22:05:25: #10 24.17 \n",
      "2025-12-17T22:05:25: #10 24.17 \n",
      "2025-12-17T22:05:25: #10 24.17 \n",
      "2025-12-17T22:05:25: openssl-3.6.0        | 3.0 MB    |            |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.20 \n",
      "2025-12-17T22:05:25: #10 24.20 \n",
      "2025-12-17T22:05:25: #10 24.20 \n",
      "2025-12-17T22:05:25: #10 24.20 \n",
      "2025-12-17T22:05:25: #10 24.20 \n",
      "2025-12-17T22:05:25: #10 24.20 \n",
      "2025-12-17T22:05:25: #10 24.20 \n",
      "2025-12-17T22:05:25: #10 24.20 \n",
      "2025-12-17T22:05:25: tk-8.6.13            | 3.1 MB    | #######3   |  74% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.21 \n",
      "2025-12-17T22:05:25: #10 24.21 \n",
      "2025-12-17T22:05:25: #10 24.21 \n",
      "2025-12-17T22:05:25: #10 24.21 \n",
      "2025-12-17T22:05:25: #10 24.21 \n",
      "2025-12-17T22:05:25: #10 24.21 \n",
      "2025-12-17T22:05:25: #10 24.21 \n",
      "2025-12-17T22:05:25: #10 24.21 \n",
      "2025-12-17T22:05:25: #10 24.21 \n",
      "2025-12-17T22:05:25: #10 24.21 \n",
      "2025-12-17T22:05:25: mkl-2025.3.0         | 119.4 MB  | ####3      |  43% \n",
      "2025-12-17T22:05:25: libtorch-2.9.1       | 57.9 MB   | #########3 |  94% \u001b[A\n",
      "2025-12-17T22:05:25: #10 24.27 \n",
      "2025-12-17T22:05:25: #10 24.27 \n",
      "2025-12-17T22:05:25: #10 24.27 \n",
      "2025-12-17T22:05:25: #10 24.27 \n",
      "2025-12-17T22:05:25: #10 24.27 \n",
      "2025-12-17T22:05:25: #10 24.27 \n",
      "2025-12-17T22:05:25: #10 24.27 \n",
      "2025-12-17T22:05:25: #10 24.27 \n",
      "2025-12-17T22:05:25: #10 24.27 \n",
      "2025-12-17T22:05:25: mkl-2025.3.0         | 119.4 MB  | ####5      |  46% \n",
      "2025-12-17T22:05:25: libtorch-2.9.1       | 57.9 MB   | #########8 |  99% \u001b[A\n",
      "2025-12-17T22:05:25: #10 24.37 \n",
      "2025-12-17T22:05:25: #10 24.37 \n",
      "2025-12-17T22:05:25: #10 24.37 \n",
      "2025-12-17T22:05:25: #10 24.37 \n",
      "2025-12-17T22:05:25: #10 24.37 \n",
      "2025-12-17T22:05:25: #10 24.37 \n",
      "2025-12-17T22:05:25: #10 24.37 \n",
      "2025-12-17T22:05:25: #10 24.37 \n",
      "2025-12-17T22:05:25: tk-8.6.13            | 3.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: sleef-3.9.0          | 1.9 MB    |            |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: #10 24.40 \n",
      "2025-12-17T22:05:25: openssl-3.6.0        | 3.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: #10 24.43 \n",
      "2025-12-17T22:05:25: mkl-2025.3.0         | 119.4 MB  | ####8      |  48% \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: #10 24.45 \n",
      "2025-12-17T22:05:25: networkx-3.4.2       | 1.2 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: #10 24.52 \n",
      "2025-12-17T22:05:25: libabseil-20250512.1 | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: #10 24.53 \n",
      "2025-12-17T22:05:25: mkl-2025.3.0         | 119.4 MB  | #####      |  51% \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: #10 24.56 \n",
      "2025-12-17T22:05:25: pip-25.3             | 1.1 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: #10 24.57 \n",
      "2025-12-17T22:05:25: libsqlite-3.51.1     | 917 KB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: #10 24.58 \n",
      "2025-12-17T22:05:25: libgcc-15.2.0        | 1018 KB   | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: #10 24.64 \n",
      "2025-12-17T22:05:25: mkl-2025.3.0         | 119.4 MB  | #####3     |  53% \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: #10 24.65 \n",
      "2025-12-17T22:05:25: libgcc-15.2.0        | 1018 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.67 \n",
      "2025-12-17T22:05:25: #10 24.67 \n",
      "2025-12-17T22:05:25: #10 24.67 \n",
      "2025-12-17T22:05:25: #10 24.67 \n",
      "2025-12-17T22:05:25: #10 24.67 \n",
      "2025-12-17T22:05:25: libstdcxx-15.2.0     | 5.6 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: #10 24.70 \n",
      "2025-12-17T22:05:25: mkl-2025.3.0         | 119.4 MB  | #####5     |  56% \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: #10 24.75 \n",
      "2025-12-17T22:05:25: mkl-2025.3.0         | 119.4 MB  | ######1    |  62% \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: #10 24.96 \n",
      "2025-12-17T22:05:25: libuv-1.51.0         | 874 KB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:25: #10 25.03 \n",
      "2025-12-17T22:05:27: mkl-2025.3.0         | 119.4 MB  | #########5 |  95% \n",
      "2025-12-17T22:05:27: mkl-2025.3.0         | 119.4 MB  | #########8 |  99% \n",
      "2025-12-17T22:05:27: #10 27.15 \n",
      "2025-12-17T22:05:27: #10 27.15 \n",
      "2025-12-17T22:05:27: #10 27.15 \n",
      "2025-12-17T22:05:28: numpy-2.2.6          | 7.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:28: #10 27.89 \n",
      "2025-12-17T22:05:28: #10 27.89 \n",
      "2025-12-17T22:05:28: #10 27.89 \n",
      "2025-12-17T22:05:28: #10 27.89 \n",
      "2025-12-17T22:05:28: #10 27.89 \n",
      "2025-12-17T22:05:28: #10 27.89 \n",
      "2025-12-17T22:05:29: mkl-2025.3.0         | 119.4 MB  | ########## | 100% \n",
      "2025-12-17T22:05:29: #10 29.06 \n",
      "2025-12-17T22:05:30: python-3.10.19       | 24.1 MB   | ########## | 100% \u001b[A\u001b[A\n",
      "2025-12-17T22:05:30: #10 29.76 \n",
      "2025-12-17T22:05:30: #10 29.76 \n",
      "2025-12-17T22:05:30: #10 29.76 \n",
      "2025-12-17T22:05:30: #10 29.76 \n",
      "2025-12-17T22:05:30: #10 29.76 \n",
      "2025-12-17T22:05:30: #10 29.76 \n",
      "2025-12-17T22:05:30: #10 29.76 \n",
      "2025-12-17T22:05:30: sympy-1.14.0         | 4.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:30: #10 29.77 \n",
      "2025-12-17T22:05:30: #10 29.77 \n",
      "2025-12-17T22:05:30: #10 29.77 \n",
      "2025-12-17T22:05:30: #10 29.77 \n",
      "2025-12-17T22:05:30: #10 29.77 \n",
      "2025-12-17T22:05:30: #10 29.77 \n",
      "2025-12-17T22:05:30: #10 29.77 \n",
      "2025-12-17T22:05:30: #10 29.77 \n",
      "2025-12-17T22:05:30: tk-8.6.13            | 3.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:30: #10 30.15 \n",
      "2025-12-17T22:05:30: #10 30.15 \n",
      "2025-12-17T22:05:30: #10 30.15 \n",
      "2025-12-17T22:05:30: #10 30.15 \n",
      "2025-12-17T22:05:30: #10 30.15 \n",
      "2025-12-17T22:05:30: #10 30.15 \n",
      "2025-12-17T22:05:30: #10 30.15 \n",
      "2025-12-17T22:05:30: #10 30.15 \n",
      "2025-12-17T22:05:30: #10 30.15 \n",
      "2025-12-17T22:05:31: openssl-3.6.0        | 3.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:31: #10 30.34 \n",
      "2025-12-17T22:05:31: #10 30.34 \n",
      "2025-12-17T22:05:31: #10 30.34 \n",
      "2025-12-17T22:05:31: #10 30.34 \n",
      "2025-12-17T22:05:31: #10 30.34 \n",
      "2025-12-17T22:05:31: #10 30.34 \n",
      "2025-12-17T22:05:31: #10 30.34 \n",
      "2025-12-17T22:05:31: #10 30.34 \n",
      "2025-12-17T22:05:31: #10 30.34 \n",
      "2025-12-17T22:05:31: #10 30.34 \n",
      "2025-12-17T22:05:31: libhwloc-2.12.1      | 2.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:31: #10 30.48 \n",
      "2025-12-17T22:05:31: #10 30.48 \n",
      "2025-12-17T22:05:31: #10 30.48 \n",
      "2025-12-17T22:05:31: #10 30.48 \n",
      "2025-12-17T22:05:31: #10 30.48 \n",
      "2025-12-17T22:05:31: #10 30.48 \n",
      "2025-12-17T22:05:31: #10 30.48 \n",
      "2025-12-17T22:05:31: #10 30.48 \n",
      "2025-12-17T22:05:31: #10 30.48 \n",
      "2025-12-17T22:05:31: #10 30.48 \n",
      "2025-12-17T22:05:31: #10 30.48 \n",
      "2025-12-17T22:05:31: sleef-3.9.0          | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: libabseil-20250512.1 | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: #10 30.93 \n",
      "2025-12-17T22:05:31: libabseil-20250512.1 | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: libsqlite-3.51.1     | 917 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: #10 30.99 \n",
      "2025-12-17T22:05:31: libsqlite-3.51.1     | 917 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:31: #10 31.14 \n",
      "2025-12-17T22:05:32: networkx-3.4.2       | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: #10 31.14 \n",
      "2025-12-17T22:05:32: networkx-3.4.2       | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: libgcc-15.2.0        | 1018 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: #10 31.27 \n",
      "2025-12-17T22:05:32: libgcc-15.2.0        | 1018 KB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: #10 31.54 \n",
      "2025-12-17T22:05:32: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:32: #10 31.55 \n",
      "2025-12-17T22:05:33: pip-25.3             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:33: #10 32.23 \n",
      "2025-12-17T22:05:33: #10 32.23 \n",
      "2025-12-17T22:05:33: pytorch-2.9.1        | 20.4 MB   | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: libuv-1.51.0         | 874 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:33: #10 32.45 \n",
      "2025-12-17T22:05:34: libuv-1.51.0         | 874 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:34: #10 34.05 \n",
      "2025-12-17T22:05:35:  ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:35: #10 34.05 \n",
      "2025-12-17T22:05:39: mkl-2025.3.0         | 119.4 MB  | ########## | 100% \n",
      "2025-12-17T22:05:39: libtorch-2.9.1       | 57.9 MB   | ########## | 100% \u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39:                                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: \u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: \u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: \u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: #10 38.38 \n",
      "2025-12-17T22:05:39: \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A done\n",
      "2025-12-17T22:05:39: #10 38.38 Preparing transaction: done\n",
      "2025-12-17T22:05:42: #10 39.14 Verifying transaction: done\n",
      "2025-12-17T22:05:52: #10 41.81 Executing transaction: done\n",
      "2025-12-17T22:07:57: #10 51.56 Installing pip dependencies: - Ran pip subprocess with arguments:\n",
      "2025-12-17T22:07:57: #10 176.5 ['/azureml-envs/azureml_f71dcdfa6b5c19f689c94e1aa90f3685/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.ksctmjkq.requirements.txt', '--exists-action=b']\n",
      "2025-12-17T22:07:57: #10 176.5 Pip subprocess output:\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azureml-defaults (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azureml_defaults-1.61.0-py3-none-any.whl.metadata (914 bytes)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting transformers<5.0.0,>=4.35.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting safetensors>=0.4.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 3))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting datasets>=2.12.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting numpy<2.0,>=1.24.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 5))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pandas>=2.0.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 6))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting scikit-learn>=1.3.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 7))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-ai-ml>=1.0.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_ai_ml-1.30.0-py3-none-any.whl.metadata (40 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-identity>=1.12.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 9))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_identity-1.25.1-py3-none-any.whl.metadata (88 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-storage-blob>=12.17.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 10))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_blob-12.27.1-py3-none-any.whl.metadata (26 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pyyaml>=6.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 11))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting tqdm>=4.65.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 12))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting seqeval>=1.2.2 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 13))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Installing build dependencies: started\n",
      "2025-12-17T22:07:57: #10 176.5   Installing build dependencies: finished with status 'done'\n",
      "2025-12-17T22:07:57: #10 176.5   Getting requirements to build wheel: started\n",
      "2025-12-17T22:07:57: #10 176.5   Getting requirements to build wheel: finished with status 'done'\n",
      "2025-12-17T22:07:57: #10 176.5   Installing backend dependencies: started\n",
      "2025-12-17T22:07:57: #10 176.5   Installing backend dependencies: finished with status 'done'\n",
      "2025-12-17T22:07:57: #10 176.5   Preparing metadata (pyproject.toml): started\n",
      "2025-12-17T22:07:57: #10 176.5   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting sentencepiece>=0.1.99 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 14))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting mlflow (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading mlflow-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azureml-mlflow (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 16))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azureml_mlflow-1.61.0.post1-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting onnxruntime (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 17))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading onnxruntime-1.23.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting onnx>=1.16.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 18))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading onnx-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Requirement already satisfied: filelock in /azureml-envs/azureml_f71dcdfa6b5c19f689c94e1aa90f3685/lib/python3.10/site-packages (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2)) (3.20.1)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting huggingface-hub<1.0,>=0.34.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting packaging>=20.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2))\n",
      "2025-12-17T22:07:57: #10 176.5   Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting requests (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Requirement already satisfied: fsspec>=2023.5.0 in /azureml-envs/azureml_f71dcdfa6b5c19f689c94e1aa90f3685/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2)) (2025.12.0)\n",
      "2025-12-17T22:07:57: #10 176.5 Requirement already satisfied: typing-extensions>=3.7.4.3 in /azureml-envs/azureml_f71dcdfa6b5c19f689c94e1aa90f3685/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2)) (4.15.0)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azureml-inference-server-http~=1.4 (from azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azureml_inference_server_http-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azureml-core~=1.61.0 (from azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azureml_core-1.61.0.post1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azureml-dataset-runtime~=1.61.0 (from azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azureml_dataset_runtime-1.61.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pytz (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting backports.tempfile (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading backports.tempfile-1.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pathspec<1.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting msal<2.0.0,>=1.15.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting msal-extensions<=2.0.0,>=0.3.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting knack<0.13.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading knack-0.12.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-core<2.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_core-1.37.0-py3-none-any.whl.metadata (47 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pkginfo (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pkginfo-1.12.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting argcomplete<4 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading argcomplete-3.6.3-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting humanfriendly<11.0,>=4.7 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting paramiko<4.0.0,>=2.0.8 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-mgmt-resource<=24.0.0,>=15.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_mgmt_resource-24.0.0-py3-none-any.whl.metadata (43 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-mgmt-containerregistry<15,>=8.2.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_mgmt_containerregistry-14.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-mgmt-storage<=24.0.0,>=16.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_mgmt_storage-24.0.0-py3-none-any.whl.metadata (36 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-mgmt-keyvault<12.0.0,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_mgmt_keyvault-11.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-mgmt-authorization<5,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-mgmt-network<=30.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_mgmt_network-30.0.0-py3-none-any.whl.metadata (94 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-graphrbac<1.0.0,>=0.40.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_graphrbac-0.61.2-py2.py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-common<2.0.0,>=1.1.12 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting msrest<=0.7.1,>=0.5.1 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting msrestazure<=0.7,>=0.4.33 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting urllib3<3.0.0,>1.26.17 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting python-dateutil<3.0.0,>=2.7.3 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting ndg-httpsclient<=0.5.1 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading ndg_httpsclient-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting SecretStorage<4.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading secretstorage-3.5.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting jsonpickle<5.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading jsonpickle-4.1.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting contextlib2<22.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting docker<8.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting PyJWT<3.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting adal<=1.2.7,>=1.2.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading adal-1.2.7-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pyopenssl<26.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting jmespath<2.0.0 (from azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting cryptography>=1.1.0 (from adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting isodate<1.0.0,>=0.6.1 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-mgmt-core<2.0.0,>=1.3.2 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_mgmt_core-1.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azureml-dataprep<5.5.0a,>=5.1.0a (from azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azureml_dataprep-5.4.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pyarrow<21.0.0,>=0.17.0 (from azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azureml-dataprep-native<43.0.0,>=42.0.0 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azureml_dataprep_native-42.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azureml-dataprep-rslex~=2.25.1 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azureml_dataprep_rslex-2.25.2-cp310-cp310-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting cloudpickle<3.0.0,>=1.1.0 (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-identity>=1.12.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 9))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_identity-1.17.0-py3-none-any.whl.metadata (79 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting jsonschema (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Requirement already satisfied: pip>=25.3 in /azureml-envs/azureml_f71dcdfa6b5c19f689c94e1aa90f3685/lib/python3.10/site-packages (from azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1)) (25.3)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting fusepy<4.0.0,>=3.0.1 (from azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Installing build dependencies: started\n",
      "2025-12-17T22:07:57: #10 176.5   Installing build dependencies: finished with status 'done'\n",
      "2025-12-17T22:07:57: #10 176.5   Getting requirements to build wheel: started\n",
      "2025-12-17T22:07:57: #10 176.5   Getting requirements to build wheel: finished with status 'done'\n",
      "2025-12-17T22:07:57: #10 176.5   Preparing metadata (pyproject.toml): started\n",
      "2025-12-17T22:07:57: #10 176.5   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting flask~=3.1.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting flask-cors~=6.0.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting gunicorn>=23.0.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting inference-schema~=1.8.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading inference_schema-1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-sdk==1.33.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-api==1.33.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_api-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-semantic-conventions (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry_exporter-1.0.0b46-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pydantic~=2.11.0 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pydantic-settings (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting werkzeug>=3.0.3 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting certifi>=2024.7.4 (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting deprecated>=1.2.6 (from opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-semantic-conventions (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting blinker>=1.9.0 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting click>=8.1.3 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting itsdangerous>=2.2.0 (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Requirement already satisfied: jinja2>=3.1.2 in /azureml-envs/azureml_f71dcdfa6b5c19f689c94e1aa90f3685/lib/python3.10/site-packages (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1)) (3.1.6)\n",
      "2025-12-17T22:07:57: #10 176.5 Requirement already satisfied: markupsafe>=2.1.1 in /azureml-envs/azureml_f71dcdfa6b5c19f689c94e1aa90f3685/lib/python3.10/site-packages (from flask~=3.1.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1)) (3.0.3)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api==1.33.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting wrapt<=1.16.0,>=1.14.0 (from inference-schema~=1.8.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pygments (from knack<0.13.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting tabulate (from knack<0.13.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting cffi>=2.0.0 (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting requests-oauthlib>=0.5.0 (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting six (from msrestazure<=0.7,>=0.4.33->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pyasn1>=0.1.1 (from ndg-httpsclient<=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting bcrypt>=3.2 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pynacl>=1.5 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pynacl-1.6.1-cp38-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting annotated-types>=0.6.0 (from pydantic~=2.11.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pydantic-core==2.33.2 (from pydantic~=2.11.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting typing-inspection>=0.4.0 (from pydantic~=2.11.0->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting charset_normalizer<4,>=2 (from requests->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting idna<4,>=2.5 (from requests->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting jeepney>=0.6 (from SecretStorage<4.0.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading jeepney-0.9.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting datasets>=2.12.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading datasets-4.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading datasets-4.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting xxhash (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting multiprocess<0.70.17 (from datasets>=2.12.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.35.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 2))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting tzdata>=2022.7 (from pandas>=2.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 6))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting scipy>=1.8.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 7))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting joblib>=1.2.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 7))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 7))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting marshmallow<4.0.0,>=3.5 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting strictyaml<2.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting colorama<1.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-storage-file-share (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_file_share-12.23.1-py3-none-any.whl.metadata (52 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_file_datalake-12.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pydash<9.0.0,>=6.0.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pydash-8.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.8.3-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting attrs>=22.2.0 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting referencing>=0.28.4 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting rpds-py>=0.7.1 (from jsonschema->azureml-dataprep<5.5.0a,>=5.1.0a->azureml-dataset-runtime~=1.61.0->azureml-dataset-runtime[fuse]~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting mlflow-skinny==3.7.0 (from mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading mlflow_skinny-3.7.0-py3-none-any.whl.metadata (31 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting mlflow-tracing==3.7.0 (from mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading mlflow_tracing-3.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting alembic!=1.10.0,<2 (from mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting graphene<4 (from mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting huey<3,>=2.5.0 (from mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading huey-2.5.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting matplotlib<4 (from mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting sqlalchemy<3,>=1.4.0 (from mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading sqlalchemy-2.0.45-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading cachetools-6.2.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading databricks_sdk-0.76.0-py3-none-any.whl.metadata (40 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting fastapi<1 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading fastapi-0.125.0-py3-none-any.whl.metadata (30 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading sqlparse-0.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting uvicorn<1 (from mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting Mako (from alembic!=1.10.0,<2->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting tomli (from alembic!=1.10.0,<2->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Using cached tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading google_auth-2.45.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting starlette<0.51.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting cycler>=0.10 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting fonttools>=4.22.0 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting kiwisolver>=1.3.1 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pillow>=8 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pyparsing>=3 (from matplotlib<4->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading greenlet-3.3.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting anyio<5,>=3.6.2 (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==3.7.0->mlflow->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 15))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of azureml-mlflow to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azureml-mlflow (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 16))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azureml_mlflow-1.61.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azureml_mlflow-1.60.0.post1-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azureml_mlflow-1.60.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-storage-blob>=12.17.0 (from -r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 10))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting coloredlogs (from onnxruntime->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 17))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting flatbuffers (from onnxruntime->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 17))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "2025-12-17T22:07:57: #10 176.5 Requirement already satisfied: sympy in /azureml-envs/azureml_f71dcdfa6b5c19f689c94e1aa90f3685/lib/python3.10/site-packages (from onnxruntime->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 17)) (1.14.0)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting ml_dtypes>=0.5.0 (from onnx>=1.16.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 18))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading ml_dtypes-0.5.4-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 4))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of azure-storage-file-datalake to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_file_datalake-12.21.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_file_datalake-12.19.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_file_datalake-12.18.1-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_file_datalake-12.18.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_file_datalake-12.17.0-py3-none-any.whl.metadata (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_file_datalake-12.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is still looking at multiple versions of azure-storage-file-datalake to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_file_datalake-12.15.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_storage_file_datalake-12.14.0-py3-none-any.whl.metadata (15 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting pycparser (from cffi>=2.0.0->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-core-tracing-opentelemetry~=1.0.0b11 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl.metadata (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of azure-monitor-opentelemetry to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.8.2-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.8.1-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.8.0-py3-none-any.whl.metadata (23 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-django~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_django-0.60b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-fastapi~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_fastapi-0.60b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-flask~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_flask-0.60b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-psycopg2~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_psycopg2-0.60b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-requests~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_requests-0.60b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-urllib~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib-0.60b1-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-urllib3~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib3-0.60b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-resource-detector-azure~=0.1.5 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl.metadata (5.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.6.13-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.6.12-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-django<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_django-0.52b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-flask<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_flask-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-psycopg2<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_psycopg2-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-requests<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_requests-0.52b1-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-urllib<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib-0.52b1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-urllib3<0.53b0,>=0.49b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib3-0.52b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-monitor-opentelemetry (from azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.6.11-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is still looking at multiple versions of azure-monitor-opentelemetry to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.6.10-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.6.9-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.6.8-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry-1.6.7-py3-none-any.whl.metadata (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of azure-monitor-opentelemetry-exporter to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry_exporter-1.0.0b45-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry_exporter-1.0.0b44-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting azure-monitor-opentelemetry-exporter (from azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry_exporter-1.0.0b43-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry_exporter-1.0.0b42-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry_exporter-1.0.0b41-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading azure_monitor_opentelemetry_exporter-1.0.0b40-py2.py3-none-any.whl.metadata (33 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting psutil<8,>=5.9 (from azure-monitor-opentelemetry-exporter->azureml-inference-server-http~=1.4->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-wsgi==0.60b1 (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_wsgi-0.60b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation==0.60b1 (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation-0.60b1-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-django to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_django-0.60b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-wsgi==0.60b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_wsgi-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation==0.60b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation-0.60b0-py3-none-any.whl.metadata (7.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_django-0.59b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-wsgi==0.59b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_wsgi-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_django-0.58b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-wsgi==0.58b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_wsgi-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation==0.58b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_django-0.57b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-wsgi==0.57b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_wsgi-0.57b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation==0.57b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_django-0.56b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-wsgi==0.56b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_wsgi-0.56b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation==0.56b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation-0.56b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_django-0.55b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-wsgi==0.55b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_wsgi-0.55b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_django-0.55b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-wsgi==0.55b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_wsgi-0.55b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation==0.55b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation-0.55b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-django to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_django-0.54b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-wsgi==0.54b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_wsgi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-django~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_django-0.54b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-wsgi==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_wsgi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-util-http==0.54b0 (from opentelemetry-instrumentation-django~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-asgi==0.60b1 (from opentelemetry-instrumentation-fastapi~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_asgi-0.60b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_fastapi-0.60b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-asgi==0.60b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_asgi-0.60b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_fastapi-0.59b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-asgi==0.59b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_asgi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_fastapi-0.58b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-asgi==0.58b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_asgi-0.58b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_fastapi-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-asgi==0.57b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_asgi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_fastapi-0.56b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-asgi==0.56b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_asgi-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_fastapi-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-asgi==0.55b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_asgi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-fastapi~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-asgi==0.54b0 (from opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b0->opentelemetry-instrumentation-fastapi~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading asgiref-3.11.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-flask to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-flask~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_flask-0.60b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_flask-0.59b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_flask-0.58b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_flask-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_flask-0.56b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_flask-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_flask-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-flask to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_flask-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_flask-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-dbapi==0.60b1 (from opentelemetry-instrumentation-psycopg2~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_dbapi-0.60b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-psycopg2 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_psycopg2-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-dbapi==0.60b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_dbapi-0.60b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_psycopg2-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-dbapi==0.59b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_dbapi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_psycopg2-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-dbapi==0.58b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_dbapi-0.58b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_psycopg2-0.57b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-dbapi==0.57b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_dbapi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_psycopg2-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-dbapi==0.56b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_dbapi-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_psycopg2-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-dbapi==0.55b1 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_dbapi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_psycopg2-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-dbapi==0.55b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_dbapi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-psycopg2 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_psycopg2-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-dbapi==0.54b1 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_dbapi-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-psycopg2~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_psycopg2-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-dbapi==0.54b0 (from opentelemetry-instrumentation-psycopg2~=0.53b0->azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_dbapi-0.54b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-requests to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-requests~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_requests-0.60b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_requests-0.59b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_requests-0.58b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_requests-0.57b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_requests-0.56b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_requests-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_requests-0.55b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-requests to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_requests-0.54b1-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_requests-0.54b0-py3-none-any.whl.metadata (2.7 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-urllib to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-urllib~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib-0.60b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib-0.59b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib-0.58b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib-0.57b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib-0.56b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib-0.55b1-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib-0.55b0-py3-none-any.whl.metadata (3.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-urllib to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib-0.54b1-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib-0.54b0-py3-none-any.whl.metadata (3.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is looking at multiple versions of opentelemetry-instrumentation-urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting opentelemetry-instrumentation-urllib3~=0.53b0 (from azure-monitor-opentelemetry->azure-ai-ml>=1.0.0->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 8))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib3-0.60b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib3-0.59b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib3-0.58b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib3-0.57b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib3-0.56b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib3-0.55b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib3-0.55b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib3-0.54b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading opentelemetry_instrumentation_urllib3-0.54b0-py3-none-any.whl.metadata (4.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Collecting backports.weakref (from backports.tempfile->azureml-core~=1.61.0->azureml-defaults->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 1))\n",
      "2025-12-17T22:07:57: #10 176.5   Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Requirement already satisfied: mpmath<1.4,>=1.1.0 in /azureml-envs/azureml_f71dcdfa6b5c19f689c94e1aa90f3685/lib/python3.10/site-packages (from sympy->onnxruntime->-r /azureml-environment-setup/condaenv.ksctmjkq.requirements.txt (line 17)) (1.3.0)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 95.3 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 78.1 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 566.1/566.1 kB 19.8 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 85.1 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 83.7 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azureml_defaults-1.61.0-py3-none-any.whl (2.1 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azureml_core-1.61.0.post1-py3-none-any.whl (3.3 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 83.3 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading argcomplete-3.6.3-py3-none-any.whl (43 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_core-1.37.0-py3-none-any.whl (214 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_graphrbac-0.61.2-py2.py3-none-any.whl (142 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl (1.1 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 45.5 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_mgmt_containerregistry-14.0.0-py3-none-any.whl (1.7 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 63.0 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_mgmt_core-1.6.0-py3-none-any.whl (29 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_mgmt_keyvault-11.0.0-py3-none-any.whl (308 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_mgmt_network-30.0.0-py3-none-any.whl (614 kB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 614.0/614.0 kB 18.2 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_mgmt_resource-24.0.0-py3-none-any.whl (3.6 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 99.4 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_mgmt_storage-24.0.0-py3-none-any.whl (290 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azureml_dataset_runtime-1.61.0-py3-none-any.whl (2.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azureml_dataprep-5.4.2-py3-none-any.whl (253 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_identity-1.17.0-py3-none-any.whl (173 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 770.3/770.3 kB 38.9 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azureml_dataprep_native-42.1.0-cp310-cp310-manylinux1_x86_64.whl (187 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azureml_dataprep_rslex-2.25.2-cp310-cp310-manylinux1_x86_64.whl (26.1 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.1/26.1 MB 76.3 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azureml_inference_server_http-1.5.0-py3-none-any.whl (42 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_api-1.33.0-py3-none-any.whl (65 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl (118 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl (194 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading inference_schema-1.8-py3-none-any.whl (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading jsonpickle-4.1.1-py3-none-any.whl (47 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading knack-0.12.0-py3-none-any.whl (60 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading msal-1.34.0-py3-none-any.whl (116 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 93.6 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl (40 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading paramiko-3.5.1-py3-none-any.whl (227 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.3/42.3 MB 71.0 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 57.5 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pyopenssl-25.3.0-py3-none-any.whl (57 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading secretstorage-3.5.0-py3-none-any.whl (15 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 80.1 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.7/9.7 MB 112.9 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_ai_ml-1.30.0-py3-none-any.whl (13.3 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.3/13.3 MB 119.1 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 51.3 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading mlflow-3.7.0-py3-none-any.whl (8.9 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.9/8.9 MB 112.8 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading mlflow_skinny-3.7.0-py3-none-any.whl (2.4 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 61.1 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading mlflow_tracing-3.7.0-py3-none-any.whl (1.3 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 51.8 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading alembic-1.17.2-py3-none-any.whl (248 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading cachetools-6.2.4-py3-none-any.whl (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading databricks_sdk-0.76.0-py3-none-any.whl (774 kB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 774.7/774.7 kB 39.6 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading fastapi-0.125.0-py3-none-any.whl (112 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading google_auth-2.45.0-py2.py3-none-any.whl (233 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading huey-2.5.5-py3-none-any.whl (76 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.7/8.7 MB 124.8 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 37.7/37.7 MB 71.8 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading sqlalchemy-2.0.45-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 55.6 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading sqlparse-0.5.4-py3-none-any.whl (45 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azureml_mlflow-1.60.0-py3-none-any.whl (1.0 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 41.0 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading onnxruntime-1.23.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.4/17.4 MB 81.2 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading onnx-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.1/18.1 MB 72.7 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 62.2 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_storage_file_datalake-12.14.0-py3-none-any.whl (251 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 118.7 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading greenlet-3.3.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (586 kB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 586.9/586.9 kB 23.5 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading jeepney-0.9.0-py3-none-any.whl (49 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 50.2 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading ml_dtypes-0.5.4-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.0/5.0 MB 99.9 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 101.2 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pynacl-1.6.1-cp38-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 60.9 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 791.7/791.7 kB 33.6 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading rpds_py-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_monitor_opentelemetry-1.6.7-py3-none-any.whl (23 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl (11 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_monitor_opentelemetry_exporter-1.0.0b40-py2.py3-none-any.whl (159 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_instrumentation_django-0.54b0-py3-none-any.whl (19 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl (31 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_instrumentation_wsgi-0.54b0-py3-none-any.whl (14 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl (7.3 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl (16 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading asgiref-3.11.0-py3-none-any.whl (24 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_instrumentation_flask-0.54b0-py3-none-any.whl (14 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_instrumentation_psycopg2-0.54b0-py3-none-any.whl (10 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_instrumentation_dbapi-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_instrumentation_requests-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_instrumentation_urllib-0.54b0-py3-none-any.whl (12 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_instrumentation_urllib3-0.54b0-py3-none-any.whl (13 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl (14 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading azure_storage_file_share-12.23.1-py3-none-any.whl (307 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pkginfo-1.12.1.2-py3-none-any.whl (32 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "2025-12-17T22:07:57: #10 176.5    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 57.0 MB/s  0:00:00\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Using cached tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "2025-12-17T22:07:57: #10 176.5 Building wheels for collected packages: fusepy, seqeval\n",
      "2025-12-17T22:07:57: #10 176.5   Building wheel for fusepy (pyproject.toml): started\n",
      "2025-12-17T22:07:57: #10 176.5   Building wheel for fusepy (pyproject.toml): finished with status 'done'\n",
      "2025-12-17T22:07:57: #10 176.5   Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10537 sha256=83520101094c68ae1727691451713a3846eb5bcf1b6a88bb514e53f9db8cc600\n",
      "2025-12-17T22:07:57: #10 176.5   Stored in directory: /root/.cache/pip/wheels/c0/18/f6/f0d6be9d0435e2677ce5cc758e91da50053dce456a346f08c5\n",
      "2025-12-17T22:07:57: #10 176.5   Building wheel for seqeval (pyproject.toml): started\n",
      "2025-12-17T22:07:57: #10 176.5   Building wheel for seqeval (pyproject.toml): finished with status 'done'\n",
      "2025-12-17T22:07:57: #10 176.5   Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16250 sha256=22f4a828371c0eda96d1b5d51250e7d9fa81e5b20843e9708d038fa5b939afd5\n",
      "2025-12-17T22:07:57: #10 176.5   Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "2025-12-17T22:07:57: #10 176.5 Successfully built fusepy seqeval\n",
      "2025-12-17T22:07:57: #10 176.5 Installing collected packages: pytz, huey, fusepy, flatbuffers, fixedint, backports.weakref, azureml-dataprep-rslex, azure-common, zipp, xxhash, wrapt, werkzeug, urllib3, tzdata, typing-inspection, tqdm, tomli, threadpoolctl, tabulate, sqlparse, smmap, six, sentencepiece, safetensors, rpds-py, regex, pyyaml, python-dotenv, PySocks, pyparsing, PyJWT, pygments, pydash, pydantic-core, pycparser, pyasn1, pyarrow, psutil, protobuf, propcache, pkginfo, pillow, pathspec, packaging, opentelemetry-util-http, oauthlib, numpy, multidict, Mako, kiwisolver, jsonpickle, joblib, jmespath, jeepney, itsdangerous, isodate, idna, humanfriendly, hf-xet, h11, greenlet, graphql-core, fsspec, frozenlist, fonttools, exceptiongroup, dill, cycler, contextlib2, colorama, cloudpickle, click, charset_normalizer, certifi, cachetools, blinker, bcrypt, backports.tempfile, azureml-dataprep-native, attrs, async-timeout, asgiref, argcomplete, annotated-types, annotated-doc, aiohappyeyeballs, yarl, uvicorn, sqlalchemy, scipy, rsa, requests, referencing, python-dateutil, pydantic, pyasn1-modules, opentelemetry-proto, multiprocess, ml_dtypes, marshmallow, knack, importlib-metadata, gunicorn, graphql-relay, gitdb, flask, deprecated, contourpy, coloredlogs, cffi, anyio, aiosignal, strictyaml, starlette, scikit-learn, requests-oauthlib, pynacl, pydantic-settings, pandas, opentelemetry-api, onnxruntime, onnx, matplotlib, jsonschema-specifications, inference-schema, huggingface-hub, graphene, google-auth, gitpython, flask-cors, docker, cryptography, azure-core, alembic, aiohttp, tokenizers, seqeval, SecretStorage, pyopenssl, paramiko, opentelemetry-semantic-conventions, msrest, jsonschema, fastapi, databricks-sdk, azure-storage-file-share, azure-storage-blob, azure-mgmt-core, azure-core-tracing-opentelemetry, adal, transformers, opentelemetry-sdk, opentelemetry-instrumentation, ndg-httpsclient, msrestazure, msal, datasets, azure-storage-file-datalake, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-network, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, opentelemetry-resource-detector-azure, opentelemetry-instrumentation-wsgi, opentelemetry-instrumentation-urllib3, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-dbapi, opentelemetry-instrumentation-asgi, msal-extensions, mlflow-tracing, mlflow-skinny, azure-graphrbac, opentelemetry-instrumentation-psycopg2, opentelemetry-instrumentation-flask, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-django, mlflow, azureml-core, azure-identity, azureml-mlflow, azureml-dataprep, azure-monitor-opentelemetry-exporter, azureml-inference-server-http, azureml-dataset-runtime, azure-monitor-opentelemetry, azure-ai-ml, azureml-defaults\n",
      "2025-12-17T22:07:57: #10 176.5   Attempting uninstall: numpy\n",
      "2025-12-17T22:07:57: #10 176.5     Found existing installation: numpy 2.2.6\n",
      "2025-12-17T22:07:57: #10 176.5     Uninstalling numpy-2.2.6:\n",
      "2025-12-17T22:07:57: #10 176.5       Successfully uninstalled numpy-2.2.6\n",
      "2025-12-17T22:07:57: #10 176.5   Attempting uninstall: fsspec\n",
      "2025-12-17T22:07:57: #10 176.5     Found existing installation: fsspec 2025.12.0\n",
      "2025-12-17T22:07:57: #10 176.5     Uninstalling fsspec-2025.12.0:\n",
      "2025-12-17T22:07:57: #10 176.5       Successfully uninstalled fsspec-2025.12.0\n",
      "2025-12-17T22:07:57: #10 176.5 \n",
      "2025-12-17T22:07:57: #10 176.5 Successfully installed Mako-1.3.10 PyJWT-2.10.1 PySocks-1.7.1 SecretStorage-3.5.0 adal-1.2.7 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 alembic-1.17.2 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.12.0 argcomplete-3.6.3 asgiref-3.11.0 async-timeout-5.0.1 attrs-25.4.0 azure-ai-ml-1.30.0 azure-common-1.1.28 azure-core-1.37.0 azure-core-tracing-opentelemetry-1.0.0b12 azure-graphrbac-0.61.2 azure-identity-1.17.0 azure-mgmt-authorization-4.0.0 azure-mgmt-containerregistry-14.0.0 azure-mgmt-core-1.6.0 azure-mgmt-keyvault-11.0.0 azure-mgmt-network-30.0.0 azure-mgmt-resource-24.0.0 azure-mgmt-storage-24.0.0 azure-monitor-opentelemetry-1.6.7 azure-monitor-opentelemetry-exporter-1.0.0b40 azure-storage-blob-12.19.0 azure-storage-file-datalake-12.14.0 azure-storage-file-share-12.23.1 azureml-core-1.61.0.post1 azureml-dataprep-5.4.2 azureml-dataprep-native-42.1.0 azureml-dataprep-rslex-2.25.2 azureml-dataset-runtime-1.61.0 azureml-defaults-1.61.0 azureml-inference-server-http-1.5.0 azureml-mlflow-1.60.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-5.0.0 blinker-1.9.0 cachetools-6.2.4 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 cloudpickle-2.2.1 colorama-0.4.6 coloredlogs-15.0.1 contextlib2-21.6.0 contourpy-1.3.2 cryptography-46.0.3 cycler-0.12.1 databricks-sdk-0.76.0 datasets-4.0.0 deprecated-1.3.1 dill-0.3.8 docker-7.1.0 exceptiongroup-1.3.1 fastapi-0.125.0 fixedint-0.1.6 flask-3.1.2 flask-cors-6.0.2 flatbuffers-25.9.23 fonttools-4.61.1 frozenlist-1.8.0 fsspec-2025.3.0 fusepy-3.0.1 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.45.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 greenlet-3.3.0 gunicorn-23.0.0 h11-0.16.0 hf-xet-1.2.0 huey-2.5.5 huggingface-hub-0.36.0 humanfriendly-10.0 idna-3.11 importlib-metadata-8.6.1 inference-schema-1.8 isodate-0.7.2 itsdangerous-2.2.0 jeepney-0.9.0 jmespath-1.0.1 joblib-1.5.3 jsonpickle-4.1.1 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kiwisolver-1.4.9 knack-0.12.0 marshmallow-3.26.1 matplotlib-3.10.8 ml_dtypes-0.5.4 mlflow-3.7.0 mlflow-skinny-3.7.0 mlflow-tracing-3.7.0 msal-1.34.0 msal-extensions-1.3.1 msrest-0.7.1 msrestazure-0.6.4.post1 multidict-6.7.0 multiprocess-0.70.16 ndg-httpsclient-0.5.1 numpy-1.26.4 oauthlib-3.3.1 onnx-1.20.0 onnxruntime-1.23.2 opentelemetry-api-1.33.0 opentelemetry-instrumentation-0.54b0 opentelemetry-instrumentation-asgi-0.54b0 opentelemetry-instrumentation-dbapi-0.54b0 opentelemetry-instrumentation-django-0.54b0 opentelemetry-instrumentation-fastapi-0.54b0 opentelemetry-instrumentation-flask-0.54b0 opentelemetry-instrumentation-psycopg2-0.54b0 opentelemetry-instrumentation-requests-0.54b0 opentelemetry-instrumentation-urllib-0.54b0 opentelemetry-instrumentation-urllib3-0.54b0 opentelemetry-instrumentation-wsgi-0.54b0 opentelemetry-proto-1.39.1 opentelemetry-resource-detector-azure-0.1.5 opentelemetry-sdk-1.33.0 opentelemetry-semantic-conventions-0.54b0 opentelemetry-util-http-0.54b0 packaging-25.0 pandas-2.3.3 paramiko-3.5.1 pathspec-0.12.1 pillow-12.0.0 pkginfo-1.12.1.2 propcache-0.4.1 protobuf-6.33.2 psutil-7.1.3 pyarrow-20.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.23 pydantic-2.11.10 pydantic-core-2.33.2 pydantic-settings-2.12.0 pydash-8.0.5 pygments-2.19.2 pynacl-1.6.1 pyopenssl-25.3.0 pyparsing-3.2.5 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 pytz-2025.2 pyyaml-6.0.3 referencing-0.37.0 regex-2025.11.3 requests-2.32.5 requests-oauthlib-2.0.0 rpds-py-0.30.0 rsa-4.9.1 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 sentencepiece-0.2.1 seqeval-1.2.2 six-1.17.0 smmap-5.0.2 sqlalchemy-2.0.45 sqlparse-0.5.4 starlette-0.50.0 strictyaml-1.7.3 tabulate-0.9.0 threadpoolctl-3.6.0 tokenizers-0.22.1 tomli-2.3.0 tqdm-4.67.1 transformers-4.57.3 typing-inspection-0.4.2 tzdata-2025.3 urllib3-2.6.2 uvicorn-0.38.0 werkzeug-3.1.4 wrapt-1.16.0 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0\n",
      "2025-12-17T22:07:57: #10 176.5 \n",
      "2025-12-17T22:07:57: #10 176.done\n",
      "2025-12-17T22:07:57: #10 176.5 #\n",
      "2025-12-17T22:07:57: #10 176.5 # To activate this environment, use\n",
      "2025-12-17T22:07:57: #10 176.5 #\n",
      "2025-12-17T22:07:57: #10 176.5 #     $ conda activate /azureml-envs/azureml_f71dcdfa6b5c19f689c94e1aa90f3685\n",
      "2025-12-17T22:07:57: #10 176.5 #\n",
      "2025-12-17T22:07:57: #10 176.5 # To deactivate an active environment, use\n",
      "2025-12-17T22:07:57: #10 176.5 #\n",
      "2025-12-17T22:07:57: #10 176.5 #     $ conda deactivate\n",
      "2025-12-17T22:07:57: #10 176.5 \n",
      "2025-12-17T22:08:00: #10 DONE 180.0s\n",
      "\n",
      "2025-12-17T22:08:01: #11 [ 7/10] COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      "2025-12-17T22:08:01: #11 DONE 0.1s\n",
      "\n",
      "2025-12-17T22:08:01: #12 [ 8/10] RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      "2025-12-17T22:08:01: #12 DONE 0.3s\n",
      "\n",
      "2025-12-17T22:08:01: #13 [ 9/10] RUN rm -rf azureml-environment-setup\n",
      "2025-12-17T22:08:01: #13 DONE 0.3s\n",
      "\n",
      "2025-12-17T22:08:01: #14 exporting to image\n",
      "2025-12-17T22:08:01: #14 exporting layers\n",
      "2025-12-17T22:08:25: #14 exporting layers 23.7s done\n",
      "2025-12-17T22:08:25: #14 writing image sha256:18ec648778bf145bdb75a0cb7b1f15d612bb959cbfac550514c5397189f4aee1 done\n",
      "2025-12-17T22:08:25: #14 naming to b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_ce68dc37400cee2fcde731c88b0a5cef done\n",
      "2025-12-17T22:08:25: #14 naming to b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_ce68dc37400cee2fcde731c88b0a5cef:1 done\n",
      "2025-12-17T22:08:25: #14 DONE 23.7s\n",
      "\n",
      "\n",
      "2025-12-17T22:08:25: Logging into Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-17T22:08:25: WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "2025-12-17T22:08:25: Login Succeeded\n",
      "\n",
      "\n",
      "2025-12-17T22:08:25: Using default tag: latest\n",
      "2025-12-17T22:08:25: The push refers to repository [b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_ce68dc37400cee2fcde731c88b0a5cef]\n",
      "2025-12-17T22:08:25: 86528136179c: Preparing\n",
      "2025-12-17T22:08:25: 5f70bf18a086: Preparing\n",
      "2025-12-17T22:08:25: 046e0586d0b4: Preparing\n",
      "2025-12-17T22:08:25: 3f137216e832: Preparing\n",
      "2025-12-17T22:08:25: 22800117a191: Preparing\n",
      "2025-12-17T22:08:25: 67048b384de9: Preparing\n",
      "2025-12-17T22:08:25: ec7d192aacb0: Preparing\n",
      "2025-12-17T22:08:25: 5f70bf18a086: Preparing\n",
      "2025-12-17T22:08:25: 6b0c1cfc8f15: Preparing\n",
      "2025-12-17T22:08:25: d0b10cfca986: Preparing\n",
      "2025-12-17T22:08:25: 2baf6d5fcdda: Preparing\n",
      "2025-12-17T22:08:25: 947277ce5638: Preparing\n",
      "2025-12-17T22:08:25: 2ea0beed9e18: Preparing\n",
      "2025-12-17T22:08:25: 7d3ba5b124ef: Preparing\n",
      "2025-12-17T22:08:25: cd1cc5cf0a38: Preparing\n",
      "2025-12-17T22:08:25: fa26ceb8799b: Preparing\n",
      "2025-12-17T22:08:25: 44bfba9b2552: Preparing\n",
      "2025-12-17T22:08:25: fffe76c64ef2: Preparing\n",
      "2025-12-17T22:08:25: 67048b384de9: Waiting\n",
      "2025-12-17T22:08:25: ec7d192aacb0: Waiting\n",
      "2025-12-17T22:08:25: 6b0c1cfc8f15: Waiting\n",
      "2025-12-17T22:08:25: d0b10cfca986: Waiting\n",
      "2025-12-17T22:08:25: 2baf6d5fcdda: Waiting\n",
      "2025-12-17T22:08:25: 947277ce5638: Waiting\n",
      "2025-12-17T22:08:25: 2ea0beed9e18: Waiting\n",
      "2025-12-17T22:08:25: 7d3ba5b124ef: Waiting\n",
      "2025-12-17T22:08:25: cd1cc5cf0a38: Waiting\n",
      "2025-12-17T22:08:25: fa26ceb8799b: Waiting\n",
      "2025-12-17T22:08:25: fffe76c64ef2: Waiting\n",
      "2025-12-17T22:08:25: 44bfba9b2552: Waiting\n",
      "2025-12-17T22:08:25: 5f70bf18a086: Pushed\n",
      "2025-12-17T22:08:25: 046e0586d0b4: Pushed\n",
      "2025-12-17T22:08:25: 22800117a191: Pushed\n",
      "2025-12-17T22:08:26: 86528136179c: Pushed\n",
      "2025-12-17T22:08:26: ec7d192aacb0: Pushed\n",
      "2025-12-17T22:08:26: 6b0c1cfc8f15: Pushed\n",
      "2025-12-17T22:08:26: 67048b384de9: Pushed\n",
      "2025-12-17T22:08:26: d0b10cfca986: Pushed\n",
      "2025-12-17T22:08:27: 7d3ba5b124ef: Pushed\n",
      "2025-12-17T22:08:27: 947277ce5638: Pushed\n",
      "2025-12-17T22:08:28: cd1cc5cf0a38: Pushed\n",
      "2025-12-17T22:08:28: fa26ceb8799b: Pushed\n",
      "2025-12-17T22:08:30: 2baf6d5fcdda: Pushed\n",
      "2025-12-17T22:08:33: fffe76c64ef2: Pushed\n",
      "2025-12-17T22:08:43: 2ea0beed9e18: Pushed\n",
      "2025-12-17T22:08:51: 44bfba9b2552: Pushed\n",
      "2025-12-17T22:10:17: 3f137216e832: Pushed\n",
      "2025-12-17T22:10:18: latest: digest: sha256:6af53cf78bfa38434304f999be5014921610cc3129317ddd4db9115ceab9bf3e size: 4092\n",
      "\n",
      "\n",
      "2025-12-17T22:10:18: The push refers to repository [b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_ce68dc37400cee2fcde731c88b0a5cef]\n",
      "2025-12-17T22:10:18: 86528136179c: Preparing\n",
      "2025-12-17T22:10:18: 5f70bf18a086: Preparing\n",
      "2025-12-17T22:10:18: 046e0586d0b4: Preparing\n",
      "2025-12-17T22:10:18: 3f137216e832: Preparing\n",
      "2025-12-17T22:10:18: 22800117a191: Preparing\n",
      "2025-12-17T22:10:18: 67048b384de9: Preparing\n",
      "2025-12-17T22:10:18: ec7d192aacb0: Preparing\n",
      "2025-12-17T22:10:18: 5f70bf18a086: Preparing\n",
      "2025-12-17T22:10:18: 6b0c1cfc8f15: Preparing\n",
      "2025-12-17T22:10:18: d0b10cfca986: Preparing\n",
      "2025-12-17T22:10:18: 2baf6d5fcdda: Preparing\n",
      "2025-12-17T22:10:18: 947277ce5638: Preparing\n",
      "2025-12-17T22:10:18: 2ea0beed9e18: Preparing\n",
      "2025-12-17T22:10:18: 7d3ba5b124ef: Preparing\n",
      "2025-12-17T22:10:18: cd1cc5cf0a38: Preparing\n",
      "2025-12-17T22:10:18: fa26ceb8799b: Preparing\n",
      "2025-12-17T22:10:18: 44bfba9b2552: Preparing\n",
      "2025-12-17T22:10:18: fffe76c64ef2: Preparing\n",
      "2025-12-17T22:10:18: 947277ce5638: Waiting\n",
      "2025-12-17T22:10:18: 2ea0beed9e18: Waiting\n",
      "2025-12-17T22:10:18: 7d3ba5b124ef: Waiting\n",
      "2025-12-17T22:10:18: cd1cc5cf0a38: Waiting\n",
      "2025-12-17T22:10:18: fa26ceb8799b: Waiting\n",
      "2025-12-17T22:10:18: 44bfba9b2552: Waiting\n",
      "2025-12-17T22:10:18: fffe76c64ef2: Waiting\n",
      "2025-12-17T22:10:18: 67048b384de9: Waiting\n",
      "2025-12-17T22:10:18: 6b0c1cfc8f15: Waiting\n",
      "2025-12-17T22:10:18: ec7d192aacb0: Waiting\n",
      "2025-12-17T22:10:18: d0b10cfca986: Waiting\n",
      "2025-12-17T22:10:18: 2baf6d5fcdda: Waiting\n",
      "2025-12-17T22:10:18: 046e0586d0b4: Layer already exists\n",
      "2025-12-17T22:10:18: 3f137216e832: Layer already exists\n",
      "2025-12-17T22:10:18: 22800117a191: Layer already exists\n",
      "2025-12-17T22:10:18: 86528136179c: Layer already exists\n",
      "2025-12-17T22:10:18: 5f70bf18a086: Layer already exists\n",
      "2025-12-17T22:10:18: 6b0c1cfc8f15: Layer already exists\n",
      "2025-12-17T22:10:18: ec7d192aacb0: Layer already exists\n",
      "2025-12-17T22:10:18: 67048b384de9: Layer already exists\n",
      "2025-12-17T22:10:18: d0b10cfca986: Layer already exists\n",
      "2025-12-17T22:10:18: 2baf6d5fcdda: Layer already exists\n",
      "2025-12-17T22:10:18: 2ea0beed9e18: Layer already exists\n",
      "2025-12-17T22:10:18: 947277ce5638: Layer already exists\n",
      "2025-12-17T22:10:18: fa26ceb8799b: Layer already exists\n",
      "2025-12-17T22:10:18: 7d3ba5b124ef: Layer already exists\n",
      "2025-12-17T22:10:18: cd1cc5cf0a38: Layer already exists\n",
      "2025-12-17T22:10:18: 44bfba9b2552: Layer already exists\n",
      "2025-12-17T22:10:18: fffe76c64ef2: Layer already exists\n",
      "2025-12-17T22:10:19: 1: digest: sha256:6af53cf78bfa38434304f999be5014921610cc3129317ddd4db9115ceab9bf3e size: 4092\n",
      "\n",
      "\n",
      "2025-12-17T22:10:19: #### Image for post-processing commands: b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_ce68dc37400cee2fcde731c88b0a5cef:latest\n",
      "2025-12-17T22:10:19: #### Image digest: sha256:6af53cf78bfa38434304f999be5014921610cc3129317ddd4db9115ceab9bf3e\n",
      "2025-12-17T22:10:19: \n",
      "\n",
      "#### Found send_dependencies.py at: /tmp/tmpz78iz6u0/azureml-environment-setup/send_dependencies.py\n",
      "2025-12-17T22:10:19: #### Attempting to run dependencies script\n",
      "\n",
      "\n",
      "2025-12-17T22:10:24: Report materialized dependencies for the environment\n",
      "2025-12-17T22:10:24: Reading environment context\n",
      "2025-12-17T22:10:24: Exporting conda environment\n",
      "2025-12-17T22:10:24: Sending request with materialized conda environment details\n",
      "2025-12-17T22:10:24: Successfully sent materialized environment dependencies\n",
      "\n",
      "\n",
      "2025-12-17T22:10:24: 475b9dcc264d622a8ab9e5a5a4848e3fa46988c420d12d1b5153b4c38fee3cef\n",
      "\n",
      "\n",
      "2025-12-17T22:10:24: #### Cleaning up local image cache\n",
      "2025-12-17T22:10:24: Deleting b64e60f9615d4178843531f534cd62a6.azurecr.io/azureml/azureml_ce68dc37400cee2fcde731c88b0a5cef from local machine\n",
      "2025-12-17T22:10:24: Error response from daemon: page not found\n",
      "\n",
      "\n",
      "2025-12-17T22:10:24: Logging out of Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-17T22:10:24: Removing login credentials for https://index.docker.io/v1/\n",
      "\n",
      "\n",
      "2025-12-17T22:10:25: Logging out of Docker registry: b64e60f9615d4178843531f534cd62a6.azurecr.io\n",
      "2025-12-17T22:10:25: Removing login credentials for https://index.docker.io/v1/\n",
      "\n",
      "\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: amiable_bell_4ml6bncptc\n",
      "Web View: https://ml.azure.com/runs/amiable_bell_4ml6bncptc?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from orchestration.environment import (\n",
    "    build_environment_config,\n",
    "    create_training_environment,\n",
    "    prepare_environment_image,\n",
    ")\n",
    "\n",
    "# Build environment configuration from env.yaml (with sensible defaults)\n",
    "env_config = build_environment_config(CONFIG_DIR, configs[\"env\"])\n",
    "\n",
    "# Materialize or fetch the Azure ML Environment\n",
    "training_environment = create_training_environment(ml_client, env_config)\n",
    "\n",
    "# Trigger a small warm-up job so the image is built/cached before real work\n",
    "prepare_environment_image(\n",
    "    ml_client=ml_client,\n",
    "    environment=training_environment,\n",
    "    compute_cluster=configs[\"env\"][\"compute\"][\"training_cluster\"],\n",
    "    env_config=env_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training environment: resume-ner-training vv0656c70c562dd554 to training_environment_cache.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save environment info to a JSON file\n",
    "env_cache_file = Path(\"training_environment_cache.json\")\n",
    "\n",
    "if 'training_environment' in globals() and training_environment is not None:\n",
    "    env_data = {\n",
    "        \"name\": training_environment.name,\n",
    "        \"version\": training_environment.version,\n",
    "    }\n",
    "    \n",
    "    with open(env_cache_file, \"w\") as f:\n",
    "        json.dump(env_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved training environment: {env_data['name']} v{env_data['version']} to {env_cache_file}\")\n",
    "else:\n",
    "    print(\"No training environment to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training environment: resume-ner-training vv0656c70c562dd554\n",
      "Skipping environment setup - using cached environment\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to reload from cache\n",
    "env_cache_file = Path(\"training_environment_cache.json\")\n",
    "\n",
    "if env_cache_file.exists():\n",
    "    with open(env_cache_file, \"r\") as f:\n",
    "        env_data = json.load(f)\n",
    "    \n",
    "    try:\n",
    "        # Reload Environment object from ML client\n",
    "        training_environment = ml_client.environments.get(\n",
    "            name=env_data[\"name\"],\n",
    "            version=env_data[\"version\"]\n",
    "        )\n",
    "        print(f\"Loaded training environment: {training_environment.name} v{training_environment.version}\")\n",
    "        print(\"Skipping environment setup - using cached environment\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load environment {env_data['name']} v{env_data['version']}: {e}\")\n",
    "        print(\"Will need to create environment again\")\n",
    "        training_environment = None\n",
    "else:\n",
    "    print(f\"Cache file {env_cache_file} not found. Will need to create environment.\")\n",
    "    training_environment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.4: The Dry Run\n",
    "\n",
    "Submit a minimal sweep job using `smoke.yaml` to validate the sweep mechanism and pipeline integrity before launching the production HPO sweep.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/current/lib/python3.12/site-packages/mlflow/__init__.py:41: UserWarning: Versions of mlflow (3.7.0) and child packages mlflow-skinny (3.5.0) are different. This may lead to unexpected behavior. Please install the same version of all MLflow packages.\n",
      "  mlflow.mismatch._check_version_mismatch()\n"
     ]
    }
   ],
   "source": [
    "from orchestration.jobs import (\n",
    "    create_dry_run_sweep_job_for_backbone,\n",
    "    submit_and_wait_for_job,\n",
    "    validate_sweep_job,\n",
    ")\n",
    "\n",
    "TRAINING_SCRIPT_PATH = Path(\"../src/train.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cluster_name = configs[\"env\"][\"compute\"][\"training_cluster\"]\n",
    "\n",
    "try:\n",
    "    compute_cluster = ml_client.compute.get(compute_cluster_name)\n",
    "    if compute_cluster.provisioning_state != \"Succeeded\":\n",
    "        raise ValueError(f\"Compute cluster not ready: {compute_cluster.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Compute cluster '{compute_cluster_name}' not accessible: {e}\")\n",
    "\n",
    "stage_name = STAGE_SMOKE\n",
    "smoke_hpo_config = configs[\"hpo\"]\n",
    "\n",
    "# Backbones are controlled by the HPO config file (single source of truth)\n",
    "backbone_values = smoke_hpo_config[\"search_space\"][\"backbone\"][\"values\"]\n",
    "\n",
    "dry_run_sweep_jobs = {}\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    aml_experiment_name = build_aml_experiment_name(\n",
    "        experiment_config,\n",
    "        configs[\"env\"],\n",
    "        stage_name,\n",
    "        backbone,\n",
    "    )\n",
    "    dry_run_sweep_jobs[backbone] = create_dry_run_sweep_job_for_backbone(\n",
    "        script_path=TRAINING_SCRIPT_PATH,\n",
    "        data_asset=data_asset,\n",
    "        environment=training_environment,\n",
    "        compute_cluster=compute_cluster_name,\n",
    "        backbone=backbone,\n",
    "        smoke_hpo_config=smoke_hpo_config,\n",
    "        configs=configs,\n",
    "        config_metadata=config_metadata,\n",
    "        aml_experiment_name=aml_experiment_name,\n",
    "        stage=stage_name,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading resume-ner-azureml (0.17 MBs): 100%|██████████| 165299/165299 [00:03<00:00, 41641.68it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: silver_pasta_yqzs0g82xm\n",
      "Web View: https://ml.azure.com/runs/silver_pasta_yqzs0g82xm?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "[2025-12-17T22:49:50.7407231Z][GENERATOR][DEBUG]Sampled 2 jobs from search space \n",
      "[2025-12-17T22:49:51.1172505Z][SCHEDULER][INFO]Scheduling job, id='silver_pasta_yqzs0g82xm_0' \n",
      "[2025-12-17T22:49:51.1541293Z][SCHEDULER][INFO]Scheduling job, id='silver_pasta_yqzs0g82xm_1' \n",
      "[2025-12-17T22:49:51.9137620Z][SCHEDULER][INFO]Successfully scheduled a job. Id='silver_pasta_yqzs0g82xm_1' \n",
      "[2025-12-17T22:49:52.0647700Z][SCHEDULER][INFO]Successfully scheduled a job. Id='silver_pasta_yqzs0g82xm_0' \n",
      "[2025-12-17T22:50:21.3548591Z][GENERATOR][DEBUG]Setting all jobs generated as True, reason : Max number of jobs reached \n",
      "[2025-12-17T22:59:24.5812109Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: silver_pasta_yqzs0g82xm\n",
      "Web View: https://ml.azure.com/runs/silver_pasta_yqzs0g82xm?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for backbone, sweep_job in dry_run_sweep_jobs.items():\n",
    "    completed_job = submit_and_wait_for_job(ml_client, sweep_job)\n",
    "    validate_sweep_job(\n",
    "        job=completed_job,\n",
    "        backbone=backbone,\n",
    "        job_type=\"Dry run sweep\",\n",
    "        ml_client=ml_client,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.5: The Sweep (HPO)\n",
    "\n",
    "Submit a hyperparameter optimization sweep to systematically search for the best model configuration.\n",
    "\n",
    "**Note**: Currently using `smoke.yaml` for demonstration purposes (CPU-only setup). For production with GPU, switch to `prod.yaml` in the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs import (\n",
    "    create_hpo_sweep_job_for_backbone,\n",
    "    submit_and_wait_for_job,\n",
    "    validate_sweep_job,\n",
    ")\n",
    "\n",
    "TRAINING_SCRIPT_PATH = Path(\"../src/train.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cluster_name = configs[\"env\"][\"compute\"][\"training_cluster\"]\n",
    "\n",
    "try:\n",
    "    compute_cluster = ml_client.compute.get(compute_cluster_name)\n",
    "    if compute_cluster.provisioning_state != \"Succeeded\":\n",
    "        raise ValueError(f\"Compute cluster not ready: {compute_cluster.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Compute cluster '{compute_cluster_name}' not accessible: {e}\")\n",
    "\n",
    "stage_name = STAGE_HPO\n",
    "hpo_config = configs[\"hpo\"]\n",
    "backbone_values = configs[\"hpo\"][\"search_space\"][\"backbone\"][\"values\"]\n",
    "hpo_sweep_jobs = {}\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    aml_experiment_name = build_aml_experiment_name(\n",
    "        experiment_config,\n",
    "        configs[\"env\"],\n",
    "        stage_name,\n",
    "        backbone,\n",
    "    )\n",
    "    hpo_sweep_jobs[backbone] = create_hpo_sweep_job_for_backbone(\n",
    "        script_path=TRAINING_SCRIPT_PATH,\n",
    "        data_asset=data_asset,\n",
    "        environment=training_environment,\n",
    "        compute_cluster=compute_cluster_name,\n",
    "        hpo_config=hpo_config,\n",
    "        backbone=backbone,\n",
    "        configs=configs,\n",
    "        config_metadata=config_metadata,\n",
    "        aml_experiment_name=aml_experiment_name,\n",
    "        stage=stage_name,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading resume-ner-azureml (0.16 MBs): 100%|██████████| 164536/164536 [00:04<00:00, 40642.06it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: elated_piano_1wnx8pn04j\n",
      "Web View: https://ml.azure.com/runs/elated_piano_1wnx8pn04j?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "[2025-12-17T22:17:46.9035784Z][GENERATOR][DEBUG]Sampled 2 jobs from search space \n",
      "[2025-12-17T22:17:47.2742309Z][SCHEDULER][INFO]Scheduling job, id='elated_piano_1wnx8pn04j_0' \n",
      "[2025-12-17T22:17:47.3124599Z][SCHEDULER][INFO]Scheduling job, id='elated_piano_1wnx8pn04j_1' \n",
      "[2025-12-17T22:17:47.8853507Z][SCHEDULER][INFO]Successfully scheduled a job. Id='elated_piano_1wnx8pn04j_0' \n",
      "[2025-12-17T22:17:48.1067549Z][SCHEDULER][INFO]Successfully scheduled a job. Id='elated_piano_1wnx8pn04j_1' \n",
      "[2025-12-17T22:18:17.4208265Z][GENERATOR][DEBUG]Setting all jobs generated as True, reason : Max number of jobs reached \n",
      "[2025-12-17T22:24:48.5493847Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: elated_piano_1wnx8pn04j\n",
      "Web View: https://ml.azure.com/runs/elated_piano_1wnx8pn04j?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hpo_completed_jobs = {}\n",
    "\n",
    "for backbone, sweep_job in hpo_sweep_jobs.items():\n",
    "    completed_job = submit_and_wait_for_job(ml_client, sweep_job)\n",
    "    validate_sweep_job(\n",
    "        job=completed_job,\n",
    "        backbone=backbone,\n",
    "        job_type=\"HPO sweep\",\n",
    "        min_expected_trials=2,\n",
    "        ml_client=ml_client,\n",
    "    )\n",
    "    hpo_completed_jobs[backbone] = completed_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 HPO job references to hpo_completed_jobs_cache.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save job names to a JSON file\n",
    "hpo_jobs_cache_file = Path(\"hpo_completed_jobs_cache.json\")\n",
    "\n",
    "if hpo_completed_jobs:\n",
    "    # Extract job names (which are strings and easily serializable)\n",
    "    hpo_jobs_data = {\n",
    "        backbone: {\n",
    "            \"job_name\": job.name,\n",
    "            \"job_id\": job.id,\n",
    "        }\n",
    "        for backbone, job in hpo_completed_jobs.items()\n",
    "    }\n",
    "    \n",
    "    with open(hpo_jobs_cache_file, \"w\") as f:\n",
    "        json.dump(hpo_jobs_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved {len(hpo_jobs_data)} HPO job references to {hpo_jobs_cache_file}\")\n",
    "else:\n",
    "    print(\"No HPO completed jobs to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HPO job for deberta: elated_piano_1wnx8pn04j (status: Completed)\n",
      "\n",
      "Successfully reloaded 1 HPO completed jobs from cache\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to reload from cache\n",
    "hpo_jobs_cache_file = Path(\"hpo_completed_jobs_cache.json\")\n",
    "\n",
    "if hpo_jobs_cache_file.exists():\n",
    "    with open(hpo_jobs_cache_file, \"r\") as f:\n",
    "        hpo_jobs_data = json.load(f)\n",
    "    \n",
    "    # Reload Job objects from ML client\n",
    "    hpo_completed_jobs = {}\n",
    "    for backbone, job_info in hpo_jobs_data.items():\n",
    "        try:\n",
    "            job = ml_client.jobs.get(job_info[\"job_name\"])\n",
    "            hpo_completed_jobs[backbone] = job\n",
    "            print(f\"Loaded HPO job for {backbone}: {job.name} (status: {job.status})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load job {job_info['job_name']} for {backbone}: {e}\")\n",
    "    \n",
    "    if hpo_completed_jobs:\n",
    "        print(f\"\\nSuccessfully reloaded {len(hpo_completed_jobs)} HPO completed jobs from cache\")\n",
    "    else:\n",
    "        print(\"No valid jobs found in cache, will need to run HPO again\")\n",
    "        hpo_completed_jobs = {}\n",
    "else:\n",
    "    print(f\"Cache file {hpo_jobs_cache_file} not found. Will need to run HPO.\")\n",
    "    hpo_completed_jobs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.6: Best Configuration Selection (Automated)\n",
    "\n",
    "Programmatically select the best configuration from all HPO sweep runs across all backbone models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs import select_best_configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No valid trials found in any sweep job.\nLooking for metric 'macro-f1' with goal 'maximize'.\nChecked 1 sweep job(s): ['deberta']\n  deberta (sweep: elated_piano_1wnx8pn04j): 2 completed. Sample metrics: []",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Select the best configuration from all HPO sweep runs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m best_configuration = \u001b[43mselect_best_configuration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mml_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mml_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpo_completed_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpo_completed_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpo_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhpo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mversion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/resume-ner-azureml/src/orchestration/jobs/selection.py:159\u001b[39m, in \u001b[36mselect_best_configuration\u001b[39m\u001b[34m(ml_client, hpo_completed_jobs, hpo_config, dataset_version)\u001b[39m\n\u001b[32m    154\u001b[39m             sample_metrics = \u001b[38;5;28mlist\u001b[39m(_get_metrics_from_mlflow(completed[\u001b[32m0\u001b[39m].name).keys())[:\u001b[32m5\u001b[39m]\n\u001b[32m    155\u001b[39m         error_parts.append(\n\u001b[32m    156\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackbone\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (sweep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msweep_job.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(completed)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m completed. Sample metrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_metrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_parts))\n\u001b[32m    161\u001b[39m best_config = extract_trial_configuration(ml_client, best_trial, dataset_version)\n\u001b[32m    162\u001b[39m best_config[\u001b[33m\"\u001b[39m\u001b[33mselection_criteria\u001b[39m\u001b[33m\"\u001b[39m] = {\n\u001b[32m    163\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m: objective_metric,\n\u001b[32m    164\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgoal\u001b[39m\u001b[33m\"\u001b[39m: goal,\n\u001b[32m    165\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbest_value\u001b[39m\u001b[33m\"\u001b[39m: best_value,\n\u001b[32m    166\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbackbone\u001b[39m\u001b[33m\"\u001b[39m: best_backbone,\n\u001b[32m    167\u001b[39m }\n",
      "\u001b[31mValueError\u001b[39m: No valid trials found in any sweep job.\nLooking for metric 'macro-f1' with goal 'maximize'.\nChecked 1 sweep job(s): ['deberta']\n  deberta (sweep: elated_piano_1wnx8pn04j): 2 completed. Sample metrics: []"
     ]
    }
   ],
   "source": [
    "# Select the best configuration from all HPO sweep runs\n",
    "best_configuration = select_best_configuration(\n",
    "    ml_client=ml_client,\n",
    "    hpo_completed_jobs=hpo_completed_jobs,\n",
    "    hpo_config=configs[\"hpo\"],\n",
    "    dataset_version=configs[\"data\"][\"version\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trial_name': 'sad_zebra_z15v7pqsxp_1',\n",
       " 'trial_id': '/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/jobs/sad_zebra_z15v7pqsxp_1',\n",
       " 'backbone': 'deberta',\n",
       " 'hyperparameters': {'learning_rate': '1.0000292947037503',\n",
       "  'batch_size': '4',\n",
       "  'dropout': '0.15375876406682445',\n",
       "  'weight_decay': '1.0480647107344465',\n",
       "  'epochs': '5',\n",
       "  'backbone': 'microsoft/deberta-v3-base'},\n",
       " 'metrics': {'macro-f1': 0.13478611783696529,\n",
       "  'macro-f1-span': 0.0,\n",
       "  'loss': 3.0111255645751953},\n",
       " 'dataset_version': 'v2.1',\n",
       " 'selection_criteria': {'metric': 'macro-f1',\n",
       "  'goal': 'maximize',\n",
       "  'best_value': 0.13478611783696529,\n",
       "  'backbone': 'deberta'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best configuration to best_configuration_cache.json\n",
      "  Backbone: deberta\n",
      "  Best metric value: 0.13478611783696529\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save best configuration to a JSON file\n",
    "best_config_cache_file = Path(\"best_configuration_cache.json\")\n",
    "\n",
    "if \"best_configuration\" in globals() and best_configuration is not None:\n",
    "    # best_configuration contains trial_name, trial_id, backbone, hyperparameters, metrics, etc.\n",
    "    # All of these are JSON-serializable\n",
    "    with open(best_config_cache_file, \"w\") as f:\n",
    "        json.dump(best_configuration, f, indent=2)\n",
    "    print(f\"Saved best configuration to {best_config_cache_file}\")\n",
    "    print(f\"  Backbone: {best_configuration.get('backbone')}\")\n",
    "    print(f\"  Best metric value: {best_configuration.get('selection_criteria', {}).get('best_value')}\")\n",
    "else:\n",
    "    print(\"No best configuration to save\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best configuration from cache:\n",
      "  Backbone: deberta\n",
      "  Trial: sad_zebra_z15v7pqsxp_1\n",
      "  Best metric value: 0.13478611783696529\n",
      "  Dataset version: v2.1\n",
      "\n",
      "Skipping best configuration selection - using cached result\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to reload from cache\n",
    "best_config_cache_file = Path(\"best_configuration_cache.json\")\n",
    "\n",
    "if best_config_cache_file.exists():\n",
    "    with open(best_config_cache_file, \"r\") as f:\n",
    "        best_configuration = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded best configuration from cache:\")\n",
    "    print(f\"  Backbone: {best_configuration.get('backbone')}\")\n",
    "    print(f\"  Trial: {best_configuration.get('trial_name')}\")\n",
    "    print(f\"  Best metric value: {best_configuration.get('selection_criteria', {}).get('best_value')}\")\n",
    "    print(f\"  Dataset version: {best_configuration.get('dataset_version')}\")\n",
    "    print(f\"\\nSkipping best configuration selection - using cached result\")\n",
    "else:\n",
    "    print(f\"Cache file {best_config_cache_file} not found. Will need to run Step P1-3.6.\")\n",
    "    best_configuration = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.7: Final Training (Post-HPO, Single Run)\n",
    "\n",
    "Train the final production model using the best configuration from HPO with stable, controlled conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs import (\n",
    "    build_final_training_config,\n",
    "    create_final_training_job,\n",
    "    validate_final_training_job,\n",
    "    submit_and_wait_for_job\n",
    ")\n",
    "\n",
    "TRAINING_SCRIPT_PATH = Path(\"../src/train.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final training config from best HPO result + train.yaml defaults\n",
    "final_training_config = build_final_training_config(best_configuration, configs[\"train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cluster_name = configs[\"env\"][\"compute\"][\"training_cluster\"]\n",
    "\n",
    "try:\n",
    "    compute_cluster = ml_client.compute.get(compute_cluster_name)\n",
    "    if compute_cluster.provisioning_state != \"Succeeded\":\n",
    "        raise ValueError(f\"Compute cluster not ready: {compute_cluster.provisioning_state}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Compute cluster '{compute_cluster_name}' not accessible: {e}\")\n",
    "    \n",
    "# Create and submit final training job\n",
    "stage_name = STAGE_TRAINING\n",
    "aml_experiment_name = build_aml_experiment_name(\n",
    "    experiment_config,\n",
    "    configs[\"env\"],\n",
    "    stage_name,\n",
    "    final_training_config[\"backbone\"],\n",
    ")\n",
    "\n",
    "final_training_job = create_final_training_job(\n",
    "    script_path=TRAINING_SCRIPT_PATH,\n",
    "    data_asset_datastore_path=datastore_path,\n",
    "    environment=training_environment,\n",
    "    compute_cluster=compute_cluster_name,\n",
    "    final_config=final_training_config,\n",
    "    configs=configs,\n",
    "    config_metadata=config_metadata,\n",
    "    best_trial_name=best_configuration[\"trial_name\"],\n",
    "    best_value=best_configuration[\"selection_criteria\"][\"best_value\"],\n",
    "    aml_experiment_name=aml_experiment_name,\n",
    "    stage=stage_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit and validate final training job\n",
    "final_training_completed_job = submit_and_wait_for_job(ml_client, final_training_job)\n",
    "validate_final_training_job(final_training_completed_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "final_training_cache_file = Path(\"final_training_job_cache.json\")\n",
    "\n",
    "if \"final_training_completed_job\" in globals() and final_training_completed_job is not None:\n",
    "    data = {\n",
    "        \"job_name\": final_training_completed_job.name,\n",
    "        \"job_id\": final_training_completed_job.id,\n",
    "    }\n",
    "    with open(final_training_cache_file, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"Saved final training job reference to {final_training_cache_file}\")\n",
    "else:\n",
    "    print(\"No final training job to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logged Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded final training job: epic_chicken_6jcb4l0mk5 (status: Completed)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "final_training_cache_file = Path(\"final_training_job_cache.json\")\n",
    "\n",
    "if final_training_cache_file.exists():\n",
    "    with open(final_training_cache_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    try:\n",
    "        final_training_completed_job = ml_client.jobs.get(data[\"job_name\"])\n",
    "        print(f\"Loaded final training job: {final_training_completed_job.name} (status: {final_training_completed_job.status})\")\n",
    "        \n",
    "        # Validate that the job has a checkpoint output\n",
    "        if not hasattr(final_training_completed_job, \"outputs\") or \"checkpoint\" not in final_training_completed_job.outputs:\n",
    "            print(f\"\\n⚠️  WARNING: Training job {final_training_completed_job.name} does not have a 'checkpoint' output.\")\n",
    "            print(\"   This job cannot be used for model conversion.\")\n",
    "            print(\"   Please re-run Step P1-3.7: Final Training to generate a new job with checkpoint output.\")\n",
    "            final_training_completed_job = None\n",
    "        else:\n",
    "            print(f\"✓ Training job has checkpoint output\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not reload final training job {data['job_name']}: {e}\")\n",
    "        final_training_completed_job = None\n",
    "else:\n",
    "    print(f\"No cache file {final_training_cache_file} found; you need to rerun Step 3.7.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-4: Model Conversion & Optimization\n",
    "\n",
    "Convert the final training checkpoint to an optimized ONNX model (int8 quantized) for production inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>resume-ner-train-deberta</td><td>epic_chicken_6jcb4l0mk5</td><td>command</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/epic_chicken_6jcb4l0mk5?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&amp;tid=e7572e92-7aee-4713-a3c4-ba64888ad45f\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {'learning_rate': '1.0000292947037503', 'batch_size': '4', 'dropout': '0.15375876406682445', 'weight_decay': '1.0480647107344465', 'epochs': '2', 'backbone': 'microsoft/deberta-v3-base'}, 'init': False, 'name': 'epic_chicken_6jcb4l0mk5', 'type': 'command', 'status': 'Completed', 'log_files': None, 'description': 'Final production training with best HPO configuration', 'tags': {'data_config_hash': '2f21eff8258574d6', 'model_config_hash': '5f90a66353401b44', 'train_config_hash': 'f0c2caf728759868', 'hpo_config_hash': 'b28114c649d43a67', 'env_config_hash': '3e54b931c7640cf2', 'data_version': 'v2.1', 'model_backbone': 'distilbert-base-uncased', 'job_type': 'final_training', 'backbone': 'deberta', 'best_trial': 'sad_zebra_z15v7pqsxp_1', 'best_metric_value': '0.13478611783696529', 'stage': 'training', '_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":0,\"CurrentNodeCount\":1}'}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/longdang193/resume-ner-azureml', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '4de42d3bad2c4fa9526ca03db8cf029b0b2ecf71', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'cpu-cluster', 'ContentSnapshotId': 'b1d98872-e887-4812-9976-ad412545a1fd', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'StartTimeUtc': '2025-12-17 15:44:18', 'EndTimeUtc': '2025-12-17 15:45:51'}, 'print_as_yaml': False, 'id': '/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/jobs/epic_chicken_6jcb4l0mk5', 'Resource__source_path': '', 'base_path': '/workspaces/resume-ner-azureml/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f28459a7440>, 'serialize': <msrest.serialization.Serializer object at 0x7f28459b4e90>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'final-training', 'experiment_name': 'resume-ner-train-deberta', 'compute': 'cpu-cluster', 'services': {'Tracking': {'endpoint': 'azureml://japanwest.api.azureml.ms/mlflow/v1.0/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/epic_chicken_6jcb4l0mk5?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/3232563f3982da9961ea618d65a32a106230b55248141ce91a9158d93c07e092/dataset_tiny', 'mode': 'ro_mount'}}, 'job_outputs': {'checkpoint': {'type': 'uri_folder', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.epic_chicken_6jcb4l0mk5', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f28459a6120>}, 'outputs': {'checkpoint': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f2845cf3680>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f285f49ef60>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'epic_chicken_6jcb4l0mk5', 'description': 'Final production training with best HPO configuration', 'tags': {'data_config_hash': '2f21eff8258574d6', 'model_config_hash': '5f90a66353401b44', 'train_config_hash': 'f0c2caf728759868', 'hpo_config_hash': 'b28114c649d43a67', 'env_config_hash': '3e54b931c7640cf2', 'data_version': 'v2.1', 'model_backbone': 'distilbert-base-uncased', 'job_type': 'final_training', 'backbone': 'deberta', 'best_trial': 'sad_zebra_z15v7pqsxp_1', 'best_metric_value': '0.13478611783696529', 'stage': 'training', '_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":0,\"CurrentNodeCount\":1}'}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/workspaces/resume-ner-azureml/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f28459a7440>, 'serialize': <msrest.serialization.Serializer object at 0x7f28459a7500>, 'command': 'python src/train.py --data-asset ${{inputs.data}} --config-dir config --backbone deberta --learning-rate 1.0000292947037503 --batch-size 4 --dropout 0.15375876406682445 --weight-decay 1.0480647107344465 --epochs 2 --random-seed 42 --early-stopping-enabled false --use-combined-data true', 'code': '/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/codes/715381e4-d53d-4579-84f8-caa8ef2c321f/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/environments/resume-ner-training/versions/v71b2f952c412701e', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'final-training', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/3232563f3982da9961ea618d65a32a106230b55248141ce91a9158d93c07e092/dataset_tiny', 'mode': 'ro_mount'}}, 'outputs': {'checkpoint': {'type': 'uri_folder', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.epic_chicken_6jcb4l0mk5', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Completed', 'parameters': {'learning_rate': '1.0000292947037503', 'batch_size': '4', 'dropout': '0.15375876406682445', 'weight_decay': '1.0480647107344465', 'epochs': '2', 'backbone': 'microsoft/deberta-v3-base'}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://japanwest.api.azureml.ms/mlflow/v1.0/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourceGroups/resume_ner_2025-12-14-13-17-35/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/epic_chicken_6jcb4l0mk5?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f', 'type': 'Studio'}}, 'status': 'Completed', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f28459a7440>}, 'instance_id': '68a4ba3e-8125-4ee0-9b95-878e0e28e0ba', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'resume-ner-training:v71b2f952c412701e', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': {'job_tier': 'null'}, 'parent_job_name': None, 'swept': False})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_training_completed_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/current/lib/python3.12/site-packages/mlflow/__init__.py:41: UserWarning: Versions of mlflow (3.7.0) and child packages mlflow-skinny (3.5.0) are different. This may lead to unexpected behavior. Please install the same version of all MLflow packages.\n",
      "  mlflow.mismatch._check_version_mismatch()\n"
     ]
    }
   ],
   "source": [
    "from orchestration.jobs import (\n",
    "    get_checkpoint_output_from_training_job,\n",
    "    create_conversion_job,\n",
    "    validate_conversion_job,\n",
    "    submit_and_wait_for_job,\n",
    ")\n",
    "\n",
    "CONVERSION_SCRIPT_PATH = Path(\"../src/convert_to_onnx.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/resume-ner-azureml/src/orchestration/jobs/conversion.py:81: UserWarning: ml_client not provided for training job 'epic_chicken_6jcb4l0mk5'. Constructing data asset reference directly. For best results, provide ml_client.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Guard: ensure final_training_completed_job is set and has checkpoint output\n",
    "if \"final_training_completed_job\" not in globals() or final_training_completed_job is None:\n",
    "    raise ValueError(\n",
    "        \"final_training_completed_job is not set. \"\n",
    "        \"Please run Step P1-3.7: Final Training first, or ensure the cached job has a checkpoint output.\"\n",
    "    )\n",
    "\n",
    "# Guard: ensure ml_client is defined (required for fetching checkpoint data asset)\n",
    "if \"ml_client\" not in globals() or ml_client is None:\n",
    "    raise ValueError(\n",
    "        \"ml_client is not defined. \"\n",
    "        \"Please run the cells that set up ml_client (Step P1-3.1) before running this cell.\"\n",
    "    )\n",
    "\n",
    "checkpoint_output = get_checkpoint_output_from_training_job(final_training_completed_job, ml_client=ml_client)\n",
    "print(f\"✓ Retrieved checkpoint output: {checkpoint_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_cluster_name = configs[\"env\"][\"compute\"][\"conversion_cluster\"]\n",
    "conversion_job = create_conversion_job(\n",
    "    script_path=CONVERSION_SCRIPT_PATH,\n",
    "    checkpoint_output=checkpoint_output,\n",
    "    environment=training_environment,\n",
    "    compute_cluster=conversion_cluster_name,\n",
    "    configs=configs,\n",
    "    config_metadata=config_metadata,\n",
    "    best_config=best_configuration,\n",
    "    final_training_job=final_training_completed_job,\n",
    "    ml_client=ml_client,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'resume-ner-training' will not be used for anonymous registration\n",
      "\u001b[32mUploading resume-ner-azureml (0.16 MBs): 100%|██████████| 163521/163521 [00:03<00:00, 42382.54it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: gray_square_jrnt7hr7ck\n",
      "Web View: https://ml.azure.com/runs/gray_square_jrnt7hr7ck?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: gray_square_jrnt7hr7ck\n",
      "Web View: https://ml.azure.com/runs/gray_square_jrnt7hr7ck?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/resume_ner_2025-12-14-13-17-35/workspaces/resume-ner-ws\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid ONNX model path: None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m conversion_completed_job = submit_and_wait_for_job(ml_client, conversion_job)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mvalidate_conversion_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconversion_completed_job\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/resume-ner-azureml/src/orchestration/jobs/conversion.py:263\u001b[39m, in \u001b[36mvalidate_conversion_job\u001b[39m\u001b[34m(job)\u001b[39m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected ONNX output type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(onnx_output)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m onnx_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m onnx_path.endswith(\u001b[33m\"\u001b[39m\u001b[33m.onnx\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid ONNX model path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Invalid ONNX model path: None"
     ]
    }
   ],
   "source": [
    "conversion_completed_job = submit_and_wait_for_job(ml_client, conversion_job)\n",
    "validate_conversion_job(conversion_completed_job, ml_client=ml_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-5: Model Registration (The Handover)\n",
    "\n",
    "Register the optimized ONNX model in Azure ML Model Registry with full metadata for production deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.core.exceptions import ResourceNotFoundError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "\n",
    "\n",
    "def get_onnx_model_reference(conversion_job: Any, ml_client: Optional[MLClient] = None) -> str:\n",
    "    \"\"\"Resolve ONNX model output reference from a completed conversion job.\n",
    "\n",
    "    Azure ML v2 command outputs are typically ``uri_folder`` outputs. The SDK may\n",
    "    not always populate ``.path``/``.uri`` on reloaded jobs, so we fall back to\n",
    "    the auto-registered data asset name.\n",
    "    \"\"\"\n",
    "    if getattr(conversion_job, \"status\", None) != \"Completed\":\n",
    "        raise ValueError(f\"Conversion job not completed (status={getattr(conversion_job, 'status', None)})\")\n",
    "\n",
    "    if not hasattr(conversion_job, \"outputs\") or not conversion_job.outputs:\n",
    "        raise ValueError(\"Conversion job produced no outputs\")\n",
    "\n",
    "    if \"onnx_model\" not in conversion_job.outputs:\n",
    "        raise ValueError(\"Conversion job missing 'onnx_model' output\")\n",
    "\n",
    "    onnx_output = conversion_job.outputs[\"onnx_model\"]\n",
    "\n",
    "    # Prefer SDK-populated uri/path when available\n",
    "    uri = getattr(onnx_output, \"uri\", None)\n",
    "    if uri:\n",
    "        return str(uri)\n",
    "\n",
    "    path = getattr(onnx_output, \"path\", None)\n",
    "    if path:\n",
    "        return str(path)\n",
    "\n",
    "    if isinstance(onnx_output, str) and onnx_output:\n",
    "        return onnx_output\n",
    "\n",
    "    # Fallback: use Azure ML's auto-registered data asset name for the output\n",
    "    data_asset_name = f\"azureml_{conversion_job.name}_output_data_onnx_model\"\n",
    "    if ml_client is not None:\n",
    "        try:\n",
    "            asset = ml_client.data.get(name=data_asset_name, version=\"1\")\n",
    "            return f\"azureml:{asset.name}:{asset.version}\"\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return f\"azureml:{data_asset_name}:1\"\n",
    "\n",
    "\n",
    "onnx_model_path = get_onnx_model_reference(conversion_completed_job, ml_client=ml_client)\n",
    "print(f\"Resolved ONNX model reference: {onnx_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_version(best_config: Dict[str, Any], config_hashes: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Compute deterministic model version from configuration hashes.\n",
    "    \n",
    "    Args:\n",
    "        best_config: Best configuration from HPO selection\n",
    "        config_hashes: Configuration hashes dictionary\n",
    "        \n",
    "    Returns:\n",
    "        str: Model version string\n",
    "    \"\"\"\n",
    "    version_components = [\n",
    "        config_hashes[\"data\"],\n",
    "        config_hashes[\"model\"],\n",
    "        config_hashes[\"train\"],\n",
    "        best_config[\"backbone\"],\n",
    "    ]\n",
    "    version_str = \"_\".join(version_components)\n",
    "    version_hash = hashlib.sha256(version_str.encode()).hexdigest()[:CONFIG_HASH_LENGTH]\n",
    "    return f\"v{version_hash}\"\n",
    "\n",
    "\n",
    "model_version = compute_model_version(best_configuration, config_hashes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_production_model(\n",
    "    ml_client: MLClient,\n",
    "    model_name: str,\n",
    "    model_version: str,\n",
    "    model_path: str,\n",
    "    best_config: Dict[str, Any],\n",
    "    configs: Dict[str, Any],\n",
    "    config_metadata: Dict[str, str],\n",
    ") -> Model:\n",
    "    \"\"\"Register optimized ONNX model in Azure ML Model Registry.\n",
    "\n",
    "    Note: In Azure ML v2, command-job outputs are often ``uri_folder`` artefacts.\n",
    "    We therefore register the *folder/data-asset reference* produced by the\n",
    "    conversion job (not necessarily a direct ``.onnx`` file URI).\n",
    "    \"\"\"\n",
    "    if not model_path:\n",
    "        raise ValueError(f\"Invalid ONNX model path: {model_path}\")\n",
    "\n",
    "    if not (str(model_path).startswith(\"azureml:\") or str(model_path).startswith(\"azureml://\")):\n",
    "        raise ValueError(\n",
    "            f\"Invalid ONNX model reference (expected azureml:... or azureml://...): {model_path}\"\n",
    "        )\n",
    "\n",
    "    selection_criteria = best_config[\"selection_criteria\"]\n",
    "\n",
    "    model_description = (\n",
    "        f\"Production ONNX model for Resume NER. \"\n",
    "        f\"Backbone: {selection_criteria['backbone']}, \"\n",
    "        f\"Metric: {selection_criteria['metric']}={selection_criteria['best_value']:.4f}\"\n",
    "    )\n",
    "\n",
    "    model_tags = {\n",
    "        **config_metadata,\n",
    "        \"stage\": PROD_STAGE,\n",
    "        \"backbone\": selection_criteria[\"backbone\"],\n",
    "        \"metric\": selection_criteria[\"metric\"],\n",
    "        \"metric_value\": str(selection_criteria[\"best_value\"]),\n",
    "        \"dataset_version\": best_config[\"dataset_version\"],\n",
    "        \"model_format\": \"onnx\",\n",
    "        \"quantization\": \"int8\",\n",
    "        \"source_training_job\": final_training_completed_job.name,\n",
    "        \"source_conversion_job\": conversion_completed_job.name,\n",
    "    }\n",
    "\n",
    "    model = Model(\n",
    "        name=model_name,\n",
    "        version=model_version,\n",
    "        description=model_description,\n",
    "        path=model_path,\n",
    "        tags=model_tags,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        existing_model = ml_client.models.get(name=model_name, version=model_version)\n",
    "        return existing_model\n",
    "    except ResourceNotFoundError:\n",
    "        return ml_client.models.create_or_update(model)\n",
    "\n",
    "\n",
    "registered_model = register_production_model(\n",
    "    ml_client=ml_client,\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=model_version,\n",
    "    model_path=onnx_model_path,\n",
    "    best_config=best_configuration,\n",
    "    configs=configs,\n",
    "    config_metadata=config_metadata,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_registered_model(model: Model) -> None:\n",
    "    \"\"\"Validate registered model has required metadata and tags.\"\"\"\n",
    "    required_tags = [\"stage\", \"backbone\", \"metric\", \"dataset_version\"]\n",
    "    for tag in required_tags:\n",
    "        if tag not in model.tags:\n",
    "            raise ValueError(f\"Registered model missing required tag: {tag}\")\n",
    "\n",
    "    if model.tags.get(\"stage\") != PROD_STAGE:\n",
    "        raise ValueError(f\"Model stage must be '{PROD_STAGE}', got: {model.tags.get('stage')}\")\n",
    "\n",
    "    # We register the output folder/data-asset reference (Azure ML v2), so do not\n",
    "    # require a direct .onnx file path here.\n",
    "    if not model.path:\n",
    "        raise ValueError(f\"Invalid model path: {model.path}\")\n",
    "\n",
    "\n",
    "validate_registered_model(registered_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
