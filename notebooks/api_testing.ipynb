{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# API Testing Notebook - Entity Extraction from Real Files\n",
        "\n",
        "This notebook tests the Resume NER API with actual test files and visualizes extracted entities.\n",
        "\n",
        "**Note:** For comprehensive error handling and edge case testing, see `tests/integration/api/test_api_local_server.py`.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before running this notebook, start the API server. See [`docs/api_testing_prerequisites.md`](../docs/api_testing_prerequisites.md) for detailed setup instructions.\n",
        "\n",
        "**Quick start (Terminal - Recommended):**\n",
        "```bash\n",
        "# Activate environment\n",
        "source /opt/conda/etc/profile.d/conda.sh\n",
        "conda activate resume-ner-training\n",
        "\n",
        "# Find latest ONNX model\n",
        "ONNX_MODEL=$(find outputs/conversion -name \"model.onnx\" -type f | head -1)\n",
        "\n",
        "# Extract spec hash and find matching checkpoint\n",
        "SPEC_HASH=$(echo \"$ONNX_MODEL\" | sed -n 's|.*\\(spec-[a-f0-9]\\{8\\}_exec-[a-f0-9]\\{8\\}\\).*|\\1|p')\n",
        "CHECKPOINT_DIR=$(find outputs/final_training -path \"*${SPEC_HASH}*/checkpoint\" -type d | head -1)\n",
        "\n",
        "# Set PYTHONPATH and start server (PYTHONPATH required for infrastructure imports)\n",
        "export PYTHONPATH=\"$(pwd)/src:$(pwd)\"\n",
        "python -m src.deployment.api.cli.run_api \\\n",
        "  --onnx-model \"$ONNX_MODEL\" \\\n",
        "  --checkpoint \"$CHECKPOINT_DIR\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install OCR dependencies for image processing\n",
        "# Note: EasyOCR is the default OCR extractor. If you prefer pytesseract, install that instead.\n",
        "%pip install easyocr pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Any, Optional\n",
        "from IPython.display import display, Markdown, JSON\n",
        "import pandas as pd\n",
        "\n",
        "# Setup Python paths (required for infrastructure and src imports)\n",
        "# Must be done before importing from src\n",
        "current_dir = Path.cwd()\n",
        "if current_dir.name == \"notebooks\":\n",
        "    project_root = current_dir.parent\n",
        "else:\n",
        "    project_root = current_dir\n",
        "\n",
        "src_path = project_root / \"src\"\n",
        "if str(src_path) not in sys.path:\n",
        "    sys.path.insert(0, str(src_path))\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Import test fixtures\n",
        "from tests.test_data.fixtures import (\n",
        "    get_text_fixture,\n",
        "    get_file_fixture,\n",
        "    get_batch_text_fixture,\n",
        "    get_batch_file_fixture,\n",
        "    TEXT_FIXTURES,\n",
        "    FILE_FIXTURES\n",
        ")\n",
        "\n",
        "# Import API utilities\n",
        "from src.deployment.api.tools.model_finder import (\n",
        "    find_latest_onnx_model,\n",
        "    find_matching_checkpoint,\n",
        "    find_model_pair,\n",
        "    list_available_models,\n",
        ")\n",
        "from src.deployment.api.tools.server_launcher import (\n",
        "    check_server_health,\n",
        "    get_server_info,\n",
        "    start_api_server,\n",
        "    wait_for_server,\n",
        ")\n",
        "from src.deployment.api.tools.notebook_helpers import (\n",
        "    display_entities,\n",
        "    make_request,\n",
        ")\n",
        "from src.deployment.api.tools.notebook_config import (\n",
        "    NotebookConfig,\n",
        "    get_default_config,\n",
        ")\n",
        "\n",
        "# Helper functions for model discovery and server management\n",
        "def find_and_display_models(outputs_dir: Optional[Path] = None, verbose: bool = False) -> tuple[Optional[Path], Optional[Path]]:\n",
        "    \"\"\"\n",
        "    Find and display available models.\n",
        "    \n",
        "    Args:\n",
        "        outputs_dir: Root outputs directory (default: project_root / \"outputs\")\n",
        "        verbose: If True, show detailed listing of all models\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (onnx_path, checkpoint_path), either may be None if not found\n",
        "    \"\"\"\n",
        "    if outputs_dir is None:\n",
        "        outputs_dir = project_root / \"outputs\"\n",
        "    \n",
        "    # List all available models\n",
        "    all_models = list_available_models(outputs_dir)\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"Found {len(all_models['onnx_models'])} ONNX model(s), {len(all_models['checkpoints'])} checkpoint(s)\")\n",
        "    \n",
        "    # Try to find matching pair\n",
        "    onnx_path, checkpoint_path = find_model_pair(outputs_dir)\n",
        "    \n",
        "    if onnx_path and checkpoint_path:\n",
        "        if verbose:\n",
        "            print(f\"✓ ONNX: {onnx_path}\\n  Checkpoint: {checkpoint_path}\")\n",
        "        return onnx_path, checkpoint_path\n",
        "    else:\n",
        "        if verbose:\n",
        "            if not onnx_path:\n",
        "                print(\"✗ No ONNX models found\")\n",
        "            if not checkpoint_path:\n",
        "                print(\"✗ No matching checkpoint found\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def start_api_server_interactive(\n",
        "    onnx_path: Optional[Path] = None,\n",
        "    checkpoint_path: Optional[Path] = None,\n",
        "    outputs_dir: Optional[Path] = None,\n",
        "    host: str = \"0.0.0.0\",\n",
        "    port: int = 8000,\n",
        "    background: bool = True,\n",
        "    verbose: bool = True,\n",
        ") -> Optional[Any]:\n",
        "    \"\"\"\n",
        "    Interactive function to start API server.\n",
        "    \n",
        "    Args:\n",
        "        onnx_path: Path to ONNX model (if None, will try to find)\n",
        "        checkpoint_path: Path to checkpoint (if None, will try to find)\n",
        "        outputs_dir: Root outputs directory (default: project_root / \"outputs\")\n",
        "        host: Server host (default: \"0.0.0.0\")\n",
        "        port: Server port (default: 8000)\n",
        "        background: Run in background (default: True)\n",
        "        verbose: If True, print status messages\n",
        "    \n",
        "    Returns:\n",
        "        subprocess.Popen object if background=True, None otherwise\n",
        "    \"\"\"\n",
        "    if outputs_dir is None:\n",
        "        outputs_dir = project_root / \"outputs\"\n",
        "    \n",
        "    # Find paths if not provided\n",
        "    if not onnx_path or not checkpoint_path:\n",
        "        if verbose:\n",
        "            print(\"Finding model pair...\")\n",
        "        found_onnx, found_checkpoint = find_model_pair(outputs_dir)\n",
        "        if not found_onnx or not found_checkpoint:\n",
        "            if verbose:\n",
        "                print(\"✗ Could not find model pair\")\n",
        "            return None\n",
        "        onnx_path = found_onnx\n",
        "        checkpoint_path = found_checkpoint\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"Starting server on {host}:{port}...\")\n",
        "    \n",
        "    try:\n",
        "        process = start_api_server(\n",
        "            onnx_path=onnx_path,\n",
        "            checkpoint_dir=checkpoint_path,\n",
        "            host=host,\n",
        "            port=port,\n",
        "            background=background,\n",
        "        )\n",
        "        \n",
        "        if background and process:\n",
        "            if verbose:\n",
        "                print(f\"✓ Server started (PID: {process.pid})\")\n",
        "            if wait_for_server(timeout=30):\n",
        "                if verbose:\n",
        "                    print(\"✓ Server ready\")\n",
        "            elif verbose:\n",
        "                print(\"⚠ Server may still be starting\")\n",
        "        elif verbose:\n",
        "            print(\"✓ Server started in foreground\")\n",
        "        \n",
        "        return process\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"✗ Failed to start server: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def verify_server_running(base_url: str = \"http://localhost:8000\", verbose: bool = True) -> bool:\n",
        "    \"\"\"\n",
        "    Verify server is running and display status.\n",
        "    \n",
        "    Args:\n",
        "        base_url: Base URL of the server (default: \"http://localhost:8000\")\n",
        "        verbose: If True, print status messages\n",
        "    \n",
        "    Returns:\n",
        "        True if server is healthy, False otherwise\n",
        "    \"\"\"\n",
        "    is_healthy = check_server_health(base_url)\n",
        "    \n",
        "    if is_healthy:\n",
        "        if verbose:\n",
        "            print(\"✓ Server is healthy\")\n",
        "        return True\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"✗ Server not running on {base_url}\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# API Configuration\n",
        "config: NotebookConfig = get_default_config()\n",
        "API_BASE_URL = config[\"api_base_url\"]\n",
        "API_TIMEOUT = config[\"api_timeout\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a wrapper that uses config values (for backward compatibility with existing notebook cells)\n",
        "from functools import partial\n",
        "make_request = partial(make_request, base_url=API_BASE_URL, timeout=API_TIMEOUT)\n",
        "\n",
        "# Check server health using helper function\n",
        "if not verify_server_running(API_BASE_URL):\n",
        "    print(\"⚠️  Server not running. Use start_api_server_interactive() to start it.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# display_entities is now imported from src.deployment.api.tools.notebook_helpers\n",
        "# No need to redefine it here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Single Text Prediction\n",
        "\n",
        "Test entity extraction from individual text inputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Test with Sample Text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with text_1\n",
        "text_1 = get_text_fixture(\"text_1\")\n",
        "result = make_request(\"POST\", \"/predict\", json={\"text\": text_1})\n",
        "if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "    entities = result[\"data\"].get(\"entities\", [])\n",
        "    display_entities(entities, source_text=text_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with text_2 (contains email, phone, location)\n",
        "text_2 = get_text_fixture(\"text_2\")\n",
        "result = make_request(\"POST\", \"/predict\", json={\"text\": text_2})\n",
        "if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "    entities = result[\"data\"].get(\"entities\", [])\n",
        "    display_entities(entities, source_text=text_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with text_special (contains email, phone, URL)\n",
        "text_special = get_text_fixture(\"text_special\")\n",
        "result = make_request(\"POST\", \"/predict\", json={\"text\": text_special})\n",
        "if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "    entities = result[\"data\"].get(\"entities\", [])\n",
        "    display_entities(entities, source_text=text_special)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Single PDF File Prediction\n",
        "\n",
        "Test entity extraction from PDF files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with PDF file\n",
        "file_path = get_file_fixture(\"file_1\", \"pdf\")\n",
        "try:\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        file_content = f.read()\n",
        "    files = {\"file\": (file_path.name, file_content, \"application/pdf\")}\n",
        "    result = make_request(\"POST\", \"/predict/file\", files=files)\n",
        "    \n",
        "    if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "        extracted_text = result[\"data\"].get(\"extracted_text\", \"\")\n",
        "        entities = result[\"data\"].get(\"entities\", [])\n",
        "        display_entities(entities, source_text=extracted_text)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with larger PDF file\n",
        "file_path = get_file_fixture(\"file_resume_1\", \"pdf\")\n",
        "try:\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        file_content = f.read()\n",
        "    files = {\"file\": (file_path.name, file_content, \"application/pdf\")}\n",
        "    result = make_request(\"POST\", \"/predict/file\", files=files)\n",
        "    \n",
        "    if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "        extracted_text = result[\"data\"].get(\"extracted_text\", \"\")\n",
        "        entities = result[\"data\"].get(\"entities\", [])\n",
        "        display_entities(entities, source_text=extracted_text)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Single Image File Prediction\n",
        "\n",
        "Test entity extraction from image files (PNG) using OCR.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with PNG image file\n",
        "file_path = get_file_fixture(\"file_1\", \"png\")\n",
        "try:\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        file_content = f.read()\n",
        "    files = {\"file\": (file_path.name, file_content, \"image/png\")}\n",
        "    result = make_request(\"POST\", \"/predict/file\", files=files)\n",
        "    \n",
        "    if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "        extracted_text = result[\"data\"].get(\"extracted_text\", \"\")\n",
        "        entities = result[\"data\"].get(\"entities\", [])\n",
        "        if extracted_text:\n",
        "            display_entities(entities, source_text=extracted_text)\n",
        "    elif result.get(\"status_code\") == 400:\n",
        "        error_detail = result.get(\"data\", {}).get(\"detail\", \"\")\n",
        "        if \"EasyOCR\" in error_detail or \"pytesseract\" in error_detail or \"Pillow\" in error_detail:\n",
        "            print(f\"⚠️  OCR dependencies not installed\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Batch Text Prediction\n",
        "\n",
        "Test entity extraction from multiple text inputs in a single batch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Batch with Multiple Texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test batch with multiple texts\n",
        "texts = get_batch_text_fixture(\"batch_text_small\")\n",
        "result = make_request(\"POST\", \"/predict/batch\", json={\"texts\": texts})\n",
        "\n",
        "if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "    predictions = result[\"data\"].get(\"predictions\", [])\n",
        "    for i, (text, prediction) in enumerate(zip(texts, predictions), 1):\n",
        "        entities = prediction.get(\"entities\", [])\n",
        "        display_entities(entities, source_text=text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Batch File Prediction\n",
        "\n",
        "Test entity extraction from multiple files in a single batch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Batch with PDF Files Only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test batch with PDF files\n",
        "file_paths = get_batch_file_fixture(\"batch_file_small\", \"pdf\")\n",
        "try:\n",
        "    files_list = []\n",
        "    for file_path in file_paths:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            file_content = f.read()\n",
        "        files_list.append((\"files\", (file_path.name, file_content, \"application/pdf\")))\n",
        "    \n",
        "    result = make_request(\"POST\", \"/predict/file/batch\", files=files_list)\n",
        "    \n",
        "    if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "        predictions = result[\"data\"].get(\"predictions\", [])\n",
        "        for i, (file_path, prediction) in enumerate(zip(file_paths, predictions), 1):\n",
        "            extracted_text = prediction.get(\"extracted_text\", \"\")\n",
        "            entities = prediction.get(\"entities\", [])\n",
        "            if extracted_text:\n",
        "                display_entities(entities, source_text=extracted_text)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Mixed Batch Prediction\n",
        "\n",
        "Test entity extraction from a batch containing a mixture of texts, PDF files, and images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test mixed content (texts + PDFs + images)\n",
        "# Note: API endpoints are separate, so we process them separately and combine results\n",
        "\n",
        "texts = [get_text_fixture(\"text_1\"), get_text_fixture(\"text_2\")]\n",
        "pdf_files = [get_file_fixture(\"file_1\", \"pdf\")]\n",
        "png_files = [get_file_fixture(\"file_1\", \"png\")]\n",
        "\n",
        "all_results = []\n",
        "\n",
        "# Process texts\n",
        "text_result = make_request(\"POST\", \"/predict/batch\", json={\"texts\": texts})\n",
        "if text_result.get(\"status_code\") == 200:\n",
        "    all_results.extend([\n",
        "        {\"type\": \"text\", \"content\": text, \"result\": pred}\n",
        "        for text, pred in zip(texts, text_result[\"data\"].get(\"predictions\", []))\n",
        "    ])\n",
        "\n",
        "# Process PDF files\n",
        "try:\n",
        "    files_list = []\n",
        "    for file_path in pdf_files:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            file_content = f.read()\n",
        "        files_list.append((\"files\", (file_path.name, file_content, \"application/pdf\")))\n",
        "    \n",
        "    pdf_result = make_request(\"POST\", \"/predict/file/batch\", files=files_list)\n",
        "    if pdf_result.get(\"status_code\") == 200:\n",
        "        all_results.extend([\n",
        "            {\"type\": \"pdf\", \"file\": str(fp), \"result\": pred}\n",
        "            for fp, pred in zip(pdf_files, pdf_result[\"data\"].get(\"predictions\", []))\n",
        "        ])\n",
        "except Exception as e:\n",
        "    print(f\"Error processing PDFs: {e}\")\n",
        "\n",
        "# Process image files\n",
        "try:\n",
        "    files_list = []\n",
        "    for file_path in png_files:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            file_content = f.read()\n",
        "        files_list.append((\"files\", (file_path.name, file_content, \"image/png\")))\n",
        "    \n",
        "    png_result = make_request(\"POST\", \"/predict/file/batch\", files=files_list)\n",
        "    if png_result.get(\"status_code\") == 200:\n",
        "        all_results.extend([\n",
        "            {\"type\": \"image\", \"file\": str(fp), \"result\": pred}\n",
        "            for fp, pred in zip(png_files, png_result[\"data\"].get(\"predictions\", []))\n",
        "        ])\n",
        "    elif png_result.get(\"status_code\") == 400:\n",
        "        error_detail = png_result.get(\"data\", {}).get(\"detail\", \"\")\n",
        "        if \"EasyOCR\" in error_detail or \"pytesseract\" in error_detail:\n",
        "            print(f\"⚠️  OCR dependencies not installed\")\n",
        "except Exception as e:\n",
        "    print(f\"Error processing images: {e}\")\n",
        "\n",
        "# Display combined results\n",
        "for item in all_results:\n",
        "    result = item[\"result\"]\n",
        "    entities = result.get(\"entities\", [])\n",
        "    \n",
        "    if item[\"type\"] == \"text\":\n",
        "        display_entities(entities, source_text=item[\"content\"])\n",
        "    else:\n",
        "        extracted_text = result.get(\"extracted_text\", \"\")\n",
        "        if extracted_text:\n",
        "            display_entities(entities, source_text=extracted_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Cross-Format Consistency Test\n",
        "\n",
        "Test the same content across different formats (text, PDF, PNG) to verify entity extraction consistency and compare performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the same content in different formats\n",
        "sample_text = \"John Doe is a software engineer at Google. Email: john.doe@example.com. Phone: +1-555-123-4567. Location: Seattle, WA.\"\n",
        "\n",
        "pdf_file = get_file_fixture(\"file_resume_1\", \"pdf\")\n",
        "png_file = get_file_fixture(\"file_resume_1\", \"png\")\n",
        "\n",
        "results = []\n",
        "\n",
        "# Test 1: Text format\n",
        "text_result = make_request(\"POST\", \"/predict\", json={\"text\": sample_text})\n",
        "if text_result.get(\"status_code\") == 200:\n",
        "    text_data = text_result[\"data\"]\n",
        "    results.append({\n",
        "        \"format\": \"Text\",\n",
        "        \"input\": sample_text,\n",
        "        \"extracted_text\": sample_text,\n",
        "        \"entities\": text_data.get(\"entities\", []),\n",
        "        \"processing_time_ms\": text_data.get(\"processing_time_ms\", 0),\n",
        "        \"num_entities\": len(text_data.get(\"entities\", []))\n",
        "    })\n",
        "    display_entities(text_data.get(\"entities\", []), source_text=sample_text)\n",
        "\n",
        "# Test 2: PDF format\n",
        "try:\n",
        "    with open(pdf_file, \"rb\") as f:\n",
        "        pdf_content = f.read()\n",
        "    pdf_files = {\"file\": (pdf_file.name, pdf_content, \"application/pdf\")}\n",
        "    pdf_result = make_request(\"POST\", \"/predict/file\", files=pdf_files)\n",
        "    \n",
        "    if pdf_result.get(\"status_code\") == 200:\n",
        "        pdf_data = pdf_result[\"data\"]\n",
        "        extracted_text = pdf_data.get(\"extracted_text\", \"\")\n",
        "        results.append({\n",
        "            \"format\": \"PDF\",\n",
        "            \"input\": str(pdf_file),\n",
        "            \"extracted_text\": extracted_text,\n",
        "            \"entities\": pdf_data.get(\"entities\", []),\n",
        "            \"processing_time_ms\": pdf_data.get(\"processing_time_ms\", 0),\n",
        "            \"num_entities\": len(pdf_data.get(\"entities\", []))\n",
        "        })\n",
        "        display_entities(pdf_data.get(\"entities\", []), source_text=extracted_text)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading PDF: {e}\")\n",
        "\n",
        "# Test 3: PNG format\n",
        "try:\n",
        "    with open(png_file, \"rb\") as f:\n",
        "        png_content = f.read()\n",
        "    png_files = {\"file\": (png_file.name, png_content, \"image/png\")}\n",
        "    png_result = make_request(\"POST\", \"/predict/file\", files=png_files)\n",
        "    \n",
        "    if png_result.get(\"status_code\") == 200:\n",
        "        png_data = png_result[\"data\"]\n",
        "        extracted_text = png_data.get(\"extracted_text\", \"\")\n",
        "        results.append({\n",
        "            \"format\": \"PNG\",\n",
        "            \"input\": str(png_file),\n",
        "            \"extracted_text\": extracted_text,\n",
        "            \"entities\": png_data.get(\"entities\", []),\n",
        "            \"processing_time_ms\": png_data.get(\"processing_time_ms\", 0),\n",
        "            \"num_entities\": len(png_data.get(\"entities\", []))\n",
        "        })\n",
        "        display_entities(png_data.get(\"entities\", []), source_text=extracted_text)\n",
        "    elif png_result.get(\"status_code\") == 400:\n",
        "        error_detail = png_result.get(\"data\", {}).get(\"detail\", \"\")\n",
        "        if \"EasyOCR\" in error_detail or \"pytesseract\" in error_detail or \"Pillow\" in error_detail:\n",
        "            print(f\"⚠️  OCR dependencies not installed\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading PNG: {e}\")\n",
        "\n",
        "# Comparison Summary\n",
        "if len(results) >= 2:\n",
        "    comparison_data = []\n",
        "    for r in results:\n",
        "        comparison_data.append({\n",
        "            \"Format\": r[\"format\"],\n",
        "            \"Processing Time (ms)\": f\"{r['processing_time_ms']:.1f}\",\n",
        "            \"Entities Extracted\": r[\"num_entities\"],\n",
        "            \"Text Length\": len(r[\"extracted_text\"])\n",
        "        })\n",
        "    \n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "    display(comparison_df)\n",
        "    \n",
        "    # Entity consistency analysis\n",
        "    if len(results) == 3:\n",
        "        text_entities = set((e.get(\"text\", \"\"), e.get(\"label\", \"\")) for e in results[0][\"entities\"])\n",
        "        pdf_entities = set((e.get(\"text\", \"\"), e.get(\"label\", \"\")) for e in results[1][\"entities\"])\n",
        "        png_entities = set((e.get(\"text\", \"\"), e.get(\"label\", \"\")) for e in results[2][\"entities\"])\n",
        "        \n",
        "        common_all = text_entities & pdf_entities & png_entities\n",
        "        text_pdf_only = (text_entities & pdf_entities) - png_entities\n",
        "        text_png_only = (text_entities & png_entities) - pdf_entities\n",
        "        pdf_png_only = (pdf_entities & png_entities) - text_entities\n",
        "        \n",
        "        if common_all:\n",
        "            print(f\"\\nEntities in all formats ({len(common_all)}):\")\n",
        "            for entity in sorted(common_all):\n",
        "                print(f\"  - '{entity[0]}' ({entity[1]})\")\n",
        "        \n",
        "        if text_pdf_only or text_png_only or pdf_png_only:\n",
        "            print(f\"\\nFormat-specific entities:\")\n",
        "            if text_pdf_only:\n",
        "                print(f\"  Text & PDF only ({len(text_pdf_only)}): {', '.join([e[0] for e in sorted(text_pdf_only)])}\")\n",
        "            if text_png_only:\n",
        "                print(f\"  Text & PNG only ({len(text_png_only)}): {', '.join([e[0] for e in sorted(text_png_only)])}\")\n",
        "            if pdf_png_only:\n",
        "                print(f\"  PDF & PNG only ({len(pdf_png_only)}): {', '.join([e[0] for e in sorted(pdf_png_only)])}\")\n",
        "        \n",
        "        # Performance comparison\n",
        "        times = [r[\"processing_time_ms\"] for r in results]\n",
        "        formats = [r[\"format\"] for r in results]\n",
        "        min_time = min(times)\n",
        "        max_time = max(times)\n",
        "        \n",
        "        print(f\"\\nPerformance: {formats[times.index(min_time)]} fastest ({min_time:.1f}ms), {formats[times.index(max_time)]} slowest ({max_time:.1f}ms)\")\n",
        "        \n",
        "        text_time = results[0][\"processing_time_ms\"]\n",
        "        png_time = results[2][\"processing_time_ms\"]\n",
        "        if png_time > text_time:\n",
        "            ocr_overhead = png_time - text_time\n",
        "            print(f\"OCR overhead: {ocr_overhead:.1f}ms ({ocr_overhead / text_time * 100:.1f}%)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "resume-ner-training",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
