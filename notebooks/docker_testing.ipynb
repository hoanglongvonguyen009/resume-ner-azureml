{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Testing Notebook - API Testing in Docker Containers\n",
    "\n",
    "This notebook tests the Resume NER API running in Docker containers, including image building, container lifecycle management, API functionality, Docker Compose, volume mounts, and environment variables.\n",
    "\n",
    "**Note:** For comprehensive error handling and edge case testing, see `tests/integration/api/test_api_local_server.py`.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure:\n",
    "\n",
    "1. **Docker and Docker Compose installed and running**\n",
    "   ```bash\n",
    "   docker --version\n",
    "   docker-compose --version\n",
    "   ```\n",
    "\n",
    "2. **Access to trained models** (ONNX model and checkpoint directory)\n",
    "   - Models should be in `outputs/conversion/` and `outputs/final_training/`\n",
    "   - See [`docs/docker_build.md`](../docs/docker_build.md) for detailed setup instructions\n",
    "\n",
    "3. **Docker Python library installed**\n",
    "   ```bash\n",
    "   pip install docker\n",
    "   ```\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "**Option 1: Build and run manually (Terminal)**\n",
    "```bash\n",
    "# Build Docker image\n",
    "docker build -t resume-ner-api:latest .\n",
    "\n",
    "# Find models\n",
    "ONNX_MODEL=$(find outputs/conversion -name \"model.onnx\" -type f | head -1)\n",
    "SPEC_HASH=$(echo \"$ONNX_MODEL\" | sed -n 's|.*\\(spec-[a-f0-9]\\{8\\}_exec-[a-f0-9]\\{8\\}\\).*|\\1|p')\n",
    "CHECKPOINT_DIR=$(find outputs/final_training -path \"*${SPEC_HASH}*/checkpoint\" -type d | head -1)\n",
    "\n",
    "# Run container\n",
    "docker run -d \\\n",
    "  --name resume-ner-api \\\n",
    "  -p 8000:8000 \\\n",
    "  -v $(pwd)/outputs:/app/outputs \\\n",
    "  resume-ner-api:latest \\\n",
    "  conda run -n resume-ner-training python -m src.deployment.api.cli.run_api \\\n",
    "    --onnx-model \"$ONNX_MODEL\" \\\n",
    "    --checkpoint \"$CHECKPOINT_DIR\" \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --port 8000\n",
    "```\n",
    "\n",
    "**Option 2: Use this notebook**\n",
    "Run the cells below to build, start, and test the Docker container programmatically.\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "- **Container won't start**: Check logs with `docker logs resume-ner-api`\n",
    "- **Models not found**: Verify volume mount `-v $(pwd)/outputs:/app/outputs`\n",
    "- **Port already in use**: Change port mapping `-p 8001:8000` or stop existing container\n",
    "- **Permission issues**: Check file permissions on mounted volumes\n",
    "\n",
    "See [`docs/docker_build.md`](../docs/docker_build.md) for more troubleshooting tips.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Docker Python library if not already installed\n",
    "%pip install docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "import time\n",
    "import requests\n",
    "import docker\n",
    "from docker.errors import DockerException, ImageNotFound\n",
    "\n",
    "# Setup Python paths (required for infrastructure and src imports)\n",
    "# Must be done before importing from src\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"notebooks\":\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import test fixtures\n",
    "from tests.test_data.fixtures import (\n",
    "    get_text_fixture,\n",
    "    get_file_fixture,\n",
    "    get_batch_text_fixture,\n",
    "    get_batch_file_fixture,\n",
    "    TEXT_FIXTURES,\n",
    "    FILE_FIXTURES\n",
    ")\n",
    "\n",
    "# Import API utilities\n",
    "from src.deployment.api.tools.model_finder import (\n",
    "    find_model_pair,\n",
    ")\n",
    "from src.deployment.api.tools.notebook_helpers import (\n",
    "    display_entities,\n",
    "    make_request,\n",
    ")\n",
    "from src.deployment.api.tools.notebook_config import (\n",
    "    NotebookConfig,\n",
    "    get_default_config,\n",
    ")\n",
    "\n",
    "# Initialize Docker client\n",
    "try:\n",
    "    docker_client = docker.from_env()\n",
    "    print(\"✓ Docker client initialized\")\n",
    "except DockerException as e:\n",
    "    print(f\"✗ Failed to connect to Docker: {e}\")\n",
    "    print(\"Make sure Docker is running and accessible\")\n",
    "    docker_client = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docker Configuration\n",
    "DOCKER_IMAGE_NAME = \"resume-ner-api\"\n",
    "DOCKER_IMAGE_TAG = \"latest\"\n",
    "DOCKER_CONTAINER_NAME = \"resume-ner-api\"\n",
    "DOCKER_HOST_PORT = 8000\n",
    "DOCKER_CONTAINER_PORT = 8000\n",
    "\n",
    "# API Configuration\n",
    "config: NotebookConfig = get_default_config()\n",
    "config[\"api_base_url\"] = f\"http://localhost:{DOCKER_HOST_PORT}\"\n",
    "API_BASE_URL = config[\"api_base_url\"]\n",
    "API_TIMEOUT = config[\"api_timeout\"]\n",
    "\n",
    "# Volume mounts (relative to project root)\n",
    "OUTPUTS_DIR = project_root / \"outputs\"\n",
    "\n",
    "print(f\"Docker Image: {DOCKER_IMAGE_NAME}:{DOCKER_IMAGE_TAG}\")\n",
    "print(f\"Container Name: {DOCKER_CONTAINER_NAME}\")\n",
    "print(f\"Port Mapping: {DOCKER_HOST_PORT}:{DOCKER_CONTAINER_PORT}\")\n",
    "print(f\"API Base URL: {API_BASE_URL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for Docker operations\n",
    "def check_port_available(host_port: int, verbose: bool = True) -> Tuple[bool, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Check if a port is available by looking for containers using it.\n",
    "    \n",
    "    Args:\n",
    "        host_port: Port to check\n",
    "        verbose: If True, print status messages\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (is_available, conflicting_container_name)\n",
    "    \"\"\"\n",
    "    if docker_client is None:\n",
    "        return False, None\n",
    "    \n",
    "    try:\n",
    "        # Get all containers (running and stopped)\n",
    "        all_containers = docker_client.containers.list(all=True)\n",
    "        \n",
    "        for container in all_containers:\n",
    "            # Check port mappings\n",
    "            ports = container.attrs.get('NetworkSettings', {}).get('Ports', {})\n",
    "            for container_port, host_bindings in ports.items():\n",
    "                if host_bindings:\n",
    "                    for binding in host_bindings:\n",
    "                        if binding.get('HostPort') == str(host_port):\n",
    "                            if verbose:\n",
    "                                print(f\"⚠ Port {host_port} is already in use by container: {container.name}\")\n",
    "                            return False, container.name\n",
    "        \n",
    "        return True, None\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error checking port availability: {e}\")\n",
    "        return False, None\n",
    "\n",
    "\n",
    "def start_docker_container(\n",
    "    image_name: str,\n",
    "    image_tag: str = \"latest\",\n",
    "    container_name: str = \"resume-ner-api\",\n",
    "    host_port: int = 8000,\n",
    "    container_port: int = 8000,\n",
    "    volumes: Optional[Dict[str, Dict[str, str]]] = None,\n",
    "    environment: Optional[Dict[str, str]] = None,\n",
    "    command: Optional[List[str]] = None,\n",
    "    verbose: bool = True,\n",
    "    force_port: bool = False,\n",
    ") -> Optional[docker.models.containers.Container]:\n",
    "    \"\"\"\n",
    "    Start Docker container with specified configuration.\n",
    "    \n",
    "    Args:\n",
    "        image_name: Name of the Docker image\n",
    "        image_tag: Tag of the image (default: \"latest\")\n",
    "        container_name: Name for the container\n",
    "        host_port: Host port to map\n",
    "        container_port: Container port to map\n",
    "        volumes: Volume mounts dictionary\n",
    "        environment: Environment variables dictionary\n",
    "        command: Command to run in container\n",
    "        verbose: If True, print status messages\n",
    "        force_port: If True, stop conflicting containers on the port\n",
    "    \n",
    "    Returns:\n",
    "        Container object if successful, None otherwise\n",
    "    \"\"\"\n",
    "    if docker_client is None:\n",
    "        print(\"✗ Docker client not available\")\n",
    "        return None\n",
    "    \n",
    "    image_tag_full = f\"{image_name}:{image_tag}\"\n",
    "    \n",
    "    # Check for port conflicts\n",
    "    port_available, conflicting_container = check_port_available(host_port, verbose=verbose)\n",
    "    if not port_available and conflicting_container:\n",
    "        if force_port:\n",
    "            if verbose:\n",
    "                print(f\"Stopping conflicting container: {conflicting_container}\")\n",
    "            try:\n",
    "                conflict_container = docker_client.containers.get(conflicting_container)\n",
    "                if conflict_container.status == \"running\":\n",
    "                    conflict_container.stop()\n",
    "                conflict_container.remove()\n",
    "                if verbose:\n",
    "                    print(f\"✓ Removed conflicting container: {conflicting_container}\")\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"✗ Failed to remove conflicting container: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"✗ Port {host_port} is already in use by container: {conflicting_container}\")\n",
    "                print(f\"  Stop the conflicting container first, or set force_port=True\")\n",
    "            return None\n",
    "    \n",
    "    # Stop and remove existing container if it exists\n",
    "    try:\n",
    "        existing_container = docker_client.containers.get(container_name)\n",
    "        if existing_container.status == \"running\":\n",
    "            if verbose:\n",
    "                print(f\"Stopping existing container: {container_name}\")\n",
    "            existing_container.stop()\n",
    "        if verbose:\n",
    "            print(f\"Removing existing container: {container_name}\")\n",
    "        existing_container.remove()\n",
    "    except docker.errors.NotFound:\n",
    "        pass  # Container doesn't exist, which is fine\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Starting container: {container_name}\")\n",
    "        print(f\"  Image: {image_tag_full}\")\n",
    "        print(f\"  Port: {host_port}:{container_port}\")\n",
    "    \n",
    "    try:\n",
    "        container = docker_client.containers.run(\n",
    "            image_tag_full,\n",
    "            name=container_name,\n",
    "            ports={f\"{container_port}/tcp\": host_port},\n",
    "            volumes=volumes or {},\n",
    "            environment=environment or {},\n",
    "            command=command,\n",
    "            detach=True,\n",
    "            remove=False,\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"✓ Container started: {container_name}\")\n",
    "            print(f\"  Container ID: {container.id[:12]}\")\n",
    "        \n",
    "        return container\n",
    "    except DockerException as e:\n",
    "        if verbose:\n",
    "            print(f\"✗ Failed to start container: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def stop_docker_container(\n",
    "    container_name: str,\n",
    "    remove: bool = True,\n",
    "    verbose: bool = True,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Stop and optionally remove Docker container.\n",
    "    \n",
    "    Args:\n",
    "        container_name: Name of the container\n",
    "        remove: If True, remove container after stopping\n",
    "        verbose: If True, print status messages\n",
    "    \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    if docker_client is None:\n",
    "        print(\"✗ Docker client not available\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        container = docker_client.containers.get(container_name)\n",
    "        \n",
    "        if container.status == \"running\":\n",
    "            if verbose:\n",
    "                print(f\"Stopping container: {container_name}\")\n",
    "            container.stop()\n",
    "        \n",
    "        if remove:\n",
    "            if verbose:\n",
    "                print(f\"Removing container: {container_name}\")\n",
    "            container.remove()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"✓ Container stopped and removed: {container_name}\")\n",
    "        return True\n",
    "    except docker.errors.NotFound:\n",
    "        if verbose:\n",
    "            print(f\"Container not found: {container_name}\")\n",
    "        return False\n",
    "    except DockerException as e:\n",
    "        if verbose:\n",
    "            print(f\"✗ Failed to stop container: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_container_health(\n",
    "    container_name: str,\n",
    "    health_endpoint: str = \"/health\",\n",
    "    base_url: Optional[str] = None,\n",
    "    verbose: bool = True,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Check container health via API endpoint.\n",
    "    \n",
    "    Args:\n",
    "        container_name: Name of the container\n",
    "        health_endpoint: Health check endpoint path\n",
    "        base_url: Base URL for API (default: uses API_BASE_URL)\n",
    "        verbose: If True, print status messages\n",
    "    \n",
    "    Returns:\n",
    "        True if healthy, False otherwise\n",
    "    \"\"\"\n",
    "    if base_url is None:\n",
    "        base_url = API_BASE_URL\n",
    "    \n",
    "    url = f\"{base_url}{health_endpoint}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        is_healthy = response.status_code == 200\n",
    "        \n",
    "        if verbose:\n",
    "            if is_healthy:\n",
    "                print(f\"✓ Container is healthy: {container_name}\")\n",
    "            else:\n",
    "                print(f\"✗ Container health check failed: {container_name} (status: {response.status_code})\")\n",
    "        \n",
    "        return is_healthy\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        if verbose:\n",
    "            print(f\"✗ Health check failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_container_logs(\n",
    "    container_name: str,\n",
    "    tail: int = 100,\n",
    "    verbose: bool = True,\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Get container logs.\n",
    "    \n",
    "    Args:\n",
    "        container_name: Name of the container\n",
    "        tail: Number of lines to retrieve\n",
    "        verbose: If True, print logs\n",
    "    \n",
    "    Returns:\n",
    "        Logs as string if successful, None otherwise\n",
    "    \"\"\"\n",
    "    if docker_client is None:\n",
    "        print(\"✗ Docker client not available\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        container = docker_client.containers.get(container_name)\n",
    "        logs = container.logs(tail=tail).decode(\"utf-8\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Container logs ({container_name}):\")\n",
    "            print(\"=\" * 60)\n",
    "            print(logs)\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        return logs\n",
    "    except docker.errors.NotFound:\n",
    "        if verbose:\n",
    "            print(f\"Container not found: {container_name}\")\n",
    "        return None\n",
    "    except DockerException as e:\n",
    "        if verbose:\n",
    "            print(f\"✗ Failed to get logs: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Create a wrapper that uses config values (for backward compatibility with existing notebook cells)\n",
    "from functools import partial\n",
    "make_request = partial(make_request, base_url=API_BASE_URL, timeout=API_TIMEOUT)\n",
    "\n",
    "# display_entities is now imported from src.deployment.api.tools.notebook_helpers\n",
    "# No need to redefine it here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Docker Image Verification\n",
    "\n",
    "Check if the Docker image exists and verify its details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate Dockerfile exists\n",
    "dockerfile_path = project_root / \"Dockerfile\"\n",
    "\n",
    "if dockerfile_path.exists():\n",
    "    print(f\"✓ Dockerfile found: {dockerfile_path}\")\n",
    "    # Read and display first few lines\n",
    "    with open(dockerfile_path) as f:\n",
    "        lines = f.readlines()[:10]\n",
    "        print(\"\\nFirst 10 lines of Dockerfile:\")\n",
    "        for i, line in enumerate(lines, 1):\n",
    "            print(f\"{i:2}: {line.rstrip()}\")\n",
    "else:\n",
    "    print(f\"✗ Dockerfile not found: {dockerfile_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Docker image exists\n",
    "image_tag = f\"{DOCKER_IMAGE_NAME}:{DOCKER_IMAGE_TAG}\"\n",
    "\n",
    "if docker_client is None:\n",
    "    print(\"✗ Docker client not available\")\n",
    "    docker_image = None\n",
    "else:\n",
    "    try:\n",
    "        docker_image = docker_client.images.get(image_tag)\n",
    "        print(f\"✓ Docker image found: {image_tag}\")\n",
    "        print(f\"\\nImage details:\")\n",
    "        print(f\"  Image ID: {docker_image.id[:12]}\")\n",
    "        print(f\"  Tags: {docker_image.tags}\")\n",
    "        print(f\"  Created: {docker_image.attrs['Created']}\")\n",
    "        print(f\"  Architecture: {docker_image.attrs['Architecture']}\")\n",
    "        print(f\"  OS: {docker_image.attrs['Os']}\")\n",
    "        \n",
    "        # Calculate size\n",
    "        size_bytes = docker_image.attrs['Size']\n",
    "        size_mb = size_bytes / (1024**2)\n",
    "        size_gb = size_bytes / (1024**3)\n",
    "        print(f\"  Size: {size_mb:.2f} MB ({size_gb:.2f} GB)\")\n",
    "    except ImageNotFound:\n",
    "        print(f\"✗ Docker image not found: {image_tag}\")\n",
    "        print(f\"\\nTo build the image, run:\")\n",
    "        print(f\"  docker build -t {image_tag} .\")\n",
    "        print(f\"\\nOr see docs/docker_build.md for detailed instructions.\")\n",
    "        docker_image = None\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error checking for image: {e}\")\n",
    "        docker_image = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect image layers and history\n",
    "if docker_image and docker_client:\n",
    "    try:\n",
    "        image_info = docker_client.images.get(f\"{DOCKER_IMAGE_NAME}:{DOCKER_IMAGE_TAG}\")\n",
    "        \n",
    "        print(f\"\\nImage history (last 5 layers):\")\n",
    "        history = image_info.history()[:5]\n",
    "        for i, layer in enumerate(history, 1):\n",
    "            created_by = layer.get('CreatedBy', 'N/A')\n",
    "            # Truncate long commands\n",
    "            if len(created_by) > 80:\n",
    "                created_by = created_by[:77] + \"...\"\n",
    "            print(f\"  {i}. {created_by}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inspecting image: {e}\")\n",
    "else:\n",
    "    print(\"Image not available for inspection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Container Lifecycle Management\n",
    "\n",
    "Find models and start/stop containers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find models (reuse pattern from api_testing.ipynb)\n",
    "onnx_path, checkpoint_path = find_model_pair(OUTPUTS_DIR)\n",
    "\n",
    "if onnx_path and checkpoint_path:\n",
    "    print(f\"✓ Found model pair:\")\n",
    "    print(f\"  ONNX: {onnx_path}\")\n",
    "    print(f\"  Checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    # Convert to container paths\n",
    "    onnx_container_path = f\"/app/outputs/{onnx_path.relative_to(OUTPUTS_DIR)}\"\n",
    "    checkpoint_container_path = f\"/app/outputs/{checkpoint_path.relative_to(OUTPUTS_DIR)}\"\n",
    "    print(f\"\\nContainer paths:\")\n",
    "    print(f\"  ONNX: {onnx_container_path}\")\n",
    "    print(f\"  Checkpoint: {checkpoint_container_path}\")\n",
    "else:\n",
    "    print(\"✗ Could not find model pair\")\n",
    "    print(\"  Make sure models are in outputs/conversion/ and outputs/final_training/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start container with model paths\n",
    "if onnx_path and checkpoint_path:\n",
    "    # Prepare volume mounts\n",
    "    volumes = {\n",
    "        str(OUTPUTS_DIR): {\"bind\": \"/app/outputs\", \"mode\": \"ro\"}  # Read-only for outputs\n",
    "    }\n",
    "    \n",
    "    # Prepare command to run API server\n",
    "    command = [\n",
    "        \"conda\", \"run\", \"-n\", \"resume-ner-training\",\n",
    "        \"python\", \"-m\", \"src.deployment.api.cli.run_api\",\n",
    "        \"--onnx-model\", f\"/app/outputs/{onnx_path.relative_to(OUTPUTS_DIR)}\",\n",
    "        \"--checkpoint\", f\"/app/outputs/{checkpoint_path.relative_to(OUTPUTS_DIR)}\",\n",
    "        \"--host\", \"0.0.0.0\",\n",
    "        \"--port\", str(DOCKER_CONTAINER_PORT),\n",
    "    ]\n",
    "    \n",
    "    # Prepare environment variables\n",
    "    environment = {\n",
    "        \"PYTHONPATH\": \"/app/src:/app\",\n",
    "        \"OCR_EXTRACTOR\": \"easyocr\",\n",
    "        \"PDF_EXTRACTOR\": \"pymupdf\",\n",
    "    }\n",
    "    \n",
    "    \n",
    "    container = start_docker_container(\n",
    "        image_name=DOCKER_IMAGE_NAME,\n",
    "        image_tag=DOCKER_IMAGE_TAG,\n",
    "        container_name=DOCKER_CONTAINER_NAME,\n",
    "        host_port=DOCKER_HOST_PORT,\n",
    "        container_port=DOCKER_CONTAINER_PORT,\n",
    "        volumes=volumes,\n",
    "        environment=environment,\n",
    "        command=command,\n",
    "        verbose=True,\n",
    "        force_port=True,  # Automatically stop conflicting containers\n",
    "    )\n",
    "    \n",
    "    if container:\n",
    "        print(\"\\nWaiting for container to start...\")\n",
    "        time.sleep(5)  # Give container time to start\n",
    "        print(\"Container started. Waiting for API to be ready...\")\n",
    "        \n",
    "        # Wait for API to be ready (up to 30 seconds)\n",
    "        max_wait = 30\n",
    "        wait_interval = 2\n",
    "        for i in range(max_wait // wait_interval):\n",
    "            if check_container_health(DOCKER_CONTAINER_NAME, verbose=False):\n",
    "                print(\"✓ API is ready!\")\n",
    "                break\n",
    "            time.sleep(wait_interval)\n",
    "        else:\n",
    "            print(\"⚠ API may not be ready yet. Check logs if needed.\")\n",
    "else:\n",
    "    print(\"✗ Cannot start container: models not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check container status\n",
    "if docker_client:\n",
    "    try:\n",
    "        container = docker_client.containers.get(DOCKER_CONTAINER_NAME)\n",
    "        status = container.status\n",
    "        print(f\"Container status: {status}\")\n",
    "        \n",
    "        if status == \"running\":\n",
    "            print(\"✓ Container is running\")\n",
    "            \n",
    "            # Check health\n",
    "            check_container_health(DOCKER_CONTAINER_NAME)\n",
    "            \n",
    "            # Show resource usage\n",
    "            stats = container.stats(stream=False)\n",
    "            memory_usage = stats['memory_stats'].get('usage', 0) / (1024**2)  # MB\n",
    "            print(f\"Memory usage: {memory_usage:.2f} MB\")\n",
    "        else:\n",
    "            print(f\"⚠ Container status: {status}\")\n",
    "            get_container_logs(DOCKER_CONTAINER_NAME, tail=50)\n",
    "    except docker.errors.NotFound:\n",
    "        print(f\"Container not found: {DOCKER_CONTAINER_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. API Testing Through Docker\n",
    "\n",
    "Test all API endpoints through the Docker container (reusing patterns from api_testing.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Single Text Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with text_1\n",
    "text_1 = get_text_fixture(\"text_1\")\n",
    "result = make_request(\"POST\", \"/predict\", json={\"text\": text_1})\n",
    "\n",
    "if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
    "    entities = result[\"data\"].get(\"entities\", [])\n",
    "    print(f\"✓ Request successful (latency: {result['latency_ms']:.1f}ms)\")\n",
    "    display_entities(entities, source_text=text_1)\n",
    "else:\n",
    "    print(f\"✗ Request failed: {result.get('error', result.get('status_code'))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with text_2 (contains email, phone, location)\n",
    "text_2 = get_text_fixture(\"text_2\")\n",
    "result = make_request(\"POST\", \"/predict\", json={\"text\": text_2})\n",
    "\n",
    "if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
    "    entities = result[\"data\"].get(\"entities\", [])\n",
    "    print(f\"✓ Request successful (latency: {result['latency_ms']:.1f}ms)\")\n",
    "    display_entities(entities, source_text=text_2)\n",
    "else:\n",
    "    print(f\"✗ Request failed: {result.get('error', result.get('status_code'))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Single PDF File Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with PDF file\n",
    "file_path = get_file_fixture(\"file_1\", \"pdf\")\n",
    "try:\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "    files = {\"file\": (file_path.name, file_content, \"application/pdf\")}\n",
    "    result = make_request(\"POST\", \"/predict/file\", files=files)\n",
    "    \n",
    "    if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
    "        extracted_text = result[\"data\"].get(\"extracted_text\", \"\")\n",
    "        entities = result[\"data\"].get(\"entities\", [])\n",
    "        print(f\"✓ Request successful (latency: {result['latency_ms']:.1f}ms)\")\n",
    "        display_entities(entities, source_text=extracted_text)\n",
    "    else:\n",
    "        print(f\"✗ Request failed: {result.get('error', result.get('status_code'))}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Single Image File Prediction (OCR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with PNG image file (requires OCR)\n",
    "file_path = get_file_fixture(\"file_1\", \"png\")\n",
    "try:\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "    files = {\"file\": (file_path.name, file_content, \"image/png\")}\n",
    "    result = make_request(\"POST\", \"/predict/file\", files=files)\n",
    "    \n",
    "    if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
    "        extracted_text = result[\"data\"].get(\"extracted_text\", \"\")\n",
    "        entities = result[\"data\"].get(\"entities\", [])\n",
    "        if extracted_text:\n",
    "            print(f\"✓ Request successful (latency: {result['latency_ms']:.1f}ms)\")\n",
    "            display_entities(entities, source_text=extracted_text)\n",
    "    elif result.get(\"status_code\") == 400:\n",
    "        error_detail = result.get(\"data\", {}).get(\"detail\", \"\")\n",
    "        if \"EasyOCR\" in error_detail or \"pytesseract\" in error_detail or \"Pillow\" in error_detail:\n",
    "            print(f\"⚠️  OCR dependencies not installed in container\")\n",
    "        else:\n",
    "            print(f\"✗ Request failed: {error_detail}\")\n",
    "    else:\n",
    "        print(f\"✗ Request failed: {result.get('error', result.get('status_code'))}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Batch Text Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch with multiple texts\n",
    "texts = get_batch_text_fixture(\"batch_text_small\")\n",
    "result = make_request(\"POST\", \"/predict/batch\", json={\"texts\": texts})\n",
    "\n",
    "if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
    "    predictions = result[\"data\"].get(\"predictions\", [])\n",
    "    print(f\"✓ Batch request successful (latency: {result['latency_ms']:.1f}ms)\")\n",
    "    print(f\"Processed {len(predictions)} texts\")\n",
    "    for i, (text, prediction) in enumerate(zip(texts, predictions), 1):\n",
    "        entities = prediction.get(\"entities\", [])\n",
    "        print(f\"\\nText {i}:\")\n",
    "        display_entities(entities, source_text=text)\n",
    "else:\n",
    "    print(f\"✗ Request failed: {result.get('error', result.get('status_code'))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Batch File Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch with PDF files\n",
    "file_paths = get_batch_file_fixture(\"batch_file_small\", \"pdf\")\n",
    "try:\n",
    "    files_list = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            file_content = f.read()\n",
    "        files_list.append((\"files\", (file_path.name, file_content, \"application/pdf\")))\n",
    "    \n",
    "    result = make_request(\"POST\", \"/predict/file/batch\", files=files_list)\n",
    "    \n",
    "    if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
    "        predictions = result[\"data\"].get(\"predictions\", [])\n",
    "        print(f\"✓ Batch request successful (latency: {result['latency_ms']:.1f}ms)\")\n",
    "        print(f\"Processed {len(predictions)} files\")\n",
    "        for i, (file_path, prediction) in enumerate(zip(file_paths, predictions), 1):\n",
    "            extracted_text = prediction.get(\"extracted_text\", \"\")\n",
    "            entities = prediction.get(\"entities\", [])\n",
    "            print(f\"\\nFile {i} ({file_path.name}):\")\n",
    "            if extracted_text:\n",
    "                display_entities(entities, source_text=extracted_text)\n",
    "    else:\n",
    "        print(f\"✗ Request failed: {result.get('error', result.get('status_code'))}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Docker Compose Testing\n",
    "\n",
    "Test using Docker Compose for orchestration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate docker-compose.yml exists\n",
    "compose_file = project_root / \"docker-compose.yml\"\n",
    "\n",
    "if compose_file.exists():\n",
    "    print(f\"✓ docker-compose.yml found: {compose_file}\")\n",
    "    # Read and display content\n",
    "    with open(compose_file) as f:\n",
    "        content = f.read()\n",
    "        print(\"\\nDocker Compose file content:\")\n",
    "        print(content)\n",
    "else:\n",
    "    print(f\"✗ docker-compose.yml not found: {compose_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start services with Docker Compose\n",
    "# Note: This requires updating docker-compose.yml with actual model paths first\n",
    "\n",
    "import subprocess\n",
    "\n",
    "compose_file = project_root / \"docker-compose.yml\"\n",
    "\n",
    "if compose_file.exists() and onnx_path and checkpoint_path:\n",
    "    # Update docker-compose.yml command with actual paths\n",
    "    # For now, we'll just validate the file\n",
    "    print(\"Note: To use docker-compose, update docker-compose.yml with actual model paths\")\n",
    "    print(f\"  ONNX: /app/outputs/{onnx_path.relative_to(OUTPUTS_DIR)}\")\n",
    "    print(f\"  Checkpoint: /app/outputs/{checkpoint_path.relative_to(OUTPUTS_DIR)}\")\n",
    "    \n",
    "    # Example: Start with docker-compose (commented out - requires manual path update)\n",
    "    # result = subprocess.run(\n",
    "    #     [\"docker-compose\", \"-f\", str(compose_file), \"up\", \"-d\"],\n",
    "    #     cwd=project_root,\n",
    "    #     capture_output=True,\n",
    "    #     text=True,\n",
    "    # )\n",
    "    # print(result.stdout)\n",
    "    # if result.returncode != 0:\n",
    "    #     print(f\"Error: {result.stderr}\")\n",
    "else:\n",
    "    print(\"Cannot start docker-compose: missing compose file or models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Volume Mounts and Environment Variables\n",
    "\n",
    "Test different volume mount configurations and environment variable settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test volume mounts - verify files are accessible in container\n",
    "if docker_client:\n",
    "    try:\n",
    "        container = docker_client.containers.get(DOCKER_CONTAINER_NAME)\n",
    "        \n",
    "        # Check if outputs directory is mounted\n",
    "        exit_code, output = container.exec_run(\n",
    "            [\"sh\", \"-c\", \"ls -la /app/outputs/conversion | head -5\"],\n",
    "            user=\"root\"\n",
    "        )\n",
    "        if exit_code == 0:\n",
    "            print(\"✓ Outputs directory is accessible:\")\n",
    "            print(output.decode(\"utf-8\"))\n",
    "        else:\n",
    "            print(\"✗ Cannot access outputs directory\")\n",
    "            if output:\n",
    "                print(f\"  Error: {output.decode('utf-8').strip()}\")\n",
    "            \n",
    "        # Check if models are visible\n",
    "        if onnx_path:\n",
    "            container_onnx_path = f\"/app/outputs/{onnx_path.relative_to(OUTPUTS_DIR)}\"\n",
    "            # Use sh -c to allow shell operators\n",
    "            exit_code, output = container.exec_run(\n",
    "                [\"sh\", \"-c\", f\"test -f {container_onnx_path} && echo 'ONNX model found' || echo 'ONNX model not found'\"],\n",
    "                user=\"root\"\n",
    "            )\n",
    "            result = output.decode('utf-8').strip() if output else \"\"\n",
    "            if exit_code == 0:\n",
    "                print(f\"\\nModel check: {result}\")\n",
    "            else:\n",
    "                print(f\"\\nModel check: Error checking model file\")\n",
    "                if result:\n",
    "                    print(f\"  {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking volumes: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different environment variable configurations\n",
    "# Note: This requires restarting the container with different env vars\n",
    "\n",
    "print(\"Testing environment variables:\")\n",
    "print(\"\\nCurrent configuration:\")\n",
    "print(f\"  OCR_EXTRACTOR: easyocr\")\n",
    "print(f\"  PDF_EXTRACTOR: pymupdf\")\n",
    "print(f\"  PYTHONPATH: /app/src:/app\")\n",
    "\n",
    "# To test different extractors, you would:\n",
    "# 1. Stop current container\n",
    "# 2. Start new container with different environment variables\n",
    "# 3. Test API endpoints\n",
    "# Example:\n",
    "# environment = {\n",
    "#     \"PYTHONPATH\": \"/app/src:/app\",\n",
    "#     \"OCR_EXTRACTOR\": \"pytesseract\",  # Different OCR\n",
    "#     \"PDF_EXTRACTOR\": \"pdfplumber\",    # Different PDF extractor\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup\n",
    "\n",
    "Stop containers and optionally remove images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Docker container\n",
    "stop_docker_container(DOCKER_CONTAINER_NAME, remove=True, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Remove Docker image (uncomment to use)\n",
    "# if docker_client:\n",
    "#     try:\n",
    "#         image = docker_client.images.get(f\"{DOCKER_IMAGE_NAME}:{DOCKER_IMAGE_TAG}\")\n",
    "#         docker_client.images.remove(image.id, force=True)\n",
    "#         print(f\"✓ Removed image: {DOCKER_IMAGE_NAME}:{DOCKER_IMAGE_TAG}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error removing image: {e}\")\n",
    "\n",
    "print(\"Cleanup complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-ner-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
